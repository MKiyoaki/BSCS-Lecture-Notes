## WEEK IV - Multilayer Perceptrons & Backpropagation

>[🏠 MENU - 7CCSMPNN](year3/7ccsmpnn.md)
>
>[⬅️ WEEK III - Introduction to Neural Networks](year3/7ccsmpnn/w3.md)
>
>[➡️ WEEK V - Deep Discriminative Neural Networks](year3/7ccsmpnn/w5.md)
>
>Outlines:
>
>1. 

### 4.1. Introduction to Deep Neural Networks

##### 4.1.1. Deep Neural Networks

- Goal
  - Classify objects by learning *non-linearity*. 
  -  Motivation
    - Regarding to ANNs, there are many problems for which linear discriminants are insufficient for minimum error.
    - In previous methods, the central difficulty was the choice of the appropriate nonlinear functions
    - A brute-force approach might be to select a complete basis set such as all polynomials; such a classifier would require too many parameters to be determined from a limited number of training samples.
    - In using the multilayer Neural Networks, the form of the nonlinearity is learned from the training data.
    - Careful choice of network topology is required, nevertheless, to avoid an over-complex network or one that performs poorly.
- Characteristics
  - Massive parallelism.
  - Distributed representation and computation.
  - Learning ability.
  - Generalisation ability.
  - Adaptivity.
- Applications
  - Pattern recognition/classification
  - Forecasting/prediction
  - Function approximation
  - Clustering/categorisation
  - Control

##### 4.1.2. Taxonomy

- Network Architectures

  - **Feedforward networks:** no loop exists (static system)
  - **Feedback/Recurrent networks:** loop exists (dynamic system)

- Learning Paradigms

  - **Supervised learning**

    - Target is known for every input pattern. Weights are determined so that the network can produce output as close as possible to the known target. 

    - *Reinforcement learning* is a special case of supervised learning where the weights are determined by critiques on the corrections of network outputs. 

      > e.g., a reward function.

  - **Unsupervised learning**

    - Target is not known. Weights are determined by exploring the underlying structure in the data or correlation between patterns in the data.

  - **Hybird learning**

    - It combines the supervised learning and unsupervised learning. A portion of weights are determined by supervised learning while the others are determined by unsupervised learning.

---

### 4.2. Feedforward Neural Networks

##### 4.2.1. MLP and Neuron Model

- Feedforward Neural Networks
  - A **feedforward neural network** or **multilayer perceptron (MLP)** consists of one input layer, some hidden layers and one output layer.
    - Each layer is an array of neurons.
    - Layers are interconnected by links.
    - Each link is associate with a connection weight.
- Neuron Model
  - A single *bias unit* is connected to each unit other than the input units.
  - 



---

### 4.3. Backpropagation Algorithm



---

### 4.4. Radial Bias Function Neural Networks