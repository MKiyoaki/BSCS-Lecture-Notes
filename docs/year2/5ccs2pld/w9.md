## WEEK IX - Logical Programming II

>[🏠 MENU - 5CCS2PLD](year2/5ccs2pld.md)
>
>[⬅️ WEEK VIII - Logical Programming I](year2/5ccs2pld/w8.md)
>
>[➡️ WEEK X - Revision II](year2/5ccs2pld/w10.md)
>
>Outlines:
>
>Unification
>
>> Introduction to Unification
>>
>> Unification Problem
>>
>> Unification Algorithm
>
>SLD-Resolution and Back-tracking
>
>Loops and Constructing SLD-Resolution Trees
>
>

### 22. Unification

##### 22.1. Introduction to Unification

- **Unification** is the process of the following, 
  - Intuition for logic programming
    - Use *formulae* to express knowledge and describe problems.
    - Use *inference* to compute with knowledge and solve problems. 
  - Experimenting with the language
    - Theory - unification and SLD-resolution
    - Pratice - implementation in Prolog
- Histroy of unification

##### 22.2. Unication Problem

- A **unification problem** $\mathcal{U}$​ is <u>a set of questions</u> between terms containing variables, denoted as
$$
\{s_1 = t_1, ..., s_n = t_n\}
$$
- A solution to $\mathcal{U}$, also called a **unifier**, is a substitution $\sigma$, such that when applied to every term in $\mathcal{U}$, for each equation $s_i=t_i$, the terms $s_{j\sigma}, t_{j\sigma}$ are syntatically identical. 
- The *most general unifier (mgu)* is a unifier $\sigma$ such that any other unifier $\rho$ is an instance of $\sigma$. 

  > e.g.
  >
  > Consider the following unification problem $\mathcal{U}=\{f(X) = f(Y)\}$ and the substitutions $\sigma = \{X \mapsto Y\}$ and $\rho = \{X \mapsto a; Y \mapsto a\}$. 
  >
  > > - Both substitutions make the terms $f(X)$ and $f(Y)$ syntactically identical, i.e.,
  > >
  > >   $f(X)\sigma = f(Y) = f(Y)\sigma$
  > >
  > >   $f(X)\rho = f(a) = f(Y)\rho$
  > >
  > >   Hence they are both unifiers. However, 
  > >
  > >   - $\sigma$ is more general than $\rho$ because $\rho$ is an instance of $\sigma$ (by applying the substitution $\gamma = \{Y \mapsto a\}$ after $\sigma$ gives us $\rho$). 
  > >   - But $\rho$ is not an instance of $\sigma$ sicne we cannot get $\sigma$ from $\rho$. 
  > >
  > > - In fact, in this case we can say that $\sigma$ is the most general unifier because no other unifier is more general than $\sigma$ is. 

- Intitution

  - Mechanism on substitutions
    - Substitutions are applied to entire clauses to allow them to resolve. 
    - Substitutions that commit variables to specific terms (e.g., constants and function terms) to <u>prevent future substitutions being able to act as unifiers</u>. 

      > e.g.
      >
      > We can unify the atoms $p(X), p(Y)$ in the clauses $p(X) \vee \neg q(X)$ and $\neg p(Y)$, either by 
      >
      > 1. replacing $X \mapsto Y$ (or $Y \mapsto X$), or 
      > 2. replacing both of $X, Y$ by a constant $a$. 
      >
      > Whereas the first two substitutions would allows us to then unify the resolvent $\neg q(X)$ (or $\neg q(Y)$) with the clause $q(b)$, the former would not. 
      >
      > i.e., Replacing method 2. (replace variables to a constant) will generate a new clause $\neg q(a)$ and would not allow the resolution of this clause with any atom involving anything other than $a$. 

  - We want to leave the variables *free*, unless we need to bind them for the unification to succeed. 


##### 22.3. Unification Algorithm

- Definition
  - The unification algorithm will
    - find the *mgu* for a unification problem if a solution exists, 
    - or otherwise fails, indicating that there are no solutions. 
  - To find the *mgu*, the algorithm <u>simplifies the set of equations using a set of transformation rules</u>. 
    - At each step, either a new set of equations is produced or a failure case arises.
    - The algorithm terminates and outputs the *mgu* when no rule may be applied. 

- Algorithm rules
  - *Input:* a finite set of equations, $\{s_1 = t_1, ..., s_n = t_n\}$. 
  - *Output*: the *mgu* of those equations, or failure. 
  - Rules
    $$
    \begin{matrix}
    
    1. &f(s_1,..., s_n) = f(t_1, ... t_n), E &\to &s_1 = t_1, ..., s_n = t_n, E \\
    2. &f(s_1,...,s_n) = g(t_1,...,t_m), E &\to &\text{failure} \\
    3. &X = X, E &\to &E \\
    4. &t = X, E &\to &X = t, E &\text{ if } t \text{ is not a variable} \\
    5. &X = t, E &\to &X = t, E\{X \mapsto t\} &\text{ if } X \text{ not in } t \text{ and } X \text { in } E \\
    6. &X = t, E &\to &\text{failure} &\text{ if } X \text{ occurs in } t \text{ and } X \neq t \\
    
    \end{matrix}
    $$
    - Notice that
      - The cases 1. and 2. apply also to constants (arity 0), i.e., In the first case the equation is eliminated and in the second failure arises. 
      - The test in case 6. is called an **occur-check**. e.g., If $X = f(X)$ is a failure case, this test is time consuming, and for this reason in some systems it is not implemented. 

- Features
  - The unification algorithm applies the rules in a non-deterministic way until no rule can be applied or a failure case arises. 
  - In the case of success, by changing each $=$ in the final set of equation to $\mapsto$ we obtain the *mgu* of the initial set of terms. 
  - The <u>order of equations in the problem is NOT important</u> because we are working on *sets* of equations. 

- Examples

  > e.g.
  >
  > *Input*: $\{f(a, a) = f(X, a)\}$
  >
  > - Using rule 1. with the first equation
  >
  >   $\{a = X, a = a\}$
  >
  > - Using rule 4. with the first equation
  >
  >   $\{X = a, a = a\}$
  >
  > - Using rule 1. with the second equation
  >
  >   $\{X = a\}$
  >
  > *Output*: $\{X \mapsto a\}$

  > e.g.
  >
  > *Input*: $\{[X | L] = [0], Y = [1, 2], [X | Z] = U\}$
  >
  > - Using rule 1. with the first equation
  >
  >   $\{X = 0, L = [], Y = [1, 2], [X | Z] = U\}$
  >
  > - Using rule 5. with the first equation
  >
  >   $\{X = 0, L = [], Y = [1, 2], [0 | Z] = U\}$
  >
  > - Using rule 4. with the last equation
  >
  >   $\{X = 0, L = [], Y = [1, 2], U = [0 | Z]\}$
  >
  > Output: $\{X \mapsto 0, L \mapsto [], Y \mapsto [1, 2], U \mapsto [0 | Z]\}$

---

### 23. SLD-Resolution and Back-tracking

##### 23.1. Resolution and SLD-Resolution

- The principle of resolution

  - In order to prove a goal $:- \ G_1, ..., G_n$ with respect to a set $P$ of program clauses, **resolution** seeks to show that $P \cup \{\neg G_1 \vee ... \vee \neg G_n\}$​ leads to a **contradiction**. 
  - A contradiction is obtained when a literal and its negation are stated at the same time, that is, both $A$ and $\neg A$ (Recall that $A \wedge \neg A$​ is unsatisfiable). 
  - If a contradiction does not arise directly, a new goal is derived by unifying the current goal with a program clause.
    - The derived goals are called **resolvents**. 

- The SLD-Resolution

  - Definition
    - **Selective** - At each resolution step a fixed computation rule is applied to select which atom from the goal will be next resolved upon. 
    - **Linear** - At each resolution step the most recently derived resolvent is used as the next goal. 
    - **Definite** - All the program clauses are definite clauses. 

  - Properties
    - Refutation-complete
      - Given a program and a goal, if a contradiction can be derived, then SLD-resolution will eventually generate it. 
    - Independence of the selection rule
      - If there exists a solution to a goal, SLD-resolution will find it, regardless of the selection rule employed for choosing which atom is resolved upon. 

  - Computing resolvents with SLD-resolution
    - Given a goal clause $:- \ G_1, ..., G_k$. 
      - We select an atom $G_i$ of form $p(s_1, ..., s_n)$​. 
      - We select a program clause $p(t_1, ..., t_n) :-\ B_1, ... B_m$ such that $p(t_1, ... t_n)$ and $p(s_1, ..., s_n)$ are unifiable using the *mgu* $\sigma$​. 
    - We then obtain the resolvent $:-\ B_1\sigma, ..., B_m\sigma, G_1\sigma, ..., G_{i-1}\sigma, ..., G_{i+1}\sigma, ... , G_k\sigma$ from which $G_i\sigma$​ has been eliminated. 
    - The idea is to continue deriving new resolvents until an empty one is found, which indicates that a contradiction has been found.
    - When an empty resolvent is generated, the composition of the substitutions applied at each resolution step, restricted to the variables of the query, is the **solution** to the goal. 

  - SLD-resolution in Prolog
    - Prolog always selects the *left-most literal* in the goal. 
    - Prolog uses the clauses in the rogram in the order they are written, that is, *from top to bottom*. 
    - SLD-resolution is complete, but Prolog's implementation of SLD-resolution is not complete because of tis search strategy in the SLD-tree.
      - Prolog uses *depth-first search*, which is efficient but not complete, because it may get stuck in a branch that expands infinitely. 

    > e.g.
    >
    > ```Prolog
    > based(prolog, logic). 
    > based(haskell, maths).
    > likes(max, logic). 
    > likes(claire, maths). 
    > likes(X, P) :- based(P, Y), likes(X, Y). 
    > 
    > ```
    >
    > - `:- likes(Z, prolog). `
    >
    >   1. Using the last clause and the *mgu* $\{X \mapsto Z, P \mapsto \text{prolog} \}$, we obtain the *resolvent* `:- based(prolog, Y), likes(Z, Y). `
    >
    >   2. Now using the first clause and the *mgu* $\{Y \mapsto \text{logic}\}$, we obtain the new resolvent `:- likes(Z, logic). `
    >
    >   3. Since we can now unify with the fact `likes(max, logic)` using the substitution $\{Z \mapsto \text{max}\}$​, we can obtain an empty resolvent `([])`
    >
    >   4. The composition of substitutions generated is
    >
    >      $\{X \mapsto \text{max}, P \mapsto \text{prolog}, Y \mapsto \text{logic}, Z \mapsto \text{max}\}$
    >
    >   5. Therefore the solution to the inital query is $\{Z \mapsto \text{max}\}$

##### 23.2. SLD-Resolution Trees

- Definition

  - We can represent each resolution step graphically as follows

    ```mermaid
    graph TB
    	goal --mgu--> resolvent
    ```

  - Since there might be several clauses in the program that can be used to generate a resolvent from a goal, we obtain a **SLD-resolution Tree**. 

    ```mermaid
    graph TB
    	goal --mgu 1--> r1[resolvent 1]
    	goal --mgu 2--> r2[resolvent 2]
    	goal --mgu 3--> r3[resolvent 3]
    ```

    - Every branch in the SLD-tree that <u>leads to an empty resolvent</u> (denoted by `[]`) yields a **solution**. 
    - If a goal unifies with <u>no program clause</u>, the branch is a **failure**. 
    - Thus, a SLD-tree may have success branches, failure branches, but also infinite branches. 

  > e.g.
  >
  > ```Prolog
  > based(prolog, logic). 
  > based(haskell, maths).
  > likes(max, logic). 
  > likes(claire, maths). 
  > likes(X, P) :- based(P, Y), likes(X, Y). 
  > 
  > # answer: X=max
  > ```
  >
  > ```mermaid
  > graph TB
  > 	init[:- likes\Z, prolog\] --{X |-> Z, P |-> prolog}--> node1[:- based\prolog, Y\, likes\Z, Y\]
  > 	node1--{Y |-> logic}-->node2[:- likes\Z, logic\]
  > 	node2--{Z |-> max}-->node3(empty - succeed! )
  > 	node2--{X |-> Z, P |-> logic}-->node4[:- based\logic, Y\, likes\Z, Y\]
  > 	node4--->failure(failure! )
  > ```

  > e.g.
  >
  > ```Prolog
  > based(prolog, logic). 
  > based(haskell, maths).
  > likes(max, logic). 
  > likes(claire, maths). 
  > likes(X, P) :- based(P, Y), likes(X, Y). 
  > 
  > # answer: false
  > ```
  >
  > ```mermaid
  > graph TB
  > 		init[:- likes\Z, painting\] --{X |-> Z, P |-> painting}--> node1[:- based\painting, Y\, likes\Z, Y\]
  > 	  node1--->failure(failure! )
  > ```

##### 23.3. Back-tracking

- Trigger

  - When *a branch ends* Prolog can *back-track* over the tree to search alternative branches. 
  - The previous resolution step is taken back and then the next possible resolvent is generated. 
  - *Failure* branches back-track **automatically**, and *solution* branches can be back-tracked from the request.
  - Back-tracking can be stopped by using the **cut** predicate, written as `!`, which means do not back-track beyond this point. 

- Examples

  > e.g.
  >
  > ```Prolog
  > append([], L, L). 
  > append({X|L], Y, [X|Z]) :- append(L, Y, Z). 
  > 
  > # answers
  > # 1) X=[], U=[1, 2]. 
  > # 2) X=[X1|[]], U=[X1|[1, 2]]. (L1=[], Z1=[1, 2])
  > # 3) ...
  > 
  > ```
  >
  > Check the slides to see details. 

---

### 24. Loops and Constructing SLD-Resolution Trees

##### 24.1. Non-termination

- Definition

  - Since Prolog searches the tree using the program clauses in the order in which they are written, and in a *depth-first* manner, it is important to <u>put base clauses before recursive ones</u>. 

    > e.g.
    >
    > ```Prolog
    > append([X|L], Y, [X|Z]) :- append(L, Y, Z). 
    > append([], L, L). 
    > ```
    >
    > This program produces no solutions and will result in an error, because <u>Prolog will attempt to construct an infinite branch</u> by using the recursive clause in each resolution step. 

##### 24.2. Constructing SLD-Resolution Trees

- Basic Rules

  - Basic objects

    - Each node in the tree represent the goal being operated on, which may contain several literals. 
    - The selection function will pick the next one to resolve. In Prolog, this is always the **left-most** literal in the goal clause. 
    - When resolving the selected literal with a clause in the program, Prolog will use the order of apperance of these clauses, i.e., from **top-to-bottom**. 
    - Each node has as many children as there are clauses in the program that can be unified with the literal selected in the goal. Fialed unifications are not depicted. 

  - Resolution

    - In the SLD-resolution tree, the order of resolution with program clauses is depicted from **left to right**. 
    - This means that the left-most child of a goal corresponds to the result of the resolution of the selected literal in the goal with the first clause in the program, whose head can be unified with the literal, and so forth. 
    - Each child is connected to its parent with an arrow from the parent to the child whose lbel corresponds to the *mgu* used in the unification. 

  - Termination

    - If no clauses in the program can be unified with the literal selected in the goal, the current branch fails (and hence has no children). This is indicted with *failure*. 

    - If a goal node is empty(i.e., the last literal of its parent has been resolved), then the node is represented by the empty clause `[]`, and ends with *success*. 

    - Some goals do not need program clauses to resolved. These typically involve built-in predicates. 

      > e.g.
      >
      > `Y is 3 + 1` succeeds if `Y` can be unified with the result of the evaluation of the expression `3 + 1`. i.e., If `Y` can be unified with `4`, then this will succeed if `Y` is free or already bound to `4`, and fail otherwise. 

##### 24.3. Variable Renaming

- Renaming in Prolog
  - 
