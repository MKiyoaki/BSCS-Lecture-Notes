## WEEK V - Deep Discriminative Neural Networks

>[🏠 MENU - 7CCSMPNN](year3/7ccsmpnn.md)
>
>[⬅️ WEEK IV - Multilayer Perceptrons & Backpropagation](year3/7ccsmpnn/w4.md)
>
>[➡️ WEEK VI - Deep Generative Neural Networks](year3/7ccsmpnn/w6.md)
>
>Outlines:
>
>1. Deep Neural Networks
>1. 

### 5.1. Deep Neural Networks

##### 5.1.1. Introduction to Deep Neural Networks

- Definition

  - A *deep* network is a neural network with more than 3 layers. Typically far more than 3 layers.
  - A *shallow* network is a neural network with less or qual than 3 layers.
  - The term **deep learning** refers to the process of training a deep neural network. 
- Motivation
  - Three-layer nerual networks are able to approximate any continuous non-linear function arbitrarily well.
    - Universal function approximators.
    - Can solve any pattern recognition task, in theory
  - However, to solve complex tasks (i.e., perform complex mapping), we need larger networks with more parameters. 
  - The success of VGGNet shows that <u>a deep network ususally has a better performance than a wide network</u>. 
- Deep Networks
  - Deep network aims to provide a hierarchy of representations with increasing level of abstraction.
    - It is the natural of dealing with many tasks.
  - Deep network allows **recurrent structures**. i.e., Recurrent nerual networks (RNNs). 
    - Recurrent networks process temporal information, where the value of $\textbf{x}$ changes over time. 
    - Training a recurrent network is achieved by unfolding the network and using backpropagation on the unfold network. 
    - There is one layer in the unfolded network for each time-step, so recurrent networks for processing long sequences are equivalent to very deep networks. 

##### 5.1.2. Difficulties in Pratices

- Vanishing Gradient

  ```mermaid
  graph LR
  	input --> y1
  	y1((y1)) --w21--> y2((y2))
  	y2 --w32--> y3((y3))
  	y3 --w43--> y4((y4))
  	y4 --w54--> y5((y5))
  	y5 --> output
  ```

  - Definition
    - Consider a deep network with one neuron per layer. While applying backpropagation: each time the error is propagated further backwards it is multiplied by a factor of the form $\phi'(w_{ji}x_i)w_{ji}$.
      - When using standard approach of activation function, the derivative of activation function results $\phi'(w_{ji}x_i)$ is small for most values of $\textbf{wx}$.
      - When using standard approach of weight initialization, the term $w_{ji}$ may also be small.
    - Thus this factor may getting more and more **smaller** when backpropagation. 
      - Neurons in the earlier layers learn much more slowly than neurons in later layers.
      - <u>Early layers contribute nothing to solving the task</u> and hence a deeper network cannot improve with the performance. 

- Exploding Gradient Problem

  - Definition
    - Consider a deep network with one neuron per layer. Each time the error is propagated further backwards it is multiplied by a factor of the form $\phi'(w_{ji}x_i)w_{ji}$. 
      - If the weights $w_{ji}$ are initialized to, or learn, large values, then this factor could be far more than 1. 
    - If not careful, the gradient tends to get **larger** as we move backward through hidden layers. This means:
      - Neurons in the earlier layers make, large, often random changes in their weights.
      - Later layers can NOT learn due to constantly changing output of earlier layers and, hence making network deeper makes the performance worse. 

- Solutions

  - Since the issues of gradients, backpropagation is inherently unstable.
  - To train deep networks it is necessary to mitigate this issue, by using:
    - activation functions with non-vanishing derivatives
    - better ways to initialize weights
    - adaptive variations on standard backpropagation
    - batch normalization
    - skip connections

  - Besides, in order to adapt large amount of parameters in the network, we need:
    - very large labelled datasets
    - large computational resources


##### 5.1.3. Solutions

- Activation Functions with Non-vanishing Derivatives

  - Rectified Linear Unit (ReLU)
    $$
    \phi'(net_j) = 
    \begin{cases}
    1 &\text{if } net_j \geq 0 \\
    0 &\text{if } net_j < 0
    \end{cases}
    $$

  - Leaky Rectified Linear Unit (LReLU)
    $$
    \phi'(net_j) =
    \begin{cases}
    1 &\text{if } net_j \geq 0 \\
    a &\text{if } net_j < 0
    \end{cases}
    $$

  - Parametric Rectified Linear Unit (PReLU)
    $$
    \phi'(net_j) =
    \begin{cases}
    1 &\text{if } net_j \geq 0 \\
    a_j &\text{if } net_j < 0
    \end{cases}
    $$

- Better Ways to Initialize Weights

  - For weights connecting $m$ inputs to $n$ outputs:

    | Methods       | Activation Function | Choose Weight from Uniform distribution with range of       | Choose Weight from Normal distribution with mean=0, deviation of |
    | :------------ | ------------------- | ----------------------------------------------------------- | ------------------------------------------------------------ |
    | Xavier Glorot | sigmoid/tanh        | $\left( -\sqrt{\frac{6}{m+n}}, \sqrt{\frac{6}{m+n}}\right)$ | $\sqrt{\frac{2}{m+n}}$                                       |
    | Kaiming He    | ReLU/LReLU/PReLU    | $\left( \sqrt{-\frac{6}{m}}, \sqrt{\frac{6}{m}}\right)$     | $\sqrt{\frac{2}{m}}$                                         |

- Adaptive Versions of Backpropagation

  - Motivation
  
    - Backpropagation struggles to deal with gradients in the cost function $J(\textbf{w})$ that are too small or too large.
  
      > Recall that backpropagation performs gradient descent to find parameters that minimize a cost function. 
  
    - Variation in the magnitude of the gradient may occur between:
  
      - Different layers (due to vanishing and exploding gradient)
      - Different parts of the cost function for a single neuron
      - Different directions for a multi-dimensional function
  
  - Momentum
  
    ![img](https://miro.medium.com/v2/1*ZASXdJV80xN7ntdINFEgIQ.jpeg)
  
    - Adds moving average of previous gradient to current gradient.
    - Increases step size when weight changes are consistently in same direction. 
  - Adaptive learning rate
    - Vary the learning rate for individual parameters during training.
      - Increase the learning rate if the cost is decreasing.
      - Decrease the learning rate if the cost is increasing.
    - Backpropagation algorithms with adaptive learning:
      - AdaGrad
      - RMSprop
    - Backpropagation algorithms with adaptive learning and momentum:
      - ADAM
      - Nadam
  
- Batch Normalization

  - Motivation
    - Learning in one layer of a network will change the distribution of inputs received by the subsequent layer of the network.
      - Consequently, learning is slow as later layers are always having to compensate for changes made to earlier layers.
      - Different inputs to one neuron can have very different scales. Inputs with smaller scales will tend to have less influence than ones with larger scales, even if the smaller ones are more discriminatory.
  - Definition
    - Batch normalization attempts to solve both these issues by scaling the output of each individual neuron so that it has a mean close to 0, and a standard deviation close to 1.

      $$
      BN(\textbf{x}) = \beta+\gamma \frac{\textbf{x} - E(\textbf{x})}{\sqrt{\text{Var}(\textbf{x}) + \epsilon}}
      $$
      where
      - $\beta, \gamma$ are parameters learnt by backpropagation,
      - $\epsilon$ is a constant used to prevent division-by-zero errors,
      - $E(\textbf{x})$ is the mean of $\textbf{x}$,
      - $\text{Var}(\textbf{x})$ is the variance (the squared standard deviation) of $\textbf{x}$. The mean and variance can be calculated using the value of $\textbf{x}$ in the current batch or using all the training data presented so far.
    - Batch normalization can be applied before or after the activation.

  - Evaluation

    - It enables saturating activation functions to be used as it limits activations to the range where the gradients are non-zero.
    - Make weight initialization less critical.
    - Generally stabilises learning, since gradient are less likely to vanish or explode.

- Skip Connections

  <img src="https://tikz.net/janosh/skip-connection.png" alt="skip-connection" style="zoom:33%;" />

  - Definition
    - Connections that skip one or more layers of the network (Residual module).
    - Skip connections let gradients by-pass parts of the network where the gradient has vanished. 
    - Network effectively becomes shallower, but this may be temporary. 


---

### 5.2. Convolutional Neural Networks (CNNs)

##### 5.2.1. Introduction to CNNs

- Definition

  - CNN is the most popular type of deep neural network.

  - A CNN is:

    - Any neural network in which at least one layer has an transfer function implemented using convolution/cross-correlation.
    - As opposed to vector multiplication.

  - Motivated by desire to recognize patterns with tolerance to location.

    > e.g.
    >
    > Spatial location from image, audio, etc.

    - Tolerance to location could be achieved by learning to recognize the pattern at each location independently.
    - Computationally more effecient to *share the weights* between the sub-networks (i.e. to have multiple copies of the same sub-network processing different locations).

- Kernel

  - Weight sharing is achieved by using cross-correlation as the transfer function.

  - A neuron's weights are defined as an array, called a **mask**, **filter**, or **kernel**. 

    > e.g. 
    >
    > $\begin{bmatrix} -1 &1 \\0 &-2 \end{bmatrix}$
  
  - The values in the array, the weights, will be learnt using backpropagation.
  
  - The input is also an array. 
  
    > e.g.
    >
    > An image or the output of the preceding layer of the network.
  
- Convolutional Layer

  ![CNN iamge](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQwHpdxADHgZ2NMU6j2BlD2DYdy3K5Y6ZTPgg&s)

  - Cross-correlation is implemented as follows. For each location in the input array in turn:

    1. Multiply each weight by corresponding value in the input,
    2. Sum these products and write answer in the corresponding location in the output array.
  
    > Note.
    >
    > Output is also an array of numbers, Sometimes called a *feature map.* 
    >
    > 
  
  - The output is strongest where the location in the input matches the weights in the kernel. 
  
    - The output is the same at the two locations in the input with the same values.
  
    - Provides tolerance to location means, the same pattern in different locations produces the same output.
  
  - Cross-correlation is equivalent to vector multiplication.
  
    > e.g.
    >
    > We can flatten a 4 * 4 array into a 1 * 16 array, whereas a 3 * 3 kernel can be flattened as 9 * 1. 
  
    - Calculating the output of transfer function in the normal way would give as:
      $$
      \sum_i w_{ji}x_i = \textbf{w}\textbf{x}
      $$
  
    - However, it is easier to use one kernel to produce all the outputs using cross-correlation. 
  
  - Convolutional Operation
  
    - The operation performed by the convolutional layers is cross-correlation (or linear filtering), instead of convolution. 
  
      > Cross-correlation:
      > $$
      > Y(i, j) = X \star H = \sum_{k, l} X(i+k, j+l) H(k, l)
      > $$
      > Convolution:
      > $$
      > Y(i,j) = X * H = \sum_{k, l} X(i+k, j+l) H(-k, -l)
      > $$

##### 5.2.2. 





##### 5.2.3. Pooling and Fully-Connected Layer