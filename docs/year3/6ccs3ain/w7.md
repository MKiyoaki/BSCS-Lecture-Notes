## WEEK VII - Game Theory

>[🏠 MENU - 6CCS3AIN](year3/6ccs3ain.md)
>
>[⬅️ WEEK VI - Consensus Mechanisms](year3/6ccs3ain/w6.md)
>
>[➡️ WEEK VIII - Agent Communications Languages](year3/6ccs3ain/w8.md)
>
>Outlines:
>
>1. Introduction to Game Theory
>    - Definition and Application
>    - Payoff Matrices
>2. Dominant Strategies
>
>     - Introduction
>       - Dominates, Strongly dominates, Weakly dominates
>     - Example
>3. Nash Equilibirum
>
>    - Introduction
>    - Calculate
>    - Pareto Optimality
>4. Normal Form Games
>5. Mixed Strategies

### 7.1. Introduction to Game Theory

##### 7.1.1. Introduction

- Definition

  - A framework for analysing interactions between a set of agents.
  - Bastract specification of interactions.
  - Describes each agent's preferences in terms of their utility. 
  - Give a range of **solution strategies** with which we can make some predictions about how agents should interact. 

- Applications

  - Competition bettwen agents
    - School admissions

  - Multi-party decision making
    - Military strategic analysis
    - The grade game
    - Choose side of road when driving


##### 7.1.2. Payoff Matrices

- **Payoff Matrices** - Can be used to record the reward for each agent basing on their decisions

  > e.g.
  >
  > Choose side game can be simulated as following, 
  >
  > |   i \ j   | Left | Right |
  > | :-------: | :--: | :---: |
  > |  **Up**   | 1, 0 | 0, 0  |
  > | **Right** | 0, 0 | 1, 1  |
  >
  > We have two agents, each player picking a (pure) strategy. 
  >
  > - Agent $i$ is the row player, gets the first reward in a cell.
  > - Agent $j$ is the column player, gets the second reward in a cell.

- **Outcomes** - what we get when we combine the actions of all the players.

  - An outcome corresponds to an element of the payoff matrix.

  > e.g.
  >
  > Consdier the above choose side game matrix.
  >
  > We identify outcomes by the moves the players make: $(\text{what }i\text{ plays, what }j\text{ plays})$.
  >
  > Thus $(\text{up, right})$ identifies the outcomes in which $i$ plays $\text{up}$ and $j$ plays $right$.

- Payoff matrices can be split into multiple matrices. One (Call $A$) that specifies the payoff to $i$ and another $B$ to $j$. 

  - Sometimes this payoff matrix could be represented as $(A, B)$. 
  - $a_{i', j'}$ represents the payoff if $i$ picks action $i'$ and $j$ picks action $j'$. 

  > e.g. 
  >
  > $A = \begin{pmatrix}1 &0 \\ 3 &1\end{pmatrix}$ is the payoff matrix for $i$  from the above table. 

---

### 7. 2. Dominant Strategies

##### 7.2.1. Introduction to Dominat Strategies

- Rational agent behave with several possible strategies in a given scenario

  > e.g.
  >
  > Play dominat strategy, nash equilibrium strategy, pareto optimal strategy, etc. 

- Definition

  - Given any particular strategy $s$, agent $i$, there will be a number of possible outcomes.
  - We say **$s_1$ dominates $s_2$** if every outcome possible by $i$ playing $s_1$ is *preferred* over every outcome possible by $i$ playing $s2$. 
    - $s_1$ **strongly dominates** $s_2$ if the utility of every outcome possible by $i$ playing $s_1$ is <u>strictly greater</u> than every outcome possible by $i$ playing $s_2$. i.e., $u(s_1) > u(s_2)$, for all outcomes.
    - $s_1$ **weakly dominates** $s_2$ if the utility of every outcome possible by $i$ playing $s_1$ is <u>no less than</u> every outcome possible by $i$ play $s_2$. i.e., $u(s_1) \geq u(s_2)$ for all outcomes. 

  > e.g.
  >
  > | i \ j |      D      |       C       |
  > | :---: | :---------: | :-----------: |
  > | **D** |    2, 1     |    2, *4*     |
  > | **C** | <u>5</u>, 1 | <u>5</u>, *4* |
  >
  > In this game, $C$ dominates $D$ for both players. 

- Process

  - A rational agent will **never** play a dominated strategy. Thus in deciding what to do, we can *delete dominated strategies*.
  - There is NOT always a unique undominated strategy.
  
  > e.g.
  >
  > Game with dominated strategies
  >
  > | Row \ Col | **L** | **C** | **R** |
  > | --------- | ----- | ----- | ----- |
  > | **U**     | 3 , 1 | 0, 1  | 0, 0  |
  > | **M**     | 1, 1  | 1, 1  | 5, 0  |
  > | **D**     | 0, 1  | 4, 1  | 0, 0  |
  >
  > - For the column player $j$ we get $B = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 1 & 0 \\ 1 & 1 & 0\end{bmatrix}$, where we can think of this as three vectors $\begin{bmatrix}1 \\ 1 \\ 1\end{bmatrix}, \begin{bmatrix}1 \\ 1 \\ 0\end{bmatrix}, \begin{bmatrix}1 \\ 1 \\ 0\end{bmatrix}$. 
  > - We can see that every component of $R$ is dominated by $L$ (and actually also $C$), thus we can remove $R$.
  >
  > | Row \ Col | **L** | **C** |
  > | --------- | ----- | ----- |
  > | **U**     | 3 , 1 | 0, 1  |
  > | **M**     | 1, 1  | 1, 1  |
  > | **D**     | 0, 1  | 4, 1  |
  >
  > - For the row player $i$ we get $A = \begin{bmatrix}3 &0 \\ 1 & 1 \\ 0 & 4\end{bmatrix}$, where we can think of this as three vectors $\begin{bmatrix}3 & 0\end{bmatrix}, \begin{bmatrix}1 & 1\end{bmatrix}, \begin{bmatrix}0 & 4\end{bmatrix}$. 
  > - No strategy here is dominated by any other. Thus we cannot remove anything else. 

##### 7.2.2. Example

> e.g.
>
> Consider the senario:
>
> | $i / j$ | **C** | **D** |
> | ------- | ----- | ----- |
> | **A**   | 2, 1  | 3, 4  |
> | **B**   | 3, 2  | 2, 3  |
>
> $D$ is dominate here. 
>
> - For the column player $j$ we get $s_j = \begin{bmatrix}1 & 4 \\ 2 & 3\end{bmatrix} \implies \begin{bmatrix}1 \\ 2\end{bmatrix}, \begin{bmatrix}4 \\ 3\end{bmatrix}$

---

### 7. 3. Nash Equilibirum

##### 7.3.1. Introduction to Nash Equilibirum

- Definition

  - We say that two strategies $s_1, s_2$ are in Nash Equilibirum (NE) if 
    1. Under the assupmtion that agent $i$ plays $s_1$, agent $j$ can do no better than $s_2$, and 
    2. Under the assupmtion that agent $j$ plays $s_2$, agent $i$ can do no better than $s_1$. 
  - i.e., Neither agent has any incentive to deviate from a NE.
  - If two strategies are best responses to each other, then they are in Nash equilibrium.

- Example

  > e.g.
  >
  > Consider the grade game
  >
  > | $i / j$ | **Y** | **X** |
  > | ------- | ----- | ----- |
  > | **Y**   | 2, 2  | 4, 1  |
  > | **X**   | 1, 4  | 3, 3  |
  >
  > Here the Nash equilibrium is $(Y, Y)$. 
  >
  > If $i$ assumes that $j$ is playing $Y$, then $i$'s best response is to play $Y$. Samilair for $j$. 

##### 7.3.2. Calculating NE

- Process

  - In a game like this you can find the NE by <u>cycling through the outcomes</u>, asking if either agent can improve its payoff by switching its strategy.

  - A pair of strategies $(i^*, j^*)$ is a **Nash equilibrium solution** to the game $(A, B)$ if:
    $$
    \forall i, a_{i^*, j^*} \geq a_{i, j^*} \\
    \forall j, b_{i^*, j^*} \geq b_{i^*, j} \\
    $$
    i.e., $(i^*, j^*)$ is a Nash equilibrium if:

    - If $j$ plays $j^*$, then $i^*$ gives the best outcome for $i$.
    - If $i$ plays $i^*$ , then $j^*$ gives the best outcome for $i$. 

- Limitation

  - NOT every interaction scenario has a pure strategy NE.
  - Some interaction scenarios <u>have more than one NE</u>.

- Example

  > e.g.
  >
  > Consider the senario:
  >
  > | $i / j$ | **C** | **D** |
  > | ------- | ----- | ----- |
  > | **A**   | 3, 5  | 2, 1  |
  > | **B**   | 2, 0  | 3, 3  |
  >
  > This game has two pure strategy NEs, $(C, C)$ and $(D, D)$. In both cases, a single agent can't unilaterally improve its payoff.

  > e.g.
  >
  > Consider the senario:
  >
  > | $i / j$ | **C** | **D** |
  > | ------- | ----- | ----- |
  > | **A**   | 1, 2  | 2, 1  |
  > | **B**   | 2, 0  | 1, 1  |
  >
  > This game has no pure strategy NE. For every outcome, one of the agents will improve its utility by switching its strategy. 
  >
  > We can find a form of NE in such games, but we need to go beyond pure strategies.

##### 7.3.3. Pareto Optimality

- Definition

  - An outcome is said to be **Pareto optimal** (or **Pareto efficient**) if there is no other outcome that <u>makes one agent better off without making another agent worse off</u>.
  - If an outcome is Pareto optimal, then at least one agent will be reluctant to move away from it (because this agent will be worse off).
  - If an outcome $\omega$ is NOT Pareto optimal, then there is another outcome $\omega'$ that makes everyone as happy, if not happier, than $\omega$.
  - *Reasonable agents* would agree to move to $\omega'$ from $\omega$ if $\omega$ is not Pareto optimal and $\omega'$ is.

  > e.g.
  >
  > | $i / j$ | **D** | **C** |
  > | ------- | ----- | ----- |
  > | **D**   | 3, 5  | 2, 1  |
  > | **C**   | 2, 0  | 1, 0  |
  >
  > This game has one Pareto efficient outcome, $(D, D)$. Thus, there is no solution in which either agent does better. 

- Note

  - Pareto efficiency does NOT necessarily mena *fair*. It is just that you can't move away and make one agent better off without making the other worse off.
  - In other words, 
    - Ignore players and imagine you are buying socks online. All options cost the same.
    - $i$ is the number of stars (rating) and $j$ is the number of pairs you get.
    - Trade off: All reasonable options are Pareto effecient. 
    

  > e.g.
  >
  > | $i / j$ | **C** | **D** |
  > | ------- | ----- | ----- |
  > | **A**   | 2, 1  | 3, 4  |
  > | **B**   | 3, 2  | 2, 3  |
  >
  > Pareto optimal outcome: $(A, D)$. 
  
- Social Welfare

  - Motivation

    - Pareto optimality is a rather weak concept.

  - Definition

    - The **social welfare** of an outcome $\omega$ is the sum of the utilities that each agent gets from $\omega$:
      $$
      \sum_{i \in A_g} u_i (\omega)
      $$
      Think of it as the *total amount of money in the system*.

    - As a solution concept, it doesn't consider the benefits to individuals.

    - May be appropriate <u>when the whole system (all agents) has a single owner</u> (then overall benefit of the system is important, not individuals).

  - Example

  > e.g.
  >
  > | $i / j$ | **D** | **C** |
  > | ------- | ----- | ----- |
  > | **D**   | 2, 2  | 1, 1  |
  > | **C**   | 3, 3  | 4, 4  |
  >
  > In this case, $(C, C)$ maximuises social welfare, since the social welfare of $(C, C)$ is $4 + 4 = 8$. 

---

### 7.4. Normal Form Games

##### 7.4.1. Introduction

- Definition

  - An n-person, finite, **nomal form** game is a tuple $(N, A, u)$, where
    - $N$ is a finite set of players,
    - $A = A_1 \times ... \times A_n$ where $A_i$ is a finite set of actions available to $i$. Each $a = (a_1, ..., a_n) \in A$ is an **action profile**, 
    - $u = (u_1, ..., u_n)$ where $u_i : A \mapsto \mathbb{R}$ is a real-valued **utility** function for $i$. 
  - Naturally represented by an n-dimensional matrix. 

- Strategies

  - We analyze games in terms of **strategies**, that is what agents decide to do.

    >  Combined with what the other agent(s) do(es) this jointly determines the payoff.

  - An agent's **strategy set** is <u>its set of available choices</u>.

  - Can just be the set of actions, i.e., **pure** strategies.

##### 7.4.2. Typical Games

- Common Payoff Games

  > e.g.
  >
  > *Choose which side game* or *Coordination game*
  >
  > | $i / j$   | **Left** | **Right** |
  > | --------- | -------- | --------- |
  > | **Left**  | 1, 1     | 0, 0      |
  > | **Right** | 0, 0     | 1, 1      |

  - Any game with $u_i(a) = u_j(a)$ for all $a \in A_i \times A_j$ is a *common payoff game*.

- Constant sum Games

  > e.g.
  >
  > | $i / j$   | **Heads** | **Tails** |
  > | --------- | --------- | --------- |
  > | **Heads** | 1, -1     | -1, 1     |
  > | **Tails** | -1, 1     | 1, -1     |
  
  - Any game with $u_i(a) + u_j(a) = c$ for all $a \in A_i \times A_j$ is a *constant sum game*.
  
- Zero-sum Game

  > e.g.
  >
  > Rock, paper, scissors
  >
  > | $i / j$      | **Rock** | **Paper** | **Scissors** |
  > | ------------ | -------- | --------- | ------------ |
  > | **Rock**     | 0, 0     | -1, 1     | 1, -1        |
  > | **Paper**    | 1, -1    | 0, 0      | -1, 1        |
  > | **Scissors** | -1, 1    | 1, -1     | 0, 0         |

  - A particular category of constant sum games are *zero-sum games*, where utilities sum to zero:

    $u_i(a) + u_j(a) = 0$ for all $a \in A_i \times A_j$

  - Preferences of agents are diametrically opposed we have strictly competitive scenarios.

    > Zero sum implies strictly competitive.

---

### 7.5. Mixed Strategies

##### 7.5.1. Introduction

- Definition

  - A mixed strategy is just a probability distribution across a set of pure strategies.

  - For a game where agent $i$ has two actions $a_1$ and $a_2$, a mixed strategy for $i$ is a probability distirbution:
    $$
    MS_i = \{P(a_1), P(a_2)\}
    $$
    Given this mixed strategy, when $i$ comes to play, they pick action $a_1$ with probability $P(a_1)$ and $a_2$ with probability $P(a_2)$.

- Process

  - To determine the mixed strategy, $i$ can compute the best values of $P(a_1)$ and $P(a_2)$.
  - These will be the values which give $i$ the highest expected payoff given the options that $j$ can choose and the joint payoffs taht result.
  - We could write down the expected payoffs of different mixed strategies and pick the one that optimizes expected payoff.
  - There is also a simple graphical method which works for very simple cases.

- Example

  > e.g.
  >
  > Let's consider the payoff matrix:
  >
  > | $i / j$ | **a3** | **a4** |
  > | ------- | ------ | ------ |
  > | **a1**  | 3, -3  | -1, 1  |
  > | **a2**  | 0, 0   | 1, -1  |
  >
  > We want to compute mixed strategies to be used by the players, which means decide $P(a_1)$ and $P(a_2)$ etc.
  >
  > $i$'s analysis of this game would be something like this:
  >
  > ```mermaid
  > xychart-beta
  > 	title "j picks a3"
  > 	x-axis "P(a1)" [0, 1]
  > 	y-axis "Payoff" -3 --> 3
  > 	line[0, 3]
  > ```
  >
  > ```mermaid
  > xychart-beta
  > 	title "j picks a4"
  > 	x-axis "P(a1)" [0, 1]
  > 	y-axis "Payoff" -3 --> 3
  > 	line[1, -1]
  > ```
  >
  > - Consider it from $i$'s perspective. Let's say you know that $j$ plays $a_3$.
  > - $i$'s payoff will be 3 or 0 depending on whether $i$ picks $a_1$ or $a_2$.
  > - The expected payoff therefore varies along the line, as $P(a_1)$ varies from 0 to 1.
  > - In the mixed strategy setting, we combine the two graphs together and we could see an intersect point, where $P(a_1) = 0.2$, $i$ have expected payoff whatever $j$ does. 
  > - This is a rational choice of mixed strategy.
  >
  > $j$ can perform a samiliar analysis. 

  - Such analysis is quite useful in zero sum games. 

##### 7.5.2. Mixed Strategy in General Sum Games

- Motivation

  > e.g.
  >
  > Consider the following battle of sexes senarios,
  >
  > | $i / j$        | **Bach** | **Stravinsky** |
  > | -------------- | -------- | -------------- |
  > | **Bach**       | 2, 1     | 0, 0           |
  > | **Stravinsky** | 0, 0     | 1, 2           |
  >
  > - Game contains elements of cooperation and competition.
  > - The interplay between these is what makes general sum games interesting.
  > - Interplay between cooperation and competition leads to **negotiation**. 

- Nash equilibrium

  - Earlier we introduced the notion of Nash equilibrium as a solution concept for general sum games.

  - Looked at pure strategy Nash equilibrium. 

    - Issue was that <u>not every game has a pure strategy Nash equilibrium</u>.

    > e.g.
    >
    > | $i / j$ | **D** | **C** |
    > | ------- | ----- | ----- |
    > | **D**   | 1, 2  | 2, 1  |
    > | **C**   | 2, 0  | 1, 1  |
    >
    > This game has no pure strategy NE. 

  - For a game with payoff matrices $A$ (to $i$) and $B$ (to $j$), a mixed strategy $(x^*, y^*)$ is a Nash equilibrium solution if:
    $$
    \forall x, x^* A y^{*T} \geq xAy^{*T} \\
    \forall y, x^* B y^{*T} \geq x^*By^T
    $$
    i.e., $x^*$ gives a higher expected value to $i$ than any other strategy when $j$ plays $y^*$. Similarly, $y^*$ gives a higher expected value to $j$ than any other strategy when $i$ plays $x^*$.

  - Unfortunately, this doesn't solve the problem of <u>which Nash equilibrium you should play</u>.
