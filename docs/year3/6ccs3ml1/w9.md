## WEEK IX - Evolutionary Algorithms

>[🏠 MENU - 6CCS3ML1](year3/6ccs3ml1.md)
>
>[⬅️ WEEK VIII - Reinforcement Learning 2](year3/6ccs3ml1/w8.md)
>
>[➡️ WEEK X - Learning from Demonstration](year3/6ccs3ml1/w10.md)
>
>Outlines:
>
>1. 

### 9.1. Genetic Algorithms (GAs)

##### 9.1.1. Introduction to Evolutionary Algorithm (EA)

- Definition
  - An evolutionary algorithm (EA) is a way of doing **search**. It is inspired by evolutionary biology and concepts from genetics.
  - We have a <u>population</u> of individuals where each <u>individual</u> is a representation of a solution to a problem.
  - We build a representation and decide how to combine these representations by doing:
    - Selection, and
    - Reproduction
  - Establishing and evaluating a population can be viewed as a (massively) parallel search.
- Simulation of the Evolution Process.
  - A population of candidate solutions evolves towards better solutions by repeatedly selecting the fit individuals from the current population and modifying them to form the next generation population.

##### 9.1.2. Genetic Algorithms (GAs)

- Overview
  - Loosely based on the idea of simulated evolution: survival of the fittest (Darwin).
  - In general, we hypothesise a *population* of candidate solutions to a particular problem. 
    - We *evaluate* each member of the population to decide how good that candidate is at solving the problem.
    - Then we *select* those members of the population that are the best (the fittest).
    - And we *reproduce* to obtain new members of the population.
    - Then we start all over again, hypothesising with this new set of candidate solutions.
  
- Evaluation

  - Adventages
    - Good for situations where it is difficult to ascertain the impact of a particular partial solution to a problem.
    - Easy to implement through parallel processing, because each candidate solution can be evaluated on its own.
    - Can adapt easily in dynamic environments.

- Basic Algorithm

  ```
  GA(Fitness,Fitness threshold,p,r,m)
  	Fitness: A function that assigns an evaluation score, given a hypothesis. 
  	Fitness threshold: A threshold specifying the termination criterion.
  	p: The number of hypotheses to be included in the population.
  	r: The fraction of the population to be replaced by Crossover at each step. 
  	m: The mutation rate.
  	
  	Initialize: P <- p random hypotheses
  	Evaluate: for each h in P, compute Fitness(h)
  	While [max_h Fitness(h)] < Fitness threshold:
  		Select
  		Crossover
  		Mutate
  		Update
  		Evaluate
  	Return the hypothesis from P that has the highest fitness.
  	
  ```

  - Select

    - Probabilistically select $(1-r)p$ members of $P$ to add to $P_s$.
      $$
      \Pr(h_i) = \frac{\text{Fitness}(h_i)}{\sum^p_{j=1} \text{Fitness}(h_j)}
      $$

  - Crossover

    - Probabilistically select $\frac{r \cdot p}{2}$ pairs of hypotheses from $P$.
    - For each pair $\langle h_1, h_2 \rangle$, produce two offspring by applying the Crossover operator. Add all offspring to $P_s$.

  - Mutate

    - Choose $m$ percent of the members of $P_s$, with uniform probability. For each, invert one randomly selected bit in its representation.

  - Update: $P \leftarrow P_s$

  - Evaluate

    - for each $h$ in $P$, compute $Fitness(h)$.

  - Finally, return the hypothesis from $P$ that has the highest fitness.

##### 9.1.3. Components of the Basic Algorithm

- Components

  - Representation - how is each candidate represented?
  - Fitness - how is each candidate evaluated?
  - Selection - how are the best candidates chosen?
  - Reproduction - how are new candidates generated?

- Representation

  - In a Genetic Algorithm, the classic representation is a *binary string* (or "bit string").

    - Each element in the string represents the presence (or absence) of a particular trait.
    - The bit string is the **genotype**.
    - The set of traits encoded is the **phenotype**.

  - Representation is **domain dependent**.

    > Note that biologists generally do not like this terminology because it only very loosely resembles real genetics.

  - Note that it is possible to generate genotypes that have:

    - Multiple phenotypes
    - Uncertain phenotypes
    - Invalid phenotypes
    
  - Different strategies exist for dealing with the situation of *invalid phenotype*, such as:
  
    - Preventing generation of invalid phenotypes.
    - Reporting lowest fitness for invalid phenotypes.
  
  
  > e.g.
  >
  > | Index | Item     | Value          |                  |                |
  > | ----- | -------- | -------------- | ---------------- | -------------- |
  > | 0     | Play     | yes/**no**     |                  | true/**false** |
  > | 1     | Windy    | true/**false** |                  | true/**false** |
  > | 2     | outlook  | **sunny**      | outlook-sunny    | **true**/false |
  > | 3     |          | overcast       | outlook-overcast | true/**false** |
  > | 4     |          | rainy          | outlook-rainy    | true/**false** |
  > | 5     | temp.    | **hot**        | temp-hot         | **true**/false |
  > | 6     |          | cool           | temp-cool        | true/**false** |
  > | 7     |          | mild           | temp-mild        | true/**false** |
  > | 8     | humidity | **high**       | humidity-high    | **true**/false |
  > | 9     |          | normal         | humidity-normal  | true/**false** |
  >
  > > Using one-hot encoding to get a 10-bit string eventually:
  > >
  > > 0 0 1 0 0 1 0 0 1 0
  >
  > > Assume we have a 10-bit string as follows:
  > >
  > > **0** 0 1 0 0 1 0 0 **1 1**
  > >
  > > - Multiple phenotypes
  > >   - Rule is certain, it applies to 2 cases: don't play (bit 0 is `0`) when *humidity* is either high or normal.
  > > - Uncertain phenotype
  > >   - Rule is uncertain: *humidity* could be either high or normal and we do not know which (but don't play in either case).
  > > - Uncertain phenotype
  > >   - Rule is invalid: *humidity* cannot be high and normal at the same time.
  
-  Fitness

  - **Fitness** means metric of success.

  - Similar to a **scoring** mechanism, it is a way of measuring how well a rule (or algorithm) performs.

  - Fitness is measured for each candidate solution in a population.

    > e.g.
    >
    > 100 individuals in a population means 100 fitness values.

  - Fitness is **domain dependent**.

- Selection

  - Classic method of selection is probabilistic:
    $$
    \Pr(h_i) = \frac{Fitness(h_i)}{\sum^N_{j=1} Fitness(h_j)}
    $$
    where

    - $N$ is the size of the population,
    - Each $h$ is the representation of a candidate solution,
    - $Fitness(h)$ is the fitness (score) of that candidate

  - This method is called **fitness proportionate selection**, or **roulette wheel selection**.

  - Fitness proportionate selection is **domain independent**.

  - Other methods of selection:

    - Tournament selection:
      - Randomly select two candidates from the population.
      - Keep the candidate with the higher fitness, with probability $p$ proportional to each candidate's fitness (i.e., the more fit candidate is more likely to survive).

    - Rank selection:
      - Sort candidates and rank them according to their fitness.
      - Keep candidates with rank higher than (or equal to) proportion $p$.

    - Tournament selection and rank selection are **domain independent**.

  - Properties

    - In the classic algorithm, a **fixed fitness threshold** is defined.
    - Fixed threshold value is **domain dependent**.
    - We segment the population of $N$ candidates into 2 groups:
      - $P_\text{keep}$ means candidates whose fitness is >= threshold.
      - $P_\text{replace}$ means candidates whose fitness is < threshold. 

    - Probabilistic selection is applied to $P_\text{keep}$. 
      - Fitness proportionate: randomly select candidates from $P_\text{keep}$.
      - Rank: select top $p$ from $P_\text{keep}$.
      - Tournament: randomly select two candidates to compare from $P_\text{keep}$. 

    - The proportion is known as the exploration-exploitation ratio:
      - $P_\text{keep}$ indicates exploitation.
      - $P_\text{replace}$ indicates exploration.

- Reproduction

  - Two main *reproduction operators* are:

    - Crossover
    - Mutation

  - In classic algorithm, where population size is $N$:

    - Crossover rate: $r \in [0, 1]$
    - Mutation rate: $m \in [0, 1]$

  - New population is generated with two steps:
    $$
    \begin{array}{lc}
    \text{first:} & \underbrace{(r \cdot N)}_\text{crossed over} + \underbrace{((1 - r) \cdot N)}_\text{selected as is} \\
    \text{second:} &\underbrace{(m \cdot N)}_\text{mutated} + \underbrace{((1 - m) \cdot N)}_\text{selected as is}
    \end{array}
    $$

- Crossover

  - 1-point crossover

    - Randomly select one bit in two strings, and swap bits from that point.

      > e.g.
      >
      > |      |      |      |      |      |      |       |      |      |      |      |
      > | ---- | ---- | ---- | ---- | ---- | ---- | ----- | ---- | ---- | ---- | ---- |
      > | p1   | 0    | 0    | 1    | 0    | 0    | **1** | 0    | 0    | 1    | 1    |
      > | p2   | 1    | 1    | 1    | 0    | 0    | **0** | 1    | 0    | 0    | 0    |
      >
      > Swap the two parts:
      >
      > |        |      |      |      |      |      |       |      |      |      |      |
      > | ------ | ---- | ---- | ---- | ---- | ---- | ----- | ---- | ---- | ---- | ---- |
      > | offsp1 | 0    | 0    | 1    | 0    | 0    | **0** | 1    | 0    | 0    | 0    |
      > | offsp2 | 1    | 1    | 1    | 0    | 0    | **1** | 0    | 0    | 1    | 1    |
      > 

  - *n*-point crossover: select $n$ points, where $n \leq \text{length of the string}$. 

    - Higher values of $n$ are not very useful, there is too much variation or not enough as $n$ approaches length of string.

  - A common way to specify crossover points is to use a crossover **mask** which indicates which bits should come from which parent.

    > e.g.
    >
    > | mask | 1    | 1    | 1    | 1    | 1    | 0    | 0    |      | 0    | 0    |
    > | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    > | p1   | 0    | 0    | 1    | 0    | 0    | 1    | 0    | 0    | 1    | 1    |
    > | p2   | 1    | 1    | 1    | 0    | 0    | 0    | 1    | 0    | 0    | 0    |

  - Uniform crossover

    - Create mask by randomly selecting bits from each parent, using a *uniform* distribution.
    - Thus, it is equally likely to draw any bit from either parent.

  - Other distributions can be used, for example if you want to weigh certain bits differently from others.

- Mutation

  - 1-point mutation

    - Randomly select one bit in one string and flip it.

      > e.g.
      >
      > |      |      |      |      |      |      |       |      |      |      |      |
      > | ---- | ---- | ---- | ---- | ---- | ---- | ----- | ---- | ---- | ---- | ---- |
      > | p1   | 0    | 0    | 1    | 0    | 0    | **1** | 0    | 0    | 1    | 1    |
      > | p2   | 1    | 1    | 1    | 0    | 0    | **0** | 0    | 0    | 1    | 1    |

  - *n*-point mutation: select $n$ points, where $n \leq \text{length of the string}$. 

##### 9.1.4. Trade-offs

- Definition

  - Classic **trade-offs** when designing genetic algorithms are between the *population size* and the *number of generations* (iterations).

    - A smaller population generally implies more generations are required; but each generation is evaluated relatively quickly.
    - A larger population can mean that fewer generations are required; but each generation can take longer to be evaluated.

  - *Exploration-exploitation* ratio.

    - A higher exploitation ratio means that the set of candidates moves around the solution space (also called *landscape*) more slowly, more smoothly (without jumping around too much from one generation to the next).
      - Solutions in a narrower search space are considered.
      - Search is conducted at a finer resolution.
    - A higher exploration ratio means that the set of candidates jumps around the solution space.
      - Solutions at more disparate points in the search space are considered.
      - Search is conducted at a coarser resolution.

  - Nature vs. Nurture

    > In biology, there is an old debate about whether learnt behaviours are passed from parent to child in their genetic makeup, dating back to Lamarck (late 1800’s). Current biological evidence disavows this view.

    - Computational methods have shown that GAs/GP which learn and pass the learnt information to their offspring can exhibit improved results over parents that do not adapt.

      > e.g.
      >
      > The Baldwin effect:
      >
      > - If the environment is changing, then individuals that can adapt to the changes will survive longer.
      > - Individuals that learn more are comprised, initially, of incomplete genetic code, which fills in as they learn.

    - Note that the inherent adaptivity in an EA is in the changing population (the change in membership) rather than changes in individual members.

##### 9.1.5. Variations

- Real-valued GA
  - Instead of bit string, string contains real numbers.
  - Each number is an actual feature value (i.e., the value of the trait) instead of representing the presence or absence of a trait.
  - **Mutation** randomly changes value (because there is no notion of *flipping*).
  - Everything else works as with bit-string representations.
- Genetic Programming (GP)


---

### 9.2. Genetic Programming (GP)

##### 9.2.1. Introduction to GP

- Definition

  - Variants of GAs.
  - Key difference with GAs is the *representation*.
    - GAs genotype: Binary string of fixed size.
    - GP genotype: Program represented as *tree*.
  -  LISP s-expression.

- Representation

  > e.g.
  >
  > ```mermaid
  > graph TD
  > 	plus((\+)) --> sin((sin))
  > 	sin --> x((x))
  > 	plus --> sqrt((√))
  > 	sqrt --> plus2((\+))
  > 	plus2 --> power((^))
  > 	plus2 --> y((y))
  > 	power --> x2((x))
  > 	power --> 2((2))
  > ```
  >
  > S-expression: `(+ (sin x) (sqrt (+ (pow x 2) y)))`
  >
  > Equation: $\sin x + \sqrt{x^2 +y}$

- Fitness

  - Fitness is determined by running the program:
    $$
    \text{Fitness} = \sin x + \sqrt{x^2 +y}
    $$

  - And then fitness (i.e., value returned by program) can be used directly:

    `if (Fitness >= fitness_threshold)`

    to determine if candidate program belongs to $P_\text{keep}$ or $P_\text{replace}$. 

- Selection

  - Selection is performed in the same way as with GAs:
    - Fitness proportionate selection.
    - Rank selection.
    - Tournament selection.

- Reproduction

  - Koza did not use mutation in his original work, but he did use crossover.
  - With crossover, one (or more) nodes in the tree are selected from two parents; And then the sub-trees starting with those nodes are swapped.
  
  ![Michael Lones : Genetic Programming](https://www.macs.hw.ac.uk/~ml355/common/thesis/jpegimages/subtree_co.jpg)

##### 9.2.2. Code Bloat

- Definition
  - One significant issue with GP is **code bloat**. The size of evolving programs grows extremely large (i.e., the length of the s-expression).
  - Possible solution: limit the maximum length of an s-expression that results from crossover.

---

### 9.3. Co-evolutionary Algorithms

##### 9.3.1. Introduction to Co-evolutionary Algorithms

- Motivation
  - With traditional evolutionary algorithms, we have **one evolving population**. The success of candidate solutions in the population is measured against a fixed fitness function and a fitness threshold.
  - With co-evolution, there are **two evolving populations**.
    - The fitness of a candidate solution is measured by comparing members of opposing populations.
    - The result is an arm's race, where one population (as a whole) reaches to surpass the other population.
- Basic components
  - Representation: could be a GA or a GP.
  - Fitness: members of opposing populations are compared against each other.
  - Selection: same as evolution.
  - Reproduction: same as evolution, but parents are chosen within the same population.

##### 9.3.2. Issues

- Collusion
  - When members of a population *live and let live*.
  - Effectively: nobody tries to win.
  - So each keeps getting better, but nobody becomes the best.
- Mediocre Stable State (MSS)
  - Also called *suboptimal equilibria*.
  - Where the populations settle into a portion of the landscape and do not change, which leads to convergence. 
  - But this might not be the optimal portion of the landscape.

- Examples

  > e.g. Function with one parameter
  >
  > Maximise $f(x) = x^2, x \in [0, 31]$
  >
  > > Representation: 5 bits (`11111` represents 31).
  > >
  > > Fitness function: $f(x)$.
  > >
  > > Example of initial population where the population size is 4.
  > >
  > > | #    | Individual $h$ | $x$  | $f(x)$ | $\Pr(h)$ |
  > > | ---- | -------------- | ---- | ------ | -------- |
  > > | 1    | `01101`        | 13   | 169    | 0.14     |
  > > | 2    | `11000`        | 24   | 576    | 0.49     |
  > > | 3    | `01000`        | 8    | 64     | 0.06     |
  > > | 4    | `10011`        | 19   | 361    | 0.31     |
  > > |      |                |      | 1170   |          |
  > >
  > > Selection: Roulette wheel which gives: `#1`, `#2`, `#2`, `#4`
  > >
  > > Reproduction operators
  > >
  > > | #    | Parents  | Crossover         | Mutation | $x$  | $f(x)$ |
  > > | ---- | -------- | ----------------- | -------- | ---- | ------ |
  > > | 1    | `0110|1` | `01100` (#1 + #2) | `01100`  | 12   | 144    |
  > > | 2    | `1100|0` | `11001` (#1 + #2) | `11001`  | 25   | 625    |
  > > | 3    | `11|000` | `11011` (#3 + #4) | `11011`  | 27   | 729    |
  > > | 4    | `10|011` | `10000` (#3 + #4) | `10010`  | 18   | 324    |
  > > |      |          |                   |          |      | 1822   |
  > >
  > > Minimise the fitness function: $f(x, y, z) = x - xy + 2z, 1 \leq x, y, z \leq 4$
  > >
  > > Representation: 2 bit for each parameter.
  > >
  > > $[x, y, z] \to [XX, YY, ZZ]$
  > >
  > > $\{1,2,3,4,\} \to \{00, 01, 10, 11\}$
  > >
  > > > `011110` -> $x=2, y=4,z=3$ -> $f(x,y,z) = 0$

> e.g.
>
> Wall-following robot
