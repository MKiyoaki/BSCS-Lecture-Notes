## WEEK X - Revision

>[🏠 MENU - 6CCS3CFL](year3/6ccs3cfl.md)
>
>[⬅️ WEEK IX - Optimizations](year3/6ccs3cfl/w9.md)
>
>⏹️
>
>Outlines:

---

## Week 1

### 1.1. Definition

1. Language: 

   - A set of string over alphabet

2. Regular Expressions:

   - Meaning is its languages: the set of strings that it matches. 

   - Base case: 
     - $\textbf{0}$: Nothing
     - $\textbf{1}$: Empty String
     - $c$: Character

   - Inductive case:
     - $r_1+r_2$
     - $r_1 \cdot r_2$
     - $r^*$

3. Concatenation ($s_1 @ s_2$)

   - $A @ \{\} = \{\}$
   - $A @ B \neq B @ A$

4. Power of a language

   - $\_^0$: $\{[]\}$
   - $\_^{n+1}$: $\_ @ \_^n$

5. Number of basic regular expressions that match only $abcd$:

   - Some factors cause infinite number:
     - $\textbf{1}, \textbf{0}$ can be in anywhere
     - Star $\_^*$
     - Alternative choice $\_ + \_$
     - Parentheses $()$

6. Equivalence of regular expression

   - If the language are the same. 
   - e.g., $(a^*b^*)^* == (a + b)^*$

7. Evil Regular Expressions

   - *Evil*: Regular expression matchers that exhibit **exponential** behaviour. 
   - *Catastrophic*: Program continuously backtracks for a large string input leads to crash. 

8. Extended Regular Expression

   - $[c_1 @ c_2]$: Range from $c_1$ to $c_2$, e.g., $[1-9] = 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9\}$
   - $c?$: $c + \textbf{1}$
   - $c^+$: $c \cdot c^*$

### 1.2. Calculation

1. Assume $A, B$ are sets, $|A|=a, |B|=b$, then $|A@B|=a \cdot b$
2. If $A=\{[a],[b],[c],[d]\}$ then $A^4 = 4^4$. 
   If $A = \{[a], [b], [c], []\}$ then $A^4 = 3^4 + 3^3 + 3^2 + 3^1 + 3^0$

---

## Week 2

### 2.1. Definition

1. Extended Regular Expressions

   - Can be defined by basic regular expressions. 

2. Derivative of a string

3. Difference between $Der$ and the notion of derivative of regular expressions:

   - $L(der\ c\ r) = Der \ c \ L(r)$
   - i.e. $der\ c\ r$ is the rest regular expression after removing $c$, $Der\ c\ L(r)$ is the matched languages for the regular expression above (the rest expression after removing $c$). 

4. Derivative of a regular expression $r$

   - function $nullable$
     $$
     \begin{array}{lll}
     \text{nullable}(\textbf{0}) &\overset{def}= &\text{false} \\
     \text{nullable}(\textbf{1}) &\overset{def}= &\text{true} \\
     \text{nullable}(c) &\overset{def}= &\text{false} \\
     \text{nullable}(r_1 + r_2) &\overset{def}= &\text{nullable}(r_1) \vee \text{nullable}(r_2) \\
     \text{nullable}(r_1 \cdot r_2) &\overset{def}= &\text{nullable}(r_1) \wedge \text{nullable}(r_2) \\
     \text{nullable}(r^*) &\overset{def}= &\text{true}
     \end{array}
     $$

   - function $der$
     $$
     \begin{array}{lll}
     \text{der } []\ r &\overset{def}= & r \\
     \text{der } (c::s)\ r &\overset{def}= & \text{der } s\ (\text{der } c\ r)
     \end{array}
     $$

     > If $c = s$ then get $\textbf{1}$ else $\textbf{0}$. 

### 2.2. Calculation

1. Language of Regular Expression (corner cases)
   - $\textbf{0}^* = \textbf{1}$
   - $\textbf{1}^* = \textbf{1}$
   - $a + \textbf{0} = a$
   - $a \cdot \textbf{0} = \textbf{0} \cdot a = \textbf{0}$
2. Prove if $nullable(r) = \text{True}$, prove if $P(Regex(r))$ holds: 
   - Base case and Inductive case. 
3. A regular expression over $\{a, b\}$ contains all strings that do not contain `bb` and end with `a`.
   - `b?.((a.b?)*).a`

---

## Week 3

### 3.1. Definition

1. Python, Java, Ruby are slow in basic regular expressions. Why?
   - Implement matchers via **NFAs**. Backtracking Recursive call has exponential time complexity. 
   - May face evil regular expression problem. 
2. Rust use non-backtracking implementation based on **DFAs**. Still it is slow in some input. Why? 
   - DFAs cannot remember the exact times for repetitions.
   - Long regular expression may lead to a large DFA, which need a large memory space. 
3. Regular Language and DFA:
   - A language is regular iff there exists a **regular expression** that recognises all its strings.
   - A language is regular iff there exists an **DFA** that recognises all its strings.
4. Every finite set of strings is a regular language:
   - Since it can be converted into a regular expresison by constructing a DFA with finite states. 

### 3.2. Calculation

1. From DFA to Regular Expression
   - Subset construction
2. Calculate minimal DFA
   - Draw the table, or
   - Split clusters
3. From Regular Expression to DFA
   - Brzozowski's Method
   - $q = q \cdot r + s \implies q = s \cdot r^*$
4. If a NFA has $n$ states:
   - a DFA need has $2^n$ states to recognize the same langugage as NFA as maximum. 

---

## Week 4

### 4.1. Definition

1. POSIX
   - Longest match rule / Maximal munch rule
   - Rule priority
2. Record regular experssion in Sulzmann & Lu Algorithm:
   - Adds an **identifier** to the regular expression. Helps about what the regular expression matched and helps highlight on particular parts of a string that is match in the regular expression.
   - i.e., For lexer this could help for tokenization. 

### 4.2. Calculation

1. Identify $nullable(\cdot)$ and $zeroable(\cdot)$ for new defined regular expressions.
   - Recursively definition. 
   - Base cases
   - Inductive cases
2. $mkeps$ from Sulzmann & Lu
   - Get the tokens like `Right()` `Left()` `Empty` `Seq()` `Stars[]`, etc. 

---

## Week 5

### 5.1. Definition

1. Define $ALL$
   - $r + \sim r$
   - $\sim \textbf{0}$
2. Specify identifiers with regular expressions as strings, digits and underscores. This can be specified by grammar rules. We need to be careful about:
   - Ensure no clashes in the grammar, i.e., keywords are excluded from the set of identifiers, etc. 
   - Ensure no left-recursion. 

### 5.2. Calculation

1. Show a property $P(r)$ holds for all regular expressions $r$ by structural induction. 

   - Base case:
     - $P(\textbf{0}), P(\textbf{1}), P(c)$ holds
   - Inductive cases:
     - $P(r_1) \vee P(r_2), P(r_1) \wedge P(r_2), P(r) \wedge P(r^*)$ holds

2. Define extended regular expression syntax by basic regular expressions.

3. Give the lexing results for input message. Or check if an input can be lexed or not. 

4. Check if input strings can be accepted by a CFG.

   - Start from $S$ and end by only terminals. 

5. Define regular expressions.

   > e.g., `ID ::= LETTER | LETTER ~ SYMBOL`, etc.

---

## Week 6

### 6.1. Definition

1. Purpose of atomic parsers
   - Simple parsers that transform the input into paris of prefix and suffix. 
   - Recognize a specific prefix in a string or tokens.
2. Purpose of map parsers (semantic actions):
   - Apply a function to the result of the parser.
   - Useful for conversions. 
3. Adventages to first lex a string and then feed a sequence of token to parser
   - Lexers give us a layer of abstraction.
   - Easier to find errors. 
   - Filter the useless tokens. 
   - POSIX provides a standard form. 

### 6.2. Calculation

1. Check if a grammar is ambiguous.
   - Ambiguous: If there will be more than one parsed result.
   - Draw syntax tree. 
2. Define Grammars. 
3. Check if input strings can be accepted by lexer. 
4. Injection for $r_1 \cdot r_2$ matches three cases, why?
   - Since $\text{der }c\ r_1 \cdot r_2$ has two branches (if $nullable(r_1)$)
     - $(\text{der }c\ r_1) \cdot r_2 + \text{der }c\ r_2 \implies \text{inj }(r_1 \cdot r_2)\ c\ (\text{Left}(\text{Seq}(v_1, v_2)))$
     - $(\text{der }c\ r_1) \cdot r_2 \implies \begin{cases} \text{inj }(r_1 \cdot r_2)\ c\ (\text{Seq}(v_1, v_2)) \\ \text{inj }(r_1 \cdot r_2)\ c\ (\text{Right}(v))\end{cases}$

---

## Week 7

### 7.1. Definition

### 7.2. Calculation

1. Context-sensitive Grammar
   - Left to right
   - Start from $S$
   - Substitute until there is only **terminals** (e.g., $abab$, etc). 
2. CYK Algorithm
   - Draw a large table for each term in the sentence. 
   - For a sentence, substitute each term (and the groups of terms by permutation) into non-terminals.
   - See if the final grid can reach $S$. 
3. Chomsky Normal Form
   - All rules are either
     - in the form of $G ::= t$, where $t$ is (a list of) terminals *(a)*, or
     - $G ::= NT_1 | NT_2$, where $NT_1, NT_2$ are non-terminals. *(b)*
   - NO rules should contain $\epsilon$. 
   - Methods: 
     - Substitute $\epsilon$ at first.
     - Extract non terminals in the form of *(a)*. 
     - Substitute the extra non-terminals.
     - Split the Non-terminals with a length more than 2.

---

## Week 8

### 8.1. Definition

1. What kind of optimization can be deployed for WHILE-programs
   - Pruning unused variables
   - Calculating constants
   - Dead code elimination
   - Simplication for assignments are only used once
   - Peep hole optimizaions
2. Difference between *Java assembler* and *Java Byte Code*? 
   - Java assembler: `.j` files. Contains labels to represent locations in the code.
   - Java Byte code: `.class` files. No labels. Only absolute addresses. 
3. Lazy-evaluation and Eager-evaluation
   - Lazy: evaluate expressions when needed. 
   - Eager: evaluate expressions once they appeared. 

### 8.2. Calculation

---

## Week 9

### 9.1. Definition

1. Eliminating tail recursion: Definition, when can be applied, why is it of benefit? 
   - An optimization performed by the compiler on functions whose last executed line is a recursive call of themselves.It converts such recursive calls to iterative loops.
   - It ensures we do not have a stack overflow. 
2. Detect dead code
   - Remove dependencies.
   - Save space for memory.
   - Avoid comparasion to save the CPU from the branch prediction.
   - Avoid thrashing CPU pipeline. 
3. Two Main features of SSA
   - Once variable has been assigned it cannot been reassigned. 
   - Every operation is atomic. 
   - i.e., Thus allows for better compiler optimisations. Take advantage of CPU pipeline. 
4. Parse Tree vs. Abstract Syntax Tree
   - Parse Tree: Gices whole parsed clauses including all symbols, etc.
   - AST: Only necessary information

### 9.2. Calculation

1. JVM code
2. LLVM IR code. 
