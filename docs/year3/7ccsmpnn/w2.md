## WEEK II - Discriminant Functions

>[🏠 MENU - 7CCSMPNN](year3/7ccsmpnn.md)
>
>[⬅️ WEEK I - Introduction to Pattern Recognition](year3/7ccsmpnn/w1.md)
>
>[➡️ WEEK III - Introduction to Neural Networks](year3/7ccsmpnn/w3.md)
>
>Outlines:
>
>1. Discriminant Functions
>2. Learning Decision Boundaries
>3. k-Nearest Neighbours Classifier

### 2.1. Discriminant Functions

##### 2.1.1. Discriminant Functions

- Definition

  - A discriminant function is a scalar function, $g$, defined over the feature vector, $\textbf{x}$. 

  - We define a separate function for each class, $g_i(\textbf{x})$ for $i = 1, ..., c$. 

  - And use the outputs of these functions to make categorization decisions, assign feature vector $\textbf{x}$ to class $\omega_j$ if: $g_j(\textbf{x})>g_i(\textbf{x}) \  \forall i \neq j$. 

    ```mermaid
    graph LR
    	x --> g1
    	x --> g2
    	x --> ...
    	x --> gc
    	
    	g1 --> argmax
    	g2 --> argmax
    	... --> argmax
    	gc --> argmax
    	
    	argmax --> d(decision)
    ```

    > Note
    >
    > Changing the discriminant functions, such that:
    > $$
    > \begin{array}{ll}
    > g_i(\textbf{x}) \leftarrow g_i(\textbf{x}) + a &\forall i \\
    > g_i(\textbf{x}) \leftarrow g_i(\textbf{x}) \cdot b &\forall i, b > 0 \\
    > g_i(\textbf{x}) \leftarrow f(g_i(\textbf{x})) a &\forall i, f \text{ is a monotonically increasing function}
    > \end{array}
    > $$
    > has no effect on classification. 

- Decision Regions and Decision Boundaries

  - Definition

    - Discriminant functions divide feature space into regions. 

      > e.g.
      >
      > ![png](https://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions_files/plot_decision_regions_6_0.png)

    - Regions are separated by boundaries. 

  - Dichotomizers

    - A special case, where we have only two categories.
      - Categorisation rule is
        - assign $\textbf{x}$ to $\omega_1$ if $g_1(\textbf{x}) > g_2(\textbf{x})$,
        - otherwise assign $\textbf{x}$ to $\omega_2$.
    - More conveniently, we can define a single function $g(\textbf{x}) = g_1(\textbf{x}) - g_2(\textbf{x})$. 
      - Categorisation rule is then
        - assign $\textbf{x}$ to $\omega$ if $g(\textbf{x})>0$,
        - otherwise assign $\textbf{x}$ to $\omega_2$.

##### 2.1.2. Linear Discriminant Functions

- Definition

  - A **linear** discriminant function uses a linear combination of feature values:
    $$
    g(\textbf{x}) = \textbf{w}^t \textbf{x} + w_0
    $$
    where

    - $\textbf{x}$ is the feature vector,
    - $\textbf{w}$ is a column vector of parameter or weight values,
    - $w_0$ is a scalar called the bias or threshold weight. 

  - As before, the classification rule is the above. This classifier is called a **Linear Machine**. 

- Decision Boundary

  > e.g.
  >
  > ![Linear Discriminant Analysis (LDA)](https://ml-explained.com/articles/linear-discriminant-analysis-explained/lda_example.png)

- Dichotomizers

  - As before, when we have only two categories, we can define a single function
    $$
    \begin{array}{lcl}
    g(\textbf{x}) &= &g_1(\textbf{x}) - g_2(\textbf{x}) \\
    ~ &= &(\textbf{w}_1^t \textbf{x} + w_{10}) - (\textbf{w}_2^t \textbf{x} + w_{20}) \\
    ~ &= &(\textbf{w}_1 - \textbf{w}_2)^t \textbf{x} + (w_{10} - w_{20}) \\
    ~ &= &\textbf{w}^t \textbf{x} + w_0
    \end{array}
    $$

  - Categorisation rule is then

    - assign $\textbf{x}$ to $\omega_1$ if $g(\textbf{x}) > 0$, otherwise assign $\textbf{x}$ to $\omega_2$, or
    - assign $\textbf{x}$ to $\omega_1$ if $\textbf{w}^t \textbf{x} > 0$, otherwise assign $\textbf{x}$ to $\omega_2$, or

##### 2.1.3. Augmented Vectors

- Definition

  - To simplify maths, *augment* weight and data vectors:

    - Augmentation means to extend a vector (or matrix) by appending elements to it.

  - i.e., Instead of defining $g(\textbf{x}) = \textbf{w}^t\textbf{x} + w_0$, we define $g(\textbf{x}) = a^t y$, where $a=[w_0\ \textbf{w}^t]^t, y = [1 \ \textbf{x}^t]^t$

    > e.g.
    >
    > if $\textbf{w} = \begin{bmatrix} 2 \\ 3 \end{bmatrix}, w_0 = 4, \textbf{x} = \begin{bmatrix}3 \\ 5\end{bmatrix}$, then
    >
    > $g(\textbf{x}) = \textbf{w}^t \textbf{x} + w_0 = \begin{bmatrix}2 & 3\end{bmatrix} \begin{bmatrix}3 \\ 5\end{bmatrix} + 4 = 6 + 15 + 4 = 25$
    >
    > $g(\textbf{x}) = a^t y = \begin{bmatrix}4 &2 & 3\end{bmatrix} \begin{bmatrix}1 \\ 3 \\ 5\end{bmatrix}= 4 + 6 + 15 = 25$

- Linear Discriminant Functions

  - Equivalent ways of defining a linear discriminant function:
    $$
    \begin{array}{lcl}
    g(\textbf{x}) &= &a^t y \\
    g(\textbf{x}) &= &\textbf{w}^t \textbf{x} + w_0\\
    g(\textbf{x}) &= &w_0 + \sum_i w_i x_i
    \end{array}
    $$

   - Location of decision boundary is defined by the weights.
     - The vector normal to the hyperplane points towards feature vectors for which $g(\textbf{x})$ is positive.
     - The value of $g(\textbf{x})$ provides a measure of how far $\textbf{x}$ is from the decision boundary. 
     - These properties are also true for linear discriminant functions in higher-dimensional space.

##### 2.1.4. Generalised Linear Discriminant Functions

- A **linear** discriminant function can be written as:
  $$
  g(\textbf{x}) = w_0 + \sum_i w_i x_i
  $$

  - This allows us to define any arbitrary decision surface in the original feature space, $\textbf{x}$.
  - This is equivalent to defining decision surfaces that are hyperplanes (i.e. linear) in the expanded feature space, $\textbf{y}$. 

- A **quadratic** discriminant function can be written as:
  $$
  g(\textbf{x}) = w_0 + \sum_i w_i x_i + \sum_{i, j} w_{ij}x_iy_j
  $$

  - Can be thought of as a linear discriminant function in an expanded feature space, $g(\textbf{x}) = a^t y$

- Boundaries can now be quadratic curves or hyperquadratic surfaces.

  - Useful, as more complex boundaries may be required for separating classes in some tasks.

---

### 2.2. Learning Decision Boundaries

##### 2.2.1. Perceptron Learning

- Motivation

  - Typically, we only have **training data** and we need to determine the appropriate form of $g(\textbf{x})$ from this data.
  - Only need to consider how to learn linear discriminant functions as we can learn any arbitrary decision surfaces by changing the feature space. 
  - Features
    - Uses **gradient descent** procedures to calculate suitable <u>linear discriminant functions</u>.
    - Learning driven by **misclassified** exemplars.
    - Converges only if data is linearly separable.
    - Solves linear inequalities $a^t \textbf{y}_k > 0 \ \forall k$

- Scheme

  - Given a training dataset $\mathcal{D} = \{(\textbf{x}_1, \omega_1'), ..., (\textbf{x}_n, \omega_b')\}$, we want to determine weights $a_1,a_2, ..., a_m $ such that
    $$
    g_j(\textbf{x}_k) > g_i(\textbf{x}_k), \forall i \neq j \text{ where }j = \omega_k' \text{ for all }k
    $$

  - If solution exists, dataset is **linearly separable**.

  - Two-category Linearly Separable Case

    - ...

- Terminologies

  - Sample Normalisation

    - If we replace all samples from class $\omega_2$ by their negatives (called **sample normalisation**):	
    $$
    \textbf{y} = - \textbf{y} \ \forall \textbf{y} \in \omega_2
    $$
      Then, a sample $\textbf{y}_k$ is correctly classified if:
      - $a^t \textbf{y}_k > 0$ and $\textbf{y}_k$ is labelled $\omega_1$, and 
      - $a^t \textbf{y}_k > 0$ and $\textbf{y}_k$ is labelled $\omega_2$. 
      -  This allows us to ignore class labels and look for a vector $a$ such that $a^t \textbf{y}_k > 0, \forall k$

  - Solutions and Margins

    - There are potentially many possible solutions for $a$ that satisfy $a^t \textbf{y}_k > 0$ but fewer solutions that satisfy $a^t \textbf{y}_k > b, \forall k \text{ where } b>0$. 
  
- Evaluation

  - linearly separable data: converges to solution
  - non-linearly separable data: fails to converge


##### 2.2.2. Perceptron Criterion Function

- Motivation

  - Gradient Descent Procedures
    - Define a cost function $J(a)$ that is minimised if $a$ is a solution vector.
    - This type of problem can be solved by a Gradient Descent Procedure.
    - Basic gradient descent:
      1. Initialise $a$ to arbitrary solution.
      2. Compute gradient vector at $a$, i.e., $∇ J(a)$
      3. Move solution in direction of steepest descent, $a \leftarrow a - \alpha ∇ J(a)$, where $\alpha$ stands for learning rate. 

- Number Misclassified Criterion Function

  - Simplest approach would be to define a cost function based on the number of samples misclassified by $a$.
  - However, this would be piecewise constant and therefore have no gradient to follow (not *convex*).

- Perceptron Criterion Function

  - A better choice is to define a cost function based on the sum of the distances to the decision boundary for all misclassified samples
    $$
    J_p(a) = \sum_{j \in \mathcal{X}} (-a^t \textbf{y})
    $$
    where $\mathcal{X}$ is the set of samples misclassified by $a$. 

- **Batch** Perceptron Learning Algorithm

  - Will only converge if data is linearly separable.

  - Algorithm

    1. Set value of hyper-parameter $\alpha$

    2. Initialise $a$ to arbitrary solution

    3. Compute gradient vector at $a$
       $$
       J_p (a) = \sum_{j \in \mathcal{X}} (-\textbf{y})
       $$

    4. Move solution in direction of steepest descent
       $$
       a \leftarrow a + \alpha \sum_{j \in \mathcal{X}} \textbf{y}
       $$
       Converges when $\mathcal{X}$ is empty, and hence, $∇ J_p \mapsto 0$ (i.e. when no more errors).

    5. Repeat 3. and 4. until converges. 

- **Sequential** Perceptron Learning Algorithm

  - Update based only on single sample errors (updating of weight vector is *sequential* or *online*)
  - Algorithm
    1.  Set value of hyperparameter
    2. Initialise $a$ to arbitrary solution
    3. For each sample $\textbf{y}_k$, in the dataset in turn:
       - If $\textbf{y}_k$ is misclassified, move solution towards $\textbf{y}_k : a \leftarrow a + \alpha \textbf{y}_k$
    4. Repeat 3., run through all samples in turn as many times as necessary for convergence (until all samples correctly classified). 
  - Improvement
    - Perceptron updates move weights towards misclassified exemplars. It only works for exemplars in $\omega_2$ because we applied sample normalisation (multiplied exemplars by -1).
    - Alternatively, we can not use sample normalisation and change the sign of the update rule to move weights
      - towards misclassified exemplars from $ω_1$, then let $\omega_1 = 1$, and
      - away from misclassified exemplars from $ω_2$, then let $\omega_2 = -1$.
    - Batch update rule becomes $a \leftarrow a + \alpha \sum_{y \in \mathcal{X}} \omega' \textbf{y}$
    - Sequential update rule becomes $a \leftarrow a + \alpha \omega_k' \textbf{y}_k$, where $\omega'$ is the class label associated with each misclassified exemplar.

- Multiclass Perceptron Learning Algorithm

  - Assign feature vector $\textbf{x}$ to class $\omega_j$ if: $g_j(\textbf{x}) > g_i(\textbf{x})\ ∀ i \neq j$.
  - If classification is wrong, adjust weights of discriminant functions:
    - move weights forrequired class towards input
    -  move weights of wrongly selected class away from input
  - Algorithm
    1. Set value of hyper-parameter
    2. For each possible class, $c$, initialise $a_c$ to arbitrary solution
    3. For each sample, $(\textbf{y}_k, \omega_k)$ in the dataset in turn:
       - Classify: $c’ = \arg\max g_c(\textbf{x}_k)$
       - If $\textbf{y}_k$ is misclassified (i.e., $c' \neq \omega_k$):
         - Move $a_{\omega_k}$ towards $\textbf{y}_k: a_{\omega_k} \leftarrow a_{\omega_k} + \alpha \textbf{y}_k$
         - Move $a_{c'}$ towards $\textbf{y}_k: a_{c'} \leftarrow a_{c'} - \alpha \textbf{y}_k$

##### 2.2.3. Minimum Squared Error (MSE) Procedures

- MSE Procedures

  - Solves linear equations $a^t\textbf{y}_k = b_k \ \forall k$. 
  - Gives result even if data is not linearly separable. Learning depends on **all** exemplars.
  - Uses matrix inversion (or gradient descent) to calculate suitable linear discriminant functions. 

- MSE via Pseudoinverse

  - Let $Y$ be a matrix, each row of which contains one exemplar, $\textbf{y}^t_k$, from the $k$ training data (in augmented and sample normalised format).

  - Then set of simultaneous linear equations can be expressed in matrix format as:
    $$
    \textbf{Y} a = \textbf{b}
    $$
    

    Typically $\textbf{Y}$ is rectangular, so the solution is given by $a = \textbf{Y}^\dagger \textbf{b}$, where $\textbf{Y}^\dagger$ is the matrix *pseudo-inverse* (or *Moore-Penrose Inverse*). 

- MSE via Gradient Descent

  - The pseudo-inverse provides a closed-form solution to find a which minimizes the squared error:
    $$
    e^2 = \parallel \textbf{Y}a - b \parallel^2
    $$
  - An alternative method to find a solution is to define a cost function $J(a)$ that is to be minimised, and use Gradient Descent.
    $$
    J_s(a) = \frac{1}{2} \parallel \textbf{Y}a - b \parallel^2
    $$

- Widrow-Hoff (or LMS) Learning Algorithm

  - Definition

    - The gradient of the MSE cost function is:
      $$
      ∇ J_s (a) = \textbf{Y}^t (\textbf{Y} a - b)
      $$

    - Hence, the batch update rule is:
      $$
      a \leftarrow a - \alpha \textbf{Y}^t (\textbf{Y} a - b)
      $$

    - The sequential update rule is:
      $$
      a \leftarrow a + \alpha (b_k - a^t \textbf{y}_k) \textbf{y}_k
      $$

  - Algorithm

    1. Set values of hyper-parameters ($\alpha, \theta, b$)
    2. Initialise $a$ to arbitrary solution
    3. For each sample, $\textbf{y}_k$, in the dataset in turn
       - Update solution by sequential update rule. 
    4. Repeat 3., iterate until converage, i.e., $|\sum_k (b_k - a^t \textbf{y}_k) \textbf{y}_k| < \theta$

- Notes on Sequential and Batch Learning

  - If training data consists of $n$ samples:
    - One update of the parameters is based on:
      - n samples with batch learning
      - 1 sample with sequential learning

    - An **epoch** is one pass through all the training data. One epoch corresponds to:
      - 1 parameter update with batch learning
      - n parameter update with sequential learning

  - **Mini-batch** learning is intermediate between sequential and batch learning. 
  - Here it is assumed that sequential learning is performed by selecting samples in a *deterministic* order. However, typically, methods are actually applied by selecting samples at random (*stochastic gradient descent*).


---

### 2.3. k-Nearest Neighbours Classifier

##### 2.3.1. Introduction

- Definition
  - Provides a way to <u>partition feature-space without learning</u>. Classify feature vector, $\textbf{x}$, into the same class as the majority of the $k$ most similar training samples.
    - $k$ is a hyper-parameter that needs to be chosen by the user.
    - For $k=1$ feature values in region around each training sample are given label associated with that sample: feature space is partitioned into Voronoi cells.
  - kNN does not explicitly compute the decision boundary. 
  - Can also succeed when data is multi-modal as well as non-linearly separable

##### 2.3.2. Evaluation

- A simple classification algorithm, only requires:
  - a metric to measure distance
    - Typically Euclidean distance, but others are possible. 
  - a value for hyper-parameter $k$
    - Different values of $k$ produce different partitions (and different class predictions). Results highly dependent on choice. 
    - Do not use *even values* for $k$ to avoid situations <u>where there is no majority for either class</u>. 
    - Using large $k$ value could be 
      - Pros
        - Smoother decision boundaries (smooths over outliers in training data).
        - More probabilistically accurate (prediction based on more samples).
      - Cons
        - May include samples far from $\textbf{x}$ (classification based on irrelevant samples).
        - Increases the computational costs.
- Pros
  - NO training time (*Lazy Training*)
  - Classification accuracy can be excellent if number of samples is very large. 
  - Can work when data is multi-modal, and/or non-linearly separable. 
  - Can use proportion of neighbours in each class to give an estimate of probability that the sample belongs to each class. 
- Cons
  - Large storage requirements (can be ameliorated, by removing samples that are surrounded by other samples from the same class)
  - computationally expensive at run-time (can be ameliorated, by organising data so that only a sub-set needs to be searched to find closest neighbours)
  - number of training samples required increases exponentially with dimensionality of feature space (but this is true of classification methods in general)

