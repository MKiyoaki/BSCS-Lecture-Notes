## WEEK IX - Evolutionary Algorithms

>[ðŸ  MENU - 6CCS3ML1](year3/6ccs3ml1.md)
>
>[â¬…ï¸ WEEK VIII - Reinforcement Learning 2](year3/6ccs3ml1/w8.md)
>
>[âž¡ï¸ WEEK X - Learning from Demonstration](year3/6ccs3ml1/w10.md)
>
>Outlines:
>
>1. 

### 9.1. Genetic Algorithms (GAs)

##### 9.1.1. Introduction to Evolutionary Algorithm (EA)

- Definition
  - An evolutionary algorithm (EA) is a way of doing **search**. It is inspired by evolutionary biology and concepts from genetics.
  - We have a <u>population</u> of individuals where each <u>individual</u> is a representation of a solution to a problem.
  - We build a representation and decide how to combine these representations by doing:
    - Selection, and
    - Reproduction
  - Establishing and evaluating a population can be viewed as a (massively) parallel search.
- Simulation of the Evolution Process.
  - A population of candidate solutions evolves towards better solutions by repeatedly selecting the fit individuals from the current population and modifying them to form the next generation population.

##### 9.1.2. Genetic Algorithms (GAs)

- Overview
  - Loosely based on the idea of simulated evolution: survival of the fittest (Darwin).
  - In general, we hypothesise a *population* of candidate solutions to a particular problem. 
    - We *evaluate* each member of the population to decide how good that candidate is at solving the problem.
    - Then we *select* those members of the population that are the best (the fittest).
    - And we *reproduce* to obtain new members of the population.
    - Then we start all over again, hypothesising with this new set of candidate solutions.
  
- Evaluation

  - Adventages
    - Good for situations where it is difficult to ascertain the impact of a particular partial solution to a problem.
    - Easy to implement through parallel processing, because each candidate solution can be evaluated on its own.
    - Can adapt easily in dynamic environments.

- Basic Algorithm

  ```
  GA(Fitness,Fitness threshold,p,r,m)
  	Fitness: A function that assigns an evaluation score, given a hypothesis. 
  	Fitness threshold: A threshold specifying the termination criterion.
  	p: The number of hypotheses to be included in the population.
  	r: The fraction of the population to be replaced by Crossover at each step. 
  	m: The mutation rate.
  	
  	Initialize: P <- p random hypotheses
  	Evaluate: for each h in P, compute Fitness(h)
  	While [max_h Fitness(h)] < Fitness threshold:
  		Select
  		Crossover
  		Mutate
  		Update
  		Evaluate
  	Return the hypothesis from P that has the highest fitness.
  	
  ```

  - Select

    - Probabilistically select $(1-r)p$ members of $P$ to add to $P_s$.
      $$
      \Pr(h_i) = \frac{\text{Fitness}(h_i)}{\sum^p_{j=1} \text{Fitness}(h_j)}
      $$

  - Crossover

    - Probabilistically select $\frac{r \cdot p}{2}$ pairs of hypotheses from $P$.
    - For each pair $\langle h_1, h_2 \rangle$, produce two offspring by applying the Crossover operator. Add all offspring to $P_s$.

  - Mutate

    - Choose $m$ percent of the members of $P_s$, with uniform probability. For each, invert one randomly selected bit in its representation.

  - Update: $P \leftarrow P_s$

  - Evaluate

    - for each $h$ in $P$, compute $Fitness(h)$.

  - Finally, return the hypothesis from $P$ that has the highest fitness.

##### 9.1.3. Components of the Basic Algorithm

- Components

  - Representation - how is each candidate represented?
  - Fitness - how is each candidate evaluated?
  - Selection - how are the best candidates chosen?
  - Reproduction - how are new candidates generated?

- Representation

  - In a Genetic Algorithm, the classic representation is a *binary string* (or "bit string").

    - Each element in the string represents the presence (or absence) of a particular trait.
    - The bit string is the **genotype**.
    - The set of traits encoded is the **phenotype**.

  - Representation is **domain dependent**.

    > Note that biologists generally do not like this terminology because it only very loosely resembles real genetics.

  - Note that it is possible to generate genotypes that have:

    - Multiple phenotypes
    - Uncertain phenotypes
    - Invalid phenotypes
    
  - Different strategies exist for dealing with the situation of *invalid phenotype*, such as:
  
    - Preventing generation of invalid phenotypes.
    - Reporting lowest fitness for invalid phenotypes.
  
  
  > e.g.
  >
  > | Index | Item     | Value          |                  |                |
  > | ----- | -------- | -------------- | ---------------- | -------------- |
  > | 0     | Play     | yes/**no**     |                  | true/**false** |
  > | 1     | Windy    | true/**false** |                  | true/**false** |
  > | 2     | outlook  | **sunny**      | outlook-sunny    | **true**/false |
  > | 3     |          | overcast       | outlook-overcast | true/**false** |
  > | 4     |          | rainy          | outlook-rainy    | true/**false** |
  > | 5     | temp.    | **hot**        | temp-hot         | **true**/false |
  > | 6     |          | cool           | temp-cool        | true/**false** |
  > | 7     |          | mild           | temp-mild        | true/**false** |
  > | 8     | humidity | **high**       | humidity-high    | **true**/false |
  > | 9     |          | normal         | humidity-normal  | true/**false** |
  >
  > > Using one-hot encoding to get a 10-bit string eventually:
  > >
  > > 0 0 1 0 0 1 0 0 1 0
  >
  > > Assume we have a 10-bit string as follows:
  > >
  > > **0** 0 1 0 0 1 0 0 **1 1**
  > >
  > > - Multiple phenotypes
  > >   - Rule is certain, it applies to 2 cases: don't play (bit 0 is `0`) when *humidity* is either high or normal.
  > > - Uncertain phenotype
  > >   - Rule is uncertain: *humidity* could be either high or normal and we do not know which (but don't play in either case).
  > > - Uncertain phenotype
  > >   - Rule is invalid: *humidity* cannot be high and normal at the same time.
  
-  Fitness

  - **Fitness** means metric of success.

  - Similar to a **scoring** mechanism, it is a way of measuring how well a rule (or algorithm) performs.

  - Fitness is measured for each candidate solution in a population.

    > e.g.
    >
    > 100 individuals in a population means 100 fitness values.

  - Fitness is **domain dependent**.

- Selection

  - Classic method of selection is probabilistic:
    $$
    \Pr(h_i) = \frac{Fitness(h_i)}{\sum^N_{j=1} Fitness(h_j)}
    $$
    where

    - $N$ is the size of the population,
    - Each $h$ is the representation of a candidate solution,
    - $Fitness(h)$ is the fitness (score) of that candidate

  - This method is called **fitness proportionate selection**, or **roulette wheel selection**.

  - Fitness proportionate selection is **domain independent**.

  - Other methods of selection:

    - Tournament selection:
      - Randomly select two candidates from the population.
      - Keep the candidate with the higher fitness, with probability $p$ proportional to each candidate's fitness (i.e., the more fit candidate is more likely to survive).

    - Rank selection:
      - Sort candidates and rank them according to their fitness.
      - Keep candidates with rank higher than (or equal to) proportion $p$.

    - Tournament selection and rank selection are **domain independent**.

  - Properties

    - In the classic algorithm, a **fixed fitness threshold** is defined.
    - Fixed threshold value is **domain dependent**.
    - We segment the population of $N$ candidates into 2 groups:
      - $P_\text{keep}$ means candidates whose fitness is >= threshold.
      - $P_\text{replace}$ means candidates whose fitness is < threshold. 

    - Probabilistic selection is applied to $P_\text{keep}$. 
      - Fitness proportionate: randomly select candidates from $P_\text{keep}$.
      - Rank: select top $p$ from $P_\text{keep}$.
      - Tournament: randomly select two candidates to compare from $P_\text{keep}$. 

    - The proportion is known as the exploration-exploitation ratio:
      - $P_\text{keep}$ indicates exploitation.
      - $P_\text{replace}$ indicates exploration.

- Reproduction

  - Two main *reproduction operators* are:

    - Crossover
    - Mutation

  - In classic algorithm, where population size is $N$:

    - Crossover rate: $r \in [0, 1]$
    - Mutation rate: $m \in [0, 1]$

  - New population is generated with two steps:
    $$
    \begin{array}{lc}
    \text{first:} & \underbrace{(r \cdot N)}_\text{crossed over} + \underbrace{((1 - r) \cdot N)}_\text{selected as is} \\
    \text{second:} &\underbrace{(m \cdot N)}_\text{mutated} + \underbrace{((1 - m) \cdot N)}_\text{selected as is}
    \end{array}
    $$

- Crossover

  - 1-point crossover

    - Randomly select one bit in two strings, and swap bits from that point.

      > e.g.
      >
      > |      |      |      |      |      |      |       |      |      |      |      |
      > | ---- | ---- | ---- | ---- | ---- | ---- | ----- | ---- | ---- | ---- | ---- |
      > | p1   | 0    | 0    | 1    | 0    | 0    | **1** | 0    | 0    | 1    | 1    |
      > | p2   | 1    | 1    | 1    | 0    | 0    | **0** | 1    | 0    | 0    | 0    |
      >
      > Swap the two parts:
      >
      > |        |      |      |      |      |      |       |      |      |      |      |
      > | ------ | ---- | ---- | ---- | ---- | ---- | ----- | ---- | ---- | ---- | ---- |
      > | offsp1 | 0    | 0    | 1    | 0    | 0    | **0** | 1    | 0    | 0    | 0    |
      > | offsp2 | 1    | 1    | 1    | 0    | 0    | **1** | 0    | 0    | 1    | 1    |
      > 

  - *n*-point crossover: select $n$ points, where $n \leq \text{length of the string}$. 

    - Higher values of $n$ are not very useful, there is too much variation or not enough as $n$ approaches length of string.

  - A common way to specify crossover points is to use a crossover **mask** which indicates which bits should come from which parent.

    > e.g.
    >
    > | mask | 1    | 1    | 1    | 1    | 1    | 0    | 0    |      | 0    | 0    |
    > | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    > | p1   | 0    | 0    | 1    | 0    | 0    | 1    | 0    | 0    | 1    | 1    |
    > | p2   | 1    | 1    | 1    | 0    | 0    | 0    | 1    | 0    | 0    | 0    |

  - Uniform crossover

    - Create mask by randomly selecting bits from each parent, using a *uniform* distribution.
    - Thus, it is equally likely to draw any bit from either parent.

  - Other distributions can be used, for example if you want to weigh certain bits differently from others.

- Mutation

  - 1-point mutation

    - Randomly select one bit in one string and flip it.

      > e.g.
      >
      > |      |      |      |      |      |      |       |      |      |      |      |
      > | ---- | ---- | ---- | ---- | ---- | ---- | ----- | ---- | ---- | ---- | ---- |
      > | p1   | 0    | 0    | 1    | 0    | 0    | **1** | 0    | 0    | 1    | 1    |
      > | p2   | 1    | 1    | 1    | 0    | 0    | **0** | 0    | 0    | 1    | 1    |

  - *n*-point mutation: select $n$ points, where $n \leq \text{length of the string}$. 

##### 9.1.4. Trade-offs

- Definition

  - Classic **trade-offs** when designing genetic algorithms are between the *population size* and the *number of generations* (iterations).

    - A smaller population generally implies more generations are required; but each generation is evaluated relatively quickly.
    - A larger population can mean that fewer generations are required; but each generation can take longer to be evaluated.

  - *Exploration-exploitation* ratio.

    - A higher exploitation ratio means that the set of candidates moves around the solution space (also called *landscape*) more slowly, more smoothly (without jumping around too much from one generation to the next).
      - Solutions in a narrower search space are considered.
      - Search is conducted at a finer resolution.
    - A higher exploration ratio means that the set of candidates jumps around the solution space.
      - Solutions at more disparate points in the search space are considered.
      - Search is conducted at a coarser resolution.

  - Nature vs. Nurture

    > In biology, there is an old debate about whether learnt behaviours are passed from parent to child in their genetic makeup, dating back to Lamarck (late 1800â€™s). Current biological evidence disavows this view.

    - Computational methods have shown that GAs/GP which learn and pass the learnt information to their offspring can exhibit improved results over parents that do not adapt.

      > e.g.
      >
      > The Baldwin effect:
      >
      > - If the environment is changing, then individuals that can adapt to the changes will survive longer.
      > - Individuals that learn more are comprised, initially, of incomplete genetic code, which fills in as they learn.

    - Note that the inherent adaptivity in an EA is in the changing population (the change in membership) rather than changes in individual members.

##### 9.1.5. Variations

- Real-valued GA
  - Instead of bit string, string contains real numbers.
  - Each number is an actual feature value (i.e., the value of the trait) instead of representing the presence or absence of a trait.
  - **Mutation** randomly changes value (because there is no notion of *flipping*).
  - Everything else works as with bit-string representations.
- Genetic Programming (GP)


---

### 9.2. Genetic Programming (GP)

##### 9.2.1. Introduction to GP

- Definition

  - Variants of GAs.
  - Key difference with GAs is the *representation*.
    - GAs genotype: Binary string of fixed size.
    - GP genotype: Program represented as *tree*.
  -  LISP s-expression.

- Representation

  > e.g.
  >
  > ```mermaid
  > graph TD
  > 	plus((\+)) --> sin((sin))
  > 	sin --> x((x))
  > 	plus --> sqrt((âˆš))
  > 	sqrt --> plus2((\+))
  > 	plus2 --> power((^))
  > 	plus2 --> y((y))
  > 	power --> x2((x))
  > 	power --> 2((2))
  > ```
  >
  > S-expression: `(+ (sin x) (sqrt (+ (pow x 2) y)))`
  >
  > Equation: $\sin x + \sqrt{x^2 +y}$

- Fitness

  - Fitness is determined by running the program:
    $$
    \text{Fitness} = \sin x + \sqrt{x^2 +y}
    $$

  - And then fitness (i.e., value returned by program) can be used directly:

    `if (Fitness >= fitness_threshold)`

    to determine if candidate program belongs to $P_\text{keep}$ or $P_\text{replace}$. 

- Selection

  - Selection is performed in the same way as with GAs:
    - Fitness proportionate selection.
    - Rank selection.
    - Tournament selection.

- Reproduction

  - Koza did not use mutation in his original work, but he did use crossover.
  - With crossover, one (or more) nodes in the tree are selected from two parents; And then the sub-trees starting with those nodes are swapped.
  
  ![Michael Lones : Genetic Programming](https://www.macs.hw.ac.uk/~ml355/common/thesis/jpegimages/subtree_co.jpg)

##### 9.2.2. Code Bloat

- Definition
  - One significant issue with GP is **code bloat**. The size of evolving programs grows extremely large (i.e., the length of the s-expression).
  - Possible solution: limit the maximum length of an s-expression that results from crossover.

---

### 9.3. Co-evolutionary Algorithms

##### 9.3.1. Introduction to Co-evolutionary Algorithms

- Motivation
  - With traditional evolutionary algorithms, we have **one evolving population**. The success of candidate solutions in the population is measured against a fixed fitness function and a fitness threshold.
  - With co-evolution, there are **two evolving populations**.
    - The fitness of a candidate solution is measured by comparing members of opposing populations.
    - The result is an arm's race, where one population (as a whole) reaches to surpass the other population.
- Basic components
  - Representation: could be a GA or a GP.
  - Fitness: members of opposing populations are compared against each other.
  - Selection: same as evolution.
  - Reproduction: same as evolution, but parents are chosen within the same population.

##### 9.3.2. Issues

- Collusion
  - When members of a population *live and let live*.
  - Effectively: nobody tries to win.
  - So each keeps getting better, but nobody becomes the best.
- Mediocre Stable State (MSS)
  - Also called *suboptimal equilibria*.
  - Where the populations settle into a portion of the landscape and do not change, which leads to convergence. 
  - But this might not be the optimal portion of the landscape.

- Examples

  > e.g. Function with one parameter
  >
  > Maximise $f(x) = x^2, x \in [0, 31]$
  >
  > > Representation: 5 bits (`11111` represents 31).
  > >
  > > Fitness function: $f(x)$.
  > >
  > > Example of initial population where the population size is 4.
  > >
  > > | #    | Individual $h$ | $x$  | $f(x)$ | $\Pr(h)$ |
  > > | ---- | -------------- | ---- | ------ | -------- |
  > > | 1    | `01101`        | 13   | 169    | 0.14     |
  > > | 2    | `11000`        | 24   | 576    | 0.49     |
  > > | 3    | `01000`        | 8    | 64     | 0.06     |
  > > | 4    | `10011`        | 19   | 361    | 0.31     |
  > > |      |                |      | 1170   |          |
  > >
  > > Selection: Roulette wheel which gives: `#1`, `#2`, `#2`, `#4`
  > >
  > > Reproduction operators
  > >
  > > | #    | Parents  | Crossover         | Mutation | $x$  | $f(x)$ |
  > > | ---- | -------- | ----------------- | -------- | ---- | ------ |
  > > | 1    | `0110|1` | `01100` (#1 + #2) | `01100`  | 12   | 144    |
  > > | 2    | `1100|0` | `11001` (#1 + #2) | `11001`  | 25   | 625    |
  > > | 3    | `11|000` | `11011` (#3 + #4) | `11011`  | 27   | 729    |
  > > | 4    | `10|011` | `10000` (#3 + #4) | `10010`  | 18   | 324    |
  > > |      |          |                   |          |      | 1822   |
  > >
  > > Minimise the fitness function: $f(x, y, z) = x - xy + 2z, 1 \leq x, y, z \leq 4$
  > >
  > > Representation: 2 bit for each parameter.
  > >
  > > $[x, y, z] \to [XX, YY, ZZ]$
  > >
  > > $\{1,2,3,4,\} \to \{00, 01, 10, 11\}$
  > >
  > > > `011110` -> $x=2, y=4,z=3$ -> $f(x,y,z) = 0$

> e.g.
>
> Wall-following robot
