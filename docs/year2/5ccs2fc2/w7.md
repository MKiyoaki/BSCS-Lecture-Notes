## WEEK VII - Linear Programming

>[ðŸ  MENU - 5CCS2FC2](year2/5ccs2fc2.md)
>
>[â¬…ï¸ WEEK VI - Approximation and the Travelling Salesman Problem](year2/5ccs2fc2/w6.md)
>
>[âž¡ï¸ WEEK VIII - Linear Programming](year2/5ccs2fc2/w8.md)
>
>Outlines
>
>- Linear Programming - Get the max of mim value
>   - Goal - maximised or minimised a value
>   - Constraints - within some variable to get the solution
> 
>- The Simplex Method *
> - Integer Programming
> 

#### 24. Linear Programming

###### ***Theorem 24.1.*** Linear Programming **LP**

**Linear Objective Function** - The quantity to be maximised / minimised,

**Linear Constraints** - Set of linear inequalities restricting the â€˜feasibleâ€™ solutions.

> e.g. 
>
> Maximise: $2x+3y$
>
> Subject to: $3x+2y \leq 15 \implies 2y-x \leq 5 \implies x+2y \leq 7$

> there may be a unique solution, infinitely many solutions or no solution

**Matrix Notation** - Linear constraints can be represented more succinctly as a matrix-vector equation $A\vec{x}=\vec{b}$

> e.g.
> $$
> \begin{bmatrix} 3 & 2 \\ -1 & 2 \\ 1 & 2\end{bmatrix}\begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 15 \\ 5 \\ 7 \end{bmatrix}
> $$

>**Input)** 
>
>- A set of linear constraints $A\vec{x} \leq \vec{b}$, 
>
>- A linear objective function $f:\mathbb{R}^n \to \mathbb{R}$
>
>**Output)** A solution $x \in (\mathbb{R}^{\geq0})^n$ such that 
>
>1. $\vec{x}$ statisfies the constraints $A\vec{x} \leq \vec{b}$, and
>2. $f(\vec{x})$ is maximal. 

###### ***Theorem 24.2.*** Feasible Region

The **Feasible Region** is the set of all possible solutions satisfying the linear constraints, which could be denoted as $R = \{\vec{x} \in \mathbb{R}^n:\vec{x} \text{ is a solution}\}$

The (set of) **optimal solution(s)**, for a given objective function $f:\mathbb{R}^n \to \mathbb{R}$ is $\{\vec{x} \in R: \forall \vec{y} \in R (f(\vec{x}) \geq f(\vec{y}))\} \subseteq R$

***Example 24.1.*** Balancing Energy Demands

>|               | Natural Gas | Coal | Solar | Wind | Nuclear |
>| :-----------: | :---------: | :--: | :---: | :--: | :-----: |
>| CO2 Emissions |     500     | 1000 |   0   |  0   |    0    |
>|     Cost      |     40      |  80  |  22   |  22  |   120   |
>|   Capacity    |     32      |  8   | 13.5  |  24  |   10    |
>
>Steps:
>
>1. For each mode of energy production introduce a new numerical variable $G,C,S,W,N$ to denote the **energy production (kWh)**. 
>
>2. We must ensure that each mode does not exceed its **capacity**, i.e.,
>
>   $G \leq 32,\ C \leq 8,\ S \leq 13.5,\ W \leq 24,\ N \leq 10$
>
>3. The total energy production must meet the **energy demands**, i.e., 
>
>   $G+C+S+W+N \geq \text{total energy demands}$
>
>4. We also don't want to exceed target **CO2 Emissions**, i.e.,
>
>   $0.5G + 1C \leq \text{target CO2 emissions}$
>
>5. Finally, we want to minimise the **total cost**, i.e., 
>
>   $\text{Minimize } 40G+80C+22S+22W+120N$

---

#### 25. The Simplex Method

###### ***Theorem 25.1.*** Dantzig's Simplex Method

- **Background**

- **Slack Variables**

  We can introduce a slack variable for each constraint, turning each inequality into an equation called the **slack form**. 

  For each choice of the **independent variables** $x, y$, we can calculate the value of the dependent slack variables $s_1,s_2,s_3$. 

  >e.g.
  >
  >$3x+2y \leq 15\\2y-x \leq 5 \\ x+2y \leq 7$ $\implies$ $3x+2y+s_1 = 15 \\ 2y-x+s_2 = 5 \\ x+2y+s_3 = 7$ $\implies$ $s_1=2 = 15-3(3)-2(2) \\ s_2=4 = 5 + (3) - 2(2) \\ s_3=0 = 7 - (3) - 2(2)$ while $x=3, y=2$
  >
  
- **The Cost Variable**

  We can treat the objective function as an equation for some new dependent variable $C$ called the **cost equation**

  > e.g. 
  >
  > $C = 2x+3y$

- **Tableaux** - a matrix representation of a system of linear equations

  >e.g. 
  >
  >Linear Constraints $3x+2y \leq 15\\2y-x \leq 5 \\ x+2y \leq 7$
  >
  >Cost Equation $C = 2x+3y$ 
  >
  >$\implies$ Tableau $\begin{bmatrix}3x+2y &+1s_1 &\ &\ &\  &=15 \\ -1x+2y &\ &+1s_2 &\ & &=5 \\ 1x+2y &\ &\ &1s_3 & &=5 \\ -2x+3y &\ &\ &\ &+1C &=0\end{bmatrix} \implies \begin{bmatrix} 3 & 2 &1 &0 &0 &0 &15 \\ -1 &2 &0 &1 &0 &0 &5 \\ 1 &2 &0 &0 &1 &0 &7 \\ -2 &-3 &0 &0 &0 &1 &0 \end{bmatrix}$
  >
  
- **Steps**

  1. Construct the initial tableau from the slack form of the linear program, together with the equation for the cost $C$. 

  2. Identify the column with the **most negative coefficient** in the final row, corresponding to the objective function. 

     >$\begin{bmatrix} 3 & 2 &1 &0 &0 &0 &15 \\ -1 &2 &0 &1 &0 &0 &5 \\ 1 &2 &0 &0 &1 &0 &7 \\ -2 &-3 &0 &0 &0 &1 &0 \end{bmatrix}$
     >
     >For this matrix, because the minimum value for the last row is $-3$, therefore the second column is the <u>pivot column</u>. 

  3. Calculate the **row equations** by dividing each of the entries in the final column by the entries in the pivot column. 

     >$\begin{bmatrix} 3 & 2 &1 &0 &0 &0 &15 \\ -1 &2 &0 &1 &0 &0 &5 \\ 1 &2 &0 &0 &1 &0 &7 \\ -2 &-3 &0 &0 &0 &1 &0 \end{bmatrix} \implies \begin{matrix} \frac{15}{2} \\ \frac{5}{2} \\ \frac{7}{2} \\ \ \end{matrix}$

  4. Identify the row with the **smallest** row quotient where both the numerator and denominator are **positive**. (i.e. row 2)

  5. The **pivot value** is the value in the pivot column and in the pivot row. Apply the following row transformation: 

     *Pivot row* - $R_{\text{pivot}} \leftarrow (\frac{1}{\text{current pivot value}}) \times R_{\text{pivot}}$
  
     *All non-pivot rows* - $R_i \leftarrow R_i - (\frac{\text{current } R_i \text{ value}}{\text{current pivot value}}) \times R_{\text{pivot}}$
  
     >$ \begin{bmatrix} 3 &2 &1 &0 &0 &0 &15 \\ \textbf{-1} &\underline{\textbf{2}} &\textbf{0} &\textbf{1} &\textbf{0} &\textbf{0} &\textbf{5} \\ 1 &2 &0 &0 &1 &0 &7 \\ -2 &-3 &0 &0 &0 &1 &0 \end{bmatrix} \implies \begin{bmatrix} 4 &0 &1 &-1 &0 &0 &10 \\ -0.5 &1 &0 &0.5 &0 &0 &2.5 \\ 2 &0 &0 &-1 &1 &0 &2 \\ -3.5 &0 &0 &1.5 &0 &1 &7.5 \end{bmatrix}$ 
     >
     >by the following steps: 
     >
     >$R_1 \leftarrow (R_1 - \frac{2}{2}R_2) \\ R_2 \leftarrow \frac{1}{2}R_2\\ R_3 \leftarrow (R_3 - \frac{2}{2}R_2)\\ R_4 \leftarrow (R_4 - \frac{3}{2}R_2)$
  
  6. Repeat until you run out of valid pivot columns
  
     > $\implies \begin{bmatrix} 0 &0 &1 &1 &-2 &0 &6 \\ 0 &1 &0 &0.25 &0.25 &0 &3 \\ 1 &0 &0 &-0.5 &0.5 &0 &1 \\ 0 &0 &0 &-0.25 &1.75 &1 &11 \end{bmatrix} \implies \begin{bmatrix} 0 &0 &1 &1 &-2 &0 &6 \\ 0 &1 &-0.25 &0 &0.75 &0 &1.5 \\ 1 &0 &0.5 &0 &-0.5 &0 &4 \\ 0 &0 &0.25 &0 &2.25 &1 &12.5 \end{bmatrix}$
  
  7. Read off the optimal solution
  
     > $\begin{matrix} &\ &\ &s_1 &+s_2 &+-2s_3 &\ &=6 \\ &\ &y &+-0.25s_1 &\ &+0.75s_3 &\ &=1.5 \\ &x &\ &+0.5s_1 &\ &+0.75s_3 &\ &=4 \\ &\ &\ &0.25s_1 &\ &+2.25s_3 &+C &=12.5 \end{matrix} $
  

###### ***Theorem 25.2.*** (Klee-Minty '72) The worst-case termination time for the Simplex Method exponential. 

$\text{Maximise: } 2^nx_0+2^{n-1}x_1+...+2x_{n-1}+x_n$

$\text{Subject to: }$ $x_0 \leq 5 \\ 4x_0+x_1 \leq 25 \\ ... \  ... \\ 2^nx_0+2^{n-1}x_1+...+2x_{n-1}+x_n \leq 5^{n+1} \\ x_0, x_1,...,x_n \geq 0$

###### ***Theorem 25.3.*** (Khachiyan '79) Linear Programming is solvable in Polynomial Time. 

---

#### 26. Integer Programming

###### ***Theorem 26.1.*** Integer Programming **IP**

>**Input)** 
>
>- A set of linear constraints $A\vec{x} \leq \vec{b}$
>
>- A linear objective function $f:\mathbb{R}^n \to \mathbb{R}$
>
>**Output)** A solution $\vec{x} \in (\mathbb{Z}^{\geq 0})^n$ such that 
>
>1. $\vec{x}$ satisfies the constraints $A\vec{x} \leq \vec{b}$ and
>2. $f(\vec{x})$ is **maximum**

***Example 26.1.*** Maximal Matchings

>Considering there are the following workers and the following tasks,
>
>workers: ðŸŽðŸŽðŸðŸŠðŸŠðŸŠðŸ‰ðŸ’ðŸŒðŸŒ
>
>tasks: *A* (need 4), *B* (need 2), *C* (need 1), *D* (need 2)
>
>1. For each edge $(i,j)$ between worker $i$ and task $j$, let $x_{i,j}$ be a **numerical variable** and add the constraint $x_{i,j} \leq 1 \text{ for all edges }(i, j)$
>2. Construct a constraint for each worker $i \in $ (ðŸŽ, ðŸ, ðŸŠ, ðŸ‰, ðŸ’,ðŸŒ) that 
>3. $x_{i,A}+x_{i,B}+x_{i,C}+x_{i,D} \leq \text{capacity of }i$
>4. Construct a constraint for each **task** $j \in {A, B, C, D}$ that
>
>   $x_{ðŸŽ,j} + x_{ðŸ, j} + x_{ðŸŠ, j} + x_{ðŸ‰, j} + x_{ðŸ’, j}+x_{ðŸŒ, j} \geq \text{requriements for }j$
>5. Add an objective to **maximize** the amount of connections. i.e., $\text{Maximize } \Sigma_{i,j}x_{i,j}$
>6. An optimal solution to the resulting *integer program* correspond to a maximal matching of workers to tasks: 
>
>   $\text{Maximize } \Sigma_{i,j}x_{i,j}$
>
>   $\text{Subject to: }$ $x_{i,j}\leq 1 \text{ for all }i, j \\ \Sigma_{j}x_{i,j} \leq \text{capacity of }i\\ \Sigma_{j}x_{i,j} \geq \text{requriements for }j\\ x_{i,j} \in \mathbb{Z} \text{ for all }i, j$

###### ***Theorem 26.2.*** Integer Programming is **NP-hard**. 

###### ***Theorem 26.3.*** The Boolean Satisfiability **SAT** problem is polynomially reducible to the Integer Programming Problem. 

***Proof.*** 

>Given a formula $F$ in Conjunctive Normal Form. 
>
>1. We want to **construct** an integer program IP$_F$ such that 
>
>   $F \text{ is satisfiable} \iff \text{IP}_F \text{ has an integer solution}$
>
>2. For each propositional variable $P$, let $x_P, x_{\neg P}$ be **numerical variables**
>
>3. Convert each clause into a linear constraint as follows: 
>
>   > $(P \vee Q \vee \neg R) \\ (\neg P \vee Q \vee R) \\ (\neg Q \vee R)$ $\implies$ $(x_P+x_Q+x_{\neg R}) \geq 1 \\ (x_{\neg P}+x_Q+x_R) \geq 1 \\ (x_{\neg Q}+x_R) \geq 1 $
>
>4. For each propositional variable add the following constraint
>
>   >$(x_P+x_{\neg P}) \leq 1 \\ (x_Q+x_{\neg }) \leq 1 \\ (x_R+x_{\neg R}) \leq 1 \\ (x_+x_{\neg S}) \leq 1 $  or  $(x_P+x_{\neg P}) \geq 1 \\ (x_Q+x_{\neg }) \geq 1 \\ (x_R+x_{\neg R}) \geq 1 \\ (x_+x_{\neg S}) \geq 1 $
>
>5. It is easy to verify that
>
>   $F \text{ is satisfiable} \iff \text{IP}_F \text{ has an integer solution}$
>
>   **SAT** $\leq_P$ **IP**
>
>6. Q.E.D.

###### ***Theorem 26.4.*** Branch-and-Bound

>`BRANCH-AND-BOUND(LP):`
>
>1. Find a solution $\vec{a}$ to the linear relaxation of **LP**
>2. **If** $\vec{a} \in \mathbb{Z}^n$ **Return** solution $\vec{a}$
>3. **Else**: 
>   4. Choose a non-integer $x_i = a_i$ on which to branch
>   5. Let $\vec{a}_L$ = BRANCH-AND-BOUND(**LP** $âˆª \{x_i \leq âŒŠa_iâŒ‹\}$)
>   6. Let $\vec{a}_R$ = BRANCH-AND-BOUND(**LP** $âˆª \{x_i \geq âŒŠa_iâŒ‹\}$)
>   7. **If** $f(\vec{a}_L) \geq f(\vec{a}_R)$ **Return** solution $\vec{a}_L$
>   8. **Return** solution $\vec{a}_R$

***Example 26.2.*** 

> 1. Solve the linear relaxation using the Simplex Method
>
>    $\text{Maximise: }2x+3y$
>
>    $\text{Sujbect to: } $$3x+2y \leq 15 \\ 2y-x \leq 5 \\ x+2y \leq 7 \\ x,y \in \mathbb{Z}$ 
>
>    $\implies x=4, y=1.5$
>
> 2. **Branch** on the non-integer value $y = 1.5$ to create two sub-problems by adding the **bounds** $y â‰¤ âŒŠ1.5âŒ‹$ and $y â‰¥ âŒˆ1.5âŒ‰$, respectively.
>
> 3. Recursively apply `Branch-and-Bound` to both sub-problems and return solution which maximises the objective function.
>
>    $x=4, y=1.5, C=12.5 \implies ...$
>
> 4. Compare and return the optimal integral solution from the two sub-problems:
>
>    $x=3, y=2 \implies C=12$ which is better than $x=5, y=0 \implies C=11$

###### ***Theorem 26.5.*** Other Variants of Linear Programming

- Mixed Integer Linear Programming (MILP)
  - Hybrid of an **Integer Program** and a classical **Linear Program**
  - Some variable are required to be integers
  - Others are allowed to take **non-integral** values.
- Zero-one Integer Programming
  - A restriction of Integer Programming
  - All variables can be either *zero* or *one*



