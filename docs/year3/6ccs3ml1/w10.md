## WEEK X - Learning from Demonstration

>[🏠 MENU - 6CCS3ML1](year3/6ccs3ml1.md)
>
>[⬅️ WEEK IX - Evolutionary Algorithms](year3/6ccs3ml1/w8.md)
>
>[➡️ REVISION](year3/6ccs3ml1/re.md)
>
>Outlines:
>
>1. 

### 10.1. Learning from Demonstration

##### 10.1.1. Overview

- Motivation

  - Problem: learn a mapping from (world) state to actions. This mapping is called a policy. Same as in reinforcement learning (RL).
  - In RL, learning is from experience. In Learning from Demonstration (LfD), learning is from examples.
  - LfD is a *supervised* learning of policies.
  - An example in LfD is a sequence of state-action pairs.
    - Model-free learning.
  - The policy is derived only from those states encountered during learning.
  - So the policy is *partial*.

- Definition

  - $S$ is set of states.

  - $A$ is set of actions.

  - Transition function:
    $$
    T(s'|s, a): S \times A \times S \to [0, 1]
    $$

  - $Z$ is observed state, accessed through mapping:
    $$
    M: S \to Z
    $$

    - If state is fully observable, then $M = I$, where $I$ means identity. 

    - Policy selects actions:
      $$
      \pi: Z \to A
      $$

  - Rather like an MDP, but with the extra indirection of:
    $$
    π:Z \to A
    $$
    rather than:
    $$
    \pi : S \to A
    $$

  - **Partially observable.** 

- Varieties

  - In LfD, there is an explicit **teacher** who provides **demonstrations** that the learner trains on.

  - Demonstration $d_j \in D$, such that
    $$
    d_j = \{(z^i_j, a^i_j)\}
    $$
    where $z_j^i \in Z$ and $a_j^i \in A$ and:
    $$
    i = 0, ..., k_j
    $$

  - This is the sequence of state/action pairs discussed above.

  - The set of demonstrations, $D$, is what differentiates LfD from other learning methods.

  - Demonstration-based learning methods include:

    - Learning from Demonstration (LfD)
    - Learning by Demonstration (LbD)
    - Programming by Demonstration (PbD)
    - Learning from Observations
    - ...

- Process

  - Teacher demonstrates execution of some behaviour.
  - Learner receives these demonstrations and derives a policy able to reproduce the demonstrated behaviour.
    - Make design choices
      1. Demonstration approach
      2. Problem space representation
      3. Policy derivation
    - Execution
      1. Gathering examples
      2. Deriving policy

- Design choices

  - Choice of demonstrator
    - 
  - Demonstration technique



##### 10.1.2. Confidence-Based Autonomy



---

### 10.2. 

