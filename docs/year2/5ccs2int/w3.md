## WEEK III - Automated Planning

>[ðŸ  MENU - 5CCS2INT](year2/5ccs2int.md)
>
>[â¬…ï¸ WEEK II - Adversarial Search & Constraint Satisfaction](year2/5ccs2int/w2.md)
>
>[âž¡ï¸ WEEK IV - Handling Uncertainty](year2/5ccs2int/w4.md)
>
>Outlines:
>
>6. Classical Planning
>     - AI Planning Problem
>     - Components
>     - Definition
>7. PDDL
>     - Definition
>     - General Approach for solving planning problems
>     - Fluents
>     - Durative Actions
>8.  Forward Chain Planning and RPG
>    - Forward Chian Planning
>    - Relaxed Planning Graph

### 6. Introduction to Classical Planning

##### 6.1. AI Planning

- Background

  > AI Planning provides hybrid of graph search approach and constraints of CSPs. 
  >
  > Defining problems in a language that allows us to encapsulate the world facts and behaviour.

- General components

  - Formally define the space of all possible problems (the domain) 
    - The relations that exist within the domain. 
    - The actions that can be executed within the domain. 
  - Then formalise specific problems within the domain. 
    - The initial state. 
    - The goal state. 
  - AI planning is general purpose 
    - Define computational problem as planning problem â†’ give it to an AI planner to solve it give it to an AI planner to solve it 
    - Make a better AI planner â†’ give it to an AI planner to solve it solve all kinds of planning problems better 

- Definition

  - Input
    - An **initial state** $I$
    - A **goal state** $G$
    - A **set of actions** $A$â€‹, each with **preconditions** and **effects**. 
  - Output
    - A plan. i.e., a sequence of actions that bring the system from $I$ to $G$â€‹, or
    - Even an optimal plan. *i.e., that is the best way to reach the goal state*. 

- Process

  > Problem Modelling
  >
  > CSPs
  >
  > Automated planning

##### 6.2. The Logistics Domain

- Problem Modelling

  - Need to define
    - The objects involved in the problem
    - The relations between the objects
    - The set of possible actions (with preconditions and effects)
    - A formalism (a language) to describe objects, relations and actions

- From general to specific problem

  - Need to define
    - Initial state
      - all the objects of our problem
      - all the true relations among the objects
    - Goal state
      - all the relations we want to be **true**


---

### 7. PDDL

##### 7.1. General Approach for solving planning problems

- Terminology

  - **Planning Language** - Allows to write definition of a planning problem in text
  - **Planning Algorithm** - Allows to solve any problem given to it in that language.
  - **Planners**

##### 7.2. Planning Domain Definition Language (PDDL)

- Definition

  - Standard language spoken by the planners 
  - Different versions (levels) of PDDL, each one able to handle different features. 

    > e.g.
    >
    > PDDL : propositional planning
    >
    > PDDL2.1 : numbers + time
    >
    > PDDL3 : preferences
    >
    > PDDL+ : continuous change, processes, events

- PDDL Planning Model

  - Described through two files
    1. Domain file
       - General description of the world.
         > e.g., Which types of objects are involved, What actions can be applied, etc ...

    2. Problem file(s)
       - Specific situation you want to solve. 
         > e.g., List of objects, initial state, goal state.
  
- The Gripper Domain

##### 7.3. Fluents - Planning with Number

- Background

  >Original PDDL doesn't handle the idea of resource consumption or the passage of time. *i.e., All actions take uniform time, have no costs.* 
  >
  >PDDL 2.1 is an Extension to PDDL for Expressing Temporal Planning Domains, including numbers, resources, costs (metrics) & time. 

- Fluent

  - PDDL 2.1 introduces the ability to model <u>numeric values</u> through **fluents**.
  - We can identify a particular resource within the **domain** file, 
    - by having action effects increase or decrease the value of that resource, 
    - which more accurately helps maintain an understanding of the costs of actions.
    
    > i.e., Fluent allows for management of resources. *e.g., Check resource within limit, increase/decrease resource, etc.*
    

##### 7.4. Durative Actions - Planning with Time

- Background

  >Fluents allow us to handle resources and their ability to change throughout the execution of a plan.
  >
  >However, we still need to handle the passage of time. This can influence conditions as well as effects of actions since,
  >- Conditions might hold true at different times. 
  >- Effects can occur at different times.

- Durative actions

  - PDDL 2.1 allows for handling of more complex temporal and resource-heavy problems
  - Temporal planning considers how planning must execute within fixed time frames.
    - The overall **Duration** of the action.
    - **Conditions** that must hold true.
      - For the start of the action. i.e., at start. 
      - Until the end of the action. i.e., at end. 
      - Throughout the action. i.e., over all. 
    - **Effects** that will be applied to the state.
      - At the start of the action.
      - Upon completion of the action.

---

### 8. Forward Chain Planning and RPG

>- RPG
>  - RPG provides a heuristic automatically (no domain knowledge)
>    - Lower bound distance to the goal (admissible)
>  - How can we use it in a planner?
>    - Heuristic search (e.g. A*) where $h$ comes from RPG. 
>    - Every time we want to add a new node to the open list, we need to solve a simplified version of the problem (RPG) to find out $h$. 

##### 8.1. Forward Chain Planning

- Process

  - Choose a *state* $s$, and expand it, which will begin with the initial state $S_{init}$
  - Consider the *actions* applicable in $s$â€‹, examine the actions whose preconditions are satisfied in $s$
  - One *successor state* $s'$ is generated for each applicable action $a$â€‹â€‹
    - $S' = S - \{\text{delete effects of }a\} + \{\text{add effects of }a\}$â€‹
    - Create a plan for the state $S'$ by chaining $a$ to the end of the plan for $s$. 
  - A *goal state* is a state containing goal conditions. If state does not satisfy, loop and expand more states. 

##### 8.2. Relaxed Planning Graph

- Planning

  - General Planning tasks
    - A Planner takes all of these and generates a plan. i.e., A sequence of actions from $A$ which will transform $S_{init}$ into $S_{goal}$. 
    - The Planner performs search to consider the different possible plans available until $S_{goal}$ is found.
  - Domain-Independent Planning
    - **Domain-independent heuristics** is <u>the method that defining heuristics for PDDL domain</u>. 

- Relaxed Planning Graph

  - Definition
    - **Relaxed Planning Graph (RPG)** is a *domain-independent heuristic* used in actual planners *(e.g. FF planner)*
    - Involves finding a plan from the current state $S$ which achieves the goals $G$ but ignores the delete effects of each action. 
    - The length of this plan is used as a heuristic value for the state $S$. 
  - Fact & Action Layers
    - The Relaxed Planning Graph (RPG) is made of alternate **fact layers** and **action layers**.
    - **Fact layer** $f(n)$ is used to determine which actions can appear in **action layer** $a(n+1)$
      - Those whose preconditions are satisfied in $f(n)$
      - Fact layers will get bigger and bigger as more actions become applicable. 
        - $f(n+1) = f(n)$, plus all the add effects of the actions in $a(n+1)$
        - We ignore delete effects
  - Constructing the RPG Value
    1. For each state $S$ reached during forward search, 
       - The length of the relaxed plan $P'$ which achieves the goals $G$ starting from $S$ is computed.
       - This is an estimate of the goal distance.
    2. The relaxed solution plan $P'=<O_0, O_1, ..., O_{m-1}>$, 
       - Each $O_i$ is the set of actions **selected in parallel at time step** $i$, and $m$ is the number of the first **fact layer** containing all goals. 
       - $h(s) := \Sigma |O_i|$

         > i.e., heuristic is estimation of the sequential solution length.
