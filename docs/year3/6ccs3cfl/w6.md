## WEEK VI - Parsing Combinators

>[ðŸ  MENU - 6CCS3CFL](year3/6ccs3cfl.md)
>
>[â¬…ï¸ WEEK V - Grammar & Parsing](year3/6ccs3cfl/w5.md)
>
>[âž¡ï¸ WEEK VII - Compilation in JVM](year3/6ccs3cfl/w7.md)
>
>Outlines:
>
>1. Parser Combinators
>2. 

### 6.1. Parser Combinators

##### 6.1.1. Introduction to Parser Combinators

- Definition
  $$
  \underbrace{\text{list of tokens}}_\text{input} \implies \underbrace{\text{set of (parsed and unparsed) input}}_{\text{output}}
  $$

  - A combinator can be used to <u>combine basic parser into a complex parser</u>, while a parse can transfrom a list of token into a set of parsed and unparsed input. 
  - A parse is **successful** whenever the input has been fully â€œconsumedâ€ (that is the second component is empty). 

- Properties

  - They are very easy to implement

  - They can deal with any kind of input as long as this input is of sequence-kind, e.g., string, list, etc.  

    - Scannerless Parsers
      - string => set of (output_type, string)
      - However, using lexers is better because whitespaces or comments can be filtered out; then input is a sequence of tokens. 

  - The output type `T` for the processed part can potentially be different from the input type `I` in the parser. 

    ```scala
    abstract class Parser[I, T] {
    	def parse(in: I): Set[(T, I)]
      
    	def parse_all(in: I) : Set[T] =
    	for ((hd, tl) <- parse(in);
    		if tl.isEmpty) yield hd
    }
    ```

- Types
  - Atomic parsers
  - Sequencing
  - Alternative
  - Semantic action (map-parser)

##### 6.1.2. Types of Parsing Combinators

- Atomic parsers

  - Definition

    - Consume one or more token from the input (stream). If the input string $s$ start with $c$, then return the set with a processed $c$ and the rest of the string, empty set otherwise. 
    - Also works for characters and strings. 
  - Example

    > e.g.
    >
    > number tokens
    >
    > `Num(123) :: rest => {(Num(123), rest)}`

- Alternative parsers

  - Definiton

    - The parser combinators can build larger parsers out of smaller component parsers. 

    - Alternative parsers apply $p$ and also $q$, then combine the outputs. 

  - Notated as `p || q`. 
    $$
    p(\text{input}) \cup q(\text{input})
    $$

- Sequence parser 

  - Definition

    - Apply first $p$ producing a set of pairs, then apply $q$ to the unparsed parts, 
    - Then combine the results. 

  - Notated as `p âˆ¼ q`. 
    $$
    \{((o_1, o_2), u_2) | (o_1, u_1) \in p(\text{input}) \vee (o_2, u_2) \in q(u_1)\}
    $$
    where $o_i$ stands for the output, $u$ stands for unparsed part. 

- Semantic Action (Map parser)

  - Definition

    - Apply $p$ producing a set of pairs
    - Then apply the function $f$ to each first component

  - Notated as `p.map(f)`. 
    $$
    \{f(o_1), u_1) | (o_1, u_1) \in p(\text{input})\}
    $$
    $f$ is the **semantic action**, i.e., what to do with the parsed input. 

- Semantic Actions
  $$
  \begin{array}{lllll}
  \ T âˆ¼ + âˆ¼ E &\implies &\underbrace{f((x, y), z) \implies x + z}_{\text{semantic action}} &~ &\text{Addition} \\
  F âˆ¼ * âˆ¼ T &\implies &f((x, y), z) \implies x * z &~ &\text{Multiplication} \\
  ( âˆ¼ E âˆ¼ ) &\implies &f((x, y), z) \implies y &~ &\text{Parenthesis} 
  \end{array}
  $$

> e.g.
>
> ```scala
> val f = (c: Char) => c.toInt
> val c = new CharParser('c')
> 
> c.parse("cbd")	
> // expected result: Set(('c', "bd"))
> c.map(f).parse("cbd")
> // expected result: Set((99, "bd"))
> ```

##### 6.1.3. p-string-interpolation

- Definition

  - Used as shorthand notation for parser combinators. 

- Example

  > e.g.
  >
  > CFGs for palindromes:
  > $$
  > Pal ::= a \cdot Pal \cdot a | b \cdot Pal \cdot b|a|b| \epsilon
  > $$
  > Each alternative in this grammar translates into an alternative parser combinator.
  >
  > - $\cdot$ can be translated to a sequence parser combinator, and
  > - $a, b, \epsilon$ an be simply written as `p"a"`, `p"b"` and `p""`. 

---

### 6.2. Interpreter

##### 6.2.1. Interpreter and Parser

- Definition

  - Interpreter is used to read the source code line by line (or sentence by setence), and translate it into an executable operation. 
  - We can use combinators to build a flexible parser in handling the input strings. 
  - We can then implement an interpreter basing on a parser. 

- Example

  > e.g. While Language
  > $$
  > \begin{array}{lcl}
  > Stmt &::= &\text{skip} \\
  > ~ &| &id := AExp\\
  > ~ &| &\text{if } BExp \text{ then Block} \text{ else } Block \\
  > ~ &| &\text{while } BExp \text{ do } Block \\
  > Stmts &::= &Stmt; Stmts \\
  > ~ &| & Stmt \\
  > Block &::= &\{Stmts\} \\
  > ~ &| & Stmt \\
  > AExp &::= &... \\
  > BExp &::= &... \\
  > \end{array}
  > $$

##### 6.2.2. Example

> e.g.
>
> Suppose an arithmetic expressions are given by the grammar:
> $$
> \begin{array}{lcl}
> E &::= &E \cdot + \cdot E \\
> ~ &| & E \cdot - \cdot E \\
> ~ &| & E \cdot * \cdot E \\
> ~ &| & ( \cdot E \cdot ) \\
> ~ &| & Number
> \end{array}
> $$
> Naturally we want to implement the grammar in such a way that we can calculate what the result of an artichmetic expression, for instance, `4 * 2 + 3`. 
>
> - We are interested in an Int rather than a string. This means every component parser needs to have as output type `Int`. 
>
> - Strings like `+`, `*` and so on, need to be translated into the appropriate Scala operation like addition or multiplication, etc. 
>
>   ```scala
>   lazy val E: Parser[String, Int] =
>   	((E ~ p"+" ~ E).map{ case ((x, y), z) => x + z} ||
>   	(E ~ p"-" ~ E).map{ case ((x, y), z) => x - z} ||
>   	(E ~ p"*" ~ E).map{ case ((x, y), z) => x * z} ||
>   	(p"(" ~ E ~ p")").map{ case ((x, y), z) => y} ||	
>   	NumParserInt)
>   ```
>
> - In order to prevent left-recursion, we translate the grammar as follows:
>   $$
>   \begin{array}{lcl}
>   E &::= & T \cdot + \cdot E | T \cdot - \cdot E | T\\
>   T &::= & F \cdot * \cdot T | F \\
>   F &::= & ( \cdot E \cdot ) | Number
>   \end{array}
>   $$
>   We can translate this grammar into parsing combinators as follows
>
>   ```scala
>   lazy val E: Parser[String, Int] =
>   	(T ~ p"+" ~ E).map{ case ((x, y), z) => x + z } ||
>   	(T ~ p"-" ~ E).map{ case ((x, y), z) => x - z } || T
>   lazy val T: Parser[String, Int] =
>   	(F ~ p"*" ~ T).map{ case ((x, y), z) => x * z } || F
>   lazy val F: Parser[String, Int] =
>   	(p"(" ~ E ~ p")").map{ case ((x, y), z) => y } || NumParserInt
>   ```

