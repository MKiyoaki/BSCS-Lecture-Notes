## WEEK I - Introduction to AI & Research

>[ðŸ  MENU - 5CCS2INT](year2/5ccs2int.md)
>
>â¹ï¸
>
>[âž¡ï¸ WEEK II -  Adversarial Search & Constraint Satisfaction](year2/5ccs2int/w2.md)
>
>Outlines:
>
>1. Intro to AI
>    - Approaches
>      - Model-based
>      - Data-driven
>    - Types
>      - Autonomous agent
>      - Rational agent
>2. Search Problems
>      - BFS
>      - DFS
>      - Best First Search Idea
>        - UCS (Dijkstra Search)
>3. Heuristic Technology
>     - Greedy Best First Process
>     - A\* Algorithm
>     - Evaluation
>       - Admissibility
>       - Optimality
>

### 1. Introduction to AI

##### 1.1. Approaches to AI

- Intelligent machines

  >| Systems that think like humans       | probabilitySystems that think rationally |
  >| ------------------------------------ | ---------------------------------------- |
  >| Cognitive models of how humans think | Laws from logic, probability             |
  >| Systems that act like humans         | Systems that act rationally              |

  - Definition

    - A system is intelligent if a person cannot distinguish its behavior from a humanâ€™s.

  - Tests

    >Turing test
    >
    >- Let a human ask questions to a system, If the human cannot tell whether the answers were given by a human or machine, it passes the test
    >
    >Total Turing test
    >
    >- A robot is intelligent if a person cannot distinguish its behavior from a humanâ€™s
    >- Includes physical behavior

- Agent

  - Definition

    - A unit that makes an intelligent decision when given the opportunity.
    - Uses knowledge it has at that point in time to make decision.
    - Decision limited by range of actions possible at that point in time.

  - Types

    - **Autonomous agent** - makes decisions <u>without human input</u>.

    - **Rational agent** - always takes the <u>best action at a given point</u>.

      > e.g. a robot, autonomous vehicle, an enemy monster in a game, etc.

##### 1.2. Ways of encoding knowledge

- **Model-Based**

  >i.e., explicit knowledge --> Symbolic/Classical AI

  - Features
    - Define an encoding of what the world looks like.
    - Define how we can change that world.
    - Search for good strategies on how to change the world the way we want to.
    - Pretends to <u>think like a human</u>.

- **Data-Driven**

  > i.e., tacit knowledge --> Machine Learning

  - Reads in coarse data from a specific problem.
  - Is told the problem itâ€™s trying to solve.
  - Changes the model such that it gets the correct output.
  - Pretends to <u>learn like a human</u>.

##### 1.3. AI Evolution

- History of AI

  >1958 - Herbert A. Simon: "within 10 years a digital computer will be the worldâ€™s chess champion".
  >
  >1967 - Marvin Minsky: "within a generation, the problem of creating 'artificial intelligence' will substantially be solved".
  >
  >1997 - IBM's Deep Blue beats Gary Kasparov
  >
  >2016 - DeepMind's AlphaGo defeats Lee Sedol
  >
  >2017 - DeepMind's AlphaZero becomes one of the strongest chess players of all time.
  >
  >2019 - DeepMindâ€™s AlphaStar achieves grandmaster status in StarCraft II.
  >
  >However, true general intelligence still a long way off.

- AI in the Modern World

##### 1.4. Value alignment problem

>1. How to align the values of your system with those of humans who use and are impact by the system?
>2. How to exactly specify what a "good" *(song recommendation / conversation / game experience, etc. )* is?
>
>| Human                                | AI                             |
>| ------------------------------------ | ------------------------------ |
>| Self-directed Goals                  | Statistical reasoning          |
>| Common sense                         | Large-scale maths              |
>| Learn from few examples              | Huge state-space exploration   |
>| Adapt to similar but different tasks | Computational power (at scale) |
>| Emotional intelligence               |                                |

---

### 2. Search Algorithms I

##### 2.1. Search Problems

- Goal - Process of computing a sequence of actions that form a path to a goal.

- Parameters

  - State space
  - Initial state & goal test
  - Actions
  - Transition model
  - Action costs

- Examples

  > e.g.
  >
  > Navigate from A to B, Self-service checkout, etc.

##### 2.2. Search Trees & Search Algorithms

- Search Tree

- Search Algorithms

  - Most search algorithms use a search tree to find a path from the initial state until a goal state.
  - Different algorithms use different strategies to find a path.

##### 2.3. BFS & DFS Algorithms

- Breadth-First Search BFS

  > BFS uses a **search tree** to find solution to search problem. Search the tree in same-depth slices, skip already reached states. 

  - Process

    >![BFS Example Solution - Breadth First Search Algorithm - Edureka](https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2019/09/BFS-Example-Solution-Breadth-First-Search-Algorithm-Edureka-1.png)

  - Pseudocode

    >```
    >Input: s as the source node
    > 
    >BFS (G, s)
    >let Q be queue.
    >Q.enqueue( s )
    > 
    >mark s as visited
    >while ( Q is not empty)
    >v = Q.dequeue( )
    > 
    >for all neighbors w of v in Graph G
    >if w is not visited
    >Q.enqueue( w )
    >mark w as visited
    >```
  
  - Properties

    - Completeness - âœ…

      > Is the algorithm guaranteed to find a solution when there is one? 

    - Optimality - âœ…

      > Does the algorithm find the optimal solution? 

    - Complexity

      > $b$â€‹ stands for branching factor
      >
      > $d$ stands for the level of the goal
  
      - Time - $\sum\limits_{i=1}^{d}b^i$
      - Space - $\sum\limits_{i=1}^{d}b^i$
  
- Depth-First Search DFS

  > DFS uses a **search tree** to find solution to search problem. DFS expands deepest nodes first.

  - Process
  - Properties
    - Completeness - âœ…
    - Optimality - âŒ

      > Regardless of depth or cost.

    - Complexity

      >$b$ stands for branching factor
      >
      >$m$ for maximum depth of the tree

      - Time - $\sum\limits_{i=1}^{d}b^m$
      - Space - $b \cdot m$


##### 2.4. Best-First Search & Uniform Cost Search

- Best-First Search

  - Idea
    - Keep a *priority queue* of nodes to explore, **ordered by a value $f$**. At each iteration we **pick the node with the next lowest $f$** value
  - Process
    1. Define a value function $f(n)$, keep a *priority queue* of nodes ordered by $f$
    2. At each iteration: expand the node at the front of the queue.
    3. Stop when a goal node is expanded.
  - Properties
    - Completeness
    - Optimality
    - Complexity
      - Time
      - Space

- Uniform Cost Search UCS

  - Idea
    - Expand best node first, where "best" means reached by lowest cost.
    - Best-first search with $f(n)=\text{sum of costs of actions from start to }n$
      Finds minimum-cost plans
  - Process
    1. Define $g(n) = \text{the cost of the path}$, from the initial state to $n$
    2. Run Best First Search with $f(n)$ = $g(n)$
    3. Guaranteed to find a shortest path to a goal node
  - Properties
    - Completeness - âœ…
    - Optimality - âœ…
    - Complexity
      - Time - $\text{cost < cost of goal}$
      - Space -  $\text{cost < cost of goal}$

---

### 3. Search Algorithms II

##### 3.1. Building Heuristic

- **Heuristic**
  - A rule of thumb that gives us useful information about our distance to the goal state. 
  - A technique designed for problem solving more quickly
    - when classic methods are too slow for finding an exact or approximate solution, or 
    - when classic methods fail to find any exact solution in a search space. 
- Heuristic Function

  - A function that ranks alternatives in search algorithms at each branching step based on available information to decide which branch to follow. 

##### 3.2. Greedy Best First Process & A* Search

- Greedy Best First Process

  - Process
    - A component of $f(n)$ is the heuristic function $h(n)$ 
    - $h(n)=\text{estimated cost of the cheapest path from }n \text{ to a goal state}$
    - If $n$ is a goal node, then $h(n)=0$â€‹
    
    > i.e., GBFS will only consider the heuristic value between current node and the goal node to evaluate the Best first search. 

- A* Search

  - Process
    - Find the path that $f(n) = g(n) + h(n)$
      - $g(n)=\text{cost from the initial state to }n$
      - $h(n)=\text{estimated distance of } n \text{ from the goal state}$
      - $f(n)=\text{estimated cost of the cheapest solution through }n$
    - Choose state with the **lowest value** of $f(n)$â€‹
    
    > i.e., A\* will consider both the heuristic value between current node and the goal node, and the cost from the initial node, which is like the combination of UCS and GBFS. 

##### 3.3. Admissibility & Optimality

- Admissibility

  - A heuristic function is said to be **admissible** (or an **admissible heuristic** ) if it never over-estimates the cost of reaching the goal. 
  - i.e., <u>The actual distance is always >= than the heuristic value (the cost it estimates to reach the goal)</u> 

    > e.g., straight-line distance is admissible

- Optimality - Given an admissible heuristic A\* will find optimal solutions

  - A heuristic that assigns $0$ to each node is **admissible**, but recreates uniform cost search (as it does not provide any real guidance). 
  - Key challenge
    - Finding a heuristic which is both admissible and informative
    - Often we **relax** the constraints of the problem to come up with useful heuristics.

      > e.g., straight-line vs following topography of map.
