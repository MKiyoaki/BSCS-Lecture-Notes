## WEEK IV - Graph Algorithm

> [üè† MENU - 5CCS2FC2](year2/5ccs2fc2.md)
>
> [‚¨ÖÔ∏è WEEK III - The Cook-Levin Theorem / Divide-and-Conquer](year2/5ccs2fc2/w3.md)
>
> [‚û°Ô∏è WEEK V - SAT Solving](year2/5ccs2fc2/w5.md)
>
> Outlines: 
>
> - Graph Algorithm
>   - BFS - $O(|V|+|E|)$
>   - DFS - $O(|V|+|E|)$
>   
>   - Topological Sorting
>   - Strongly Connected Components
>   
> - MST
>   
>   - Kruskal's MST - select shortest edge - $O(|E| \log |E|)$
>   - Prim's MST - select node - $O|E|+|V | \log |V |$
>   

### 14. Introduction to Graph Algorithm

> ref: 
>
> [Graph Theory and Algorithm - OI Wiki](https://oi-wiki.org/graph/)

##### ***Theorem 14.1.*** Graph Algorithms

We expand the notation for the **termination time** for algorithms on graphs: 

$T(|V|, |E|)=\text{The number of primitive operations on a graph with }|V|\text{ vertices and }|E|\text{ edges}$

Our **primitive operations** we can perform in $O(1)$ steps. 

##### ***Theorem 14.2.*** Bredth First Search Algorithm (BFS)

>`BREDTH-FIRST-SEARCH: `
>
>1. Select root vertex and add to a *queue*
>2. While the *queue* is not-empty: 
>   3. Inspect the first element $u$ on the *queue*.
>   4. Add any unvisited neighbours of $u$ to the *queue*.
>   5. Remove $u$ from the *queue*. 

The termination time for **BFS** is $O(|V | + |E|)$.

***Proof.*** 

>1. Note that every vertex is enqueued and dequeued at most once. So *Steps 3. ‚Äì 5.* are repeated once for each $u \in V$ .
>
>2. Inspecting *(Step 3. )* and Adding *(Step 5. )* each take at most $O(1)$ operations.
>
>3. However, *Step 4.* requires $O|\text{Adj}(u)|$ operations to queue each of the adjacent vertices to u. 
>
>   (where $\text{Adj}(u)$ denotes the set of verticies adjacent to $u$)

##### ***Theorem 14.3.*** Depth First Search Algorithm (DFS)

>`BREDTH-FIRST-SEARCH: `
>
>1. Select root vertex and add to a *stack*
>2. **While** the *stack* is not-empty: 
>   3. Inspect the first element $u$ on the *stack*.
>   4. Add any unvisited neighbours of $u$ to the *stack*.
>   5. Remove $u$ from the *stack*. 

The termination time for **DFS** is $O(|V | + |E|)$.

***Proof.*** Same as **BFS**. 

---

### 15. Topological Sorting & Strongly Connected Components

>ref: 
>
>[Topological Sorting - geeksforgeeks](https://www.geeksforgeeks.org/topological-sorting/)
>
>[Strongly Connected Components - geeksforgeeks](https://www.geeksforgeeks.org/strongly-connected-components/)

##### ***Theorem 15.1.*** Directed Acyclic Graphs (DAGs)

A graph $G = (V, E)$ is said to be a **directed acyclic graph** if 

- It is **irreflexive**, and
- Does not contain any **cycles** of length $\geq 2$

> i.e., If there is a path $u \leadsto v$ then there is no path $v \leadsto u$

***Example 15.1.*** [Software Dependency Graphs](https://cxf.apache.org/docs/cxf-dependency-graphs.html)

##### ***Theorem 15.2.*** Topological Sorting

A **topological sorting** of a **Directed Acyclic Graph** $G = (V, E)$ is an ordered list of vertices $L = ‚ü®v_1,v_2,...,v_n‚ü©$ such that

$\text{if } v_i \leadsto v_j \text{ then } i<j \text{, for all }i,j \leq n$

<img src="https://upload.wikimedia.org/wikipedia/commons/e/e2/Parallel_Topological_Sorting.gif" alt="undefined" style="zoom:50%;" />

> i.e., all the arrows point ‚Äòdownstream‚Äô from $v_1$ to $v_n$

>`TOPOLOGICAL-SORT(G): `
>
>1. **While** verticies remain unsorted: 
>  2. Select any unsorted vertex and add to a *stack*
>   3. **While** *stack* is not-empty: 
>         4. Inspect the top element $u$ on the *stack*.
>      5. **If** $u$ has no unsorted neighbours: 
>        6. Pop $u$ from the *stack* and add to list $L$.
>      6. **Else**: 
>         7. Add any unsorted neighbours of $u$ to the *stack*. 
> 
>8. **Return** sorted list $L$. 

##### ***Theorem 15.3.*** Strongly Connected Components

- Strongly Connected Component (SCC)

  We can define an binary relation $‚àº ‚äÜ V √ó V$ on the set of vertices such that

  $u ‚àº v \iff u=v \text{ or there is a path } u \leadsto v \text{ and a path } v \leadsto u$

  - A strongly connected component is a **maximal subset** $C ‚äÜ V$ , such that

    $u ‚àº v \text{ for all }u,v \in C$

    $[u]_{‚â°}=\{v \in V : v ‚àº u\}$
    
    > i.e., If every vertice could be connected by every vertice on the graph, then the graph is strongly connected. 

- Component Graph

  The **component graph** of $G$ is a new graph $G^{SCC}=(V^{SCC}, E^{SCC})$, where

  $V^{SCC}=\{\text{all strongly connected components of }G\}$

  $(A,B) \in E^{SCC} \iff (a,b) \in E \text{ for some }a \in A \text{ and } b \in B,\text{ where } A \neq B$

##### ***Theorem 15.4.*** The component graph $G^{SCC}$ is a directed acylic graph, for any directed graph $G$. 

***Proof.*** 

>1. Suppose, for contradiction, that there is a cycle $‚ü®C_1, C_2, ... , C_n, C_{n+1}‚ü©$: 
>2. Choose any $a \in C_i$ and $b \in C_i$  for some $C_i \neq C_j$. 
>3. It follows that there must be a path $a \leadsto b$ and $b \leadsto a$. 
>4. Hence, by contradiction, $G^{SCC}$ cannot contain any cycles as required. 
>5. QED. 

##### ***Theorem 15.5.*** Finding Strongly Connected Components

>`SCC(G): `
>
>1. Call `TOPOLOGICAL-SORT(G)` to generate ordered *list* $L$. 
>2. **While** $L$ is not-empty: 
>
>   3. Inspect the first element $u$ in the list.
>
>   4. Perform `DFS` on the transpose graph $G^T$ from $u$. 
>
>   5. Add all visited vertices to a new component $S$. 
>
>   6. Remove these vertices from the list $L$. 
>3. **Return** all components identified. 

---

### 16. Minimum Spanning Trees

>ref: 
>
>[Prim's Algorithm - geeksforgees](https://www.geeksforgeeks.org/prims-minimum-spanning-tree-mst-greedy-algo-5/)

##### ***Theorem 16.1.*** Spanning Tree

- A **spanning tree** for a weighted graph $G = (V,E,w)$ is a tree $T = (V,E^‚Ä≤)$ in which each vertex is connected and $E^‚Ä≤ ‚äÜ E$, 
- A **minmum spanning tree** is a spanning tree whose weight is minimal out of all possible spanning trees. 

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/4x4_grid_spanning_tree.svg/1920px-4x4_grid_spanning_tree.svg.png" alt="undefined" style="zoom: 25%;" />

##### ***Theorem 16.2.*** Kruskal‚Äôs Minimum Spanning Tree Algorithm

Find the MST by checking the shortest edge by using sorted list. 

>`KRUSKAL-MST (G): `
>
>1. Sort the edge *list* $E$ by weight (shortest first)
>
>2. Initialise the set $T = ‚àÖ$
>
>3. **While** sorted list $E$ is not-empty:
>
>   4. Dequeue the shortest edge $(u, v)$ from $E$. 
>   5. **If** $T \cup \{(u, v)\}$ is acyclic: 
>      6. Update $T ‚Üê T\cup{(u,v)}$.
>
>   7. **Return** tree $T$

The termination time for Kruskal‚Äôs Algorithm is $O(|E| \log |E|)$. (So the number of $E$ affect the effeciency)

***Proof.*** 

>1. For *Step 1.* we need to sort $E$ which can be done via **merge-sort** or some other efficient sorting algorithm: 
>
>   $\text{time to sort }E\text{ by weight}=O(|E|\log|E|)$
>
>2. For *Step 4.* and *6.* are primitive and take $O(1)$ steps, for each iteration $(u,v)\in E$. 
>
>   $\text{total time for Step 4. and 6.}=\sum_{E}(O(1)+O(1))=O(|E|)$
>
>3. *Step 5.* can be performed by checking whether $u$ and $v$ are already connected, since a second connection would create a cycle. 
>
>   $\text{total time to check connectedness}=O((|V|+|E|)\alpha(|V|))$
>
>   where $\alpha$ is a very very slow growing function that we can forget about. 
>
>4. Hence, the total worst-case termination time is given by
>
>   $T(V,E)=O(|E|\log|E|)+O(|E|)+O((|V|+|E|)\alpha(|V))$

##### ***Theorem 16.3.*** Prim‚Äôs Minimum Spanning Tree Algorithm

Find the MST by checking each node and using PQ to sort. 

>`PRIM-MST(G): `
>
>1. Select a root node $r \in V$ and all adjacent edges to a *priority queue* $Q$
>2. Initialise the set $T=‚àÖ$
>3. **While** *queue* $Q$ is not-empty: 
>   4. Dequeue shortest edge $(u,v)$ from $Q$
>   5. If $T \cup \{(u,v)\}$ is acyclic: 
>      6. Update $T‚ÜêT\cup\{(u,v)\}$.
>      7. Add to $Q$ any new edges adjacent to $u$ or $v$. 
>
>8. **Return** Tree $T$ 

The termination time for Prims‚Äôs Algorithm is $O|E|+|V | \log |V |$. (So the number of $V$ affect the effeciency)

***Proof.*** 

>1. Subject to the data structure used for maintaining the *priority queue*.
>2. Utilising a data structure called a *Fibonacci Heap*, we can obtain the above complexity bound. 