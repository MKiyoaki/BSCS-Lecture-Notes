## WEEK IV - Application of Automata

>[üè† MENU - 6CCS3COM](year3/6ccs3com.md)
>
>[‚¨ÖÔ∏è WEEK III - Turing Machine](year3/6ccs3com/w3.md)
>
>[‚û°Ô∏è WEEK V - Revision I](year3/6ccs3com/w5.md)
>
>Outlines:
>
>1. Compilation Process
>2. Parsing

### 4.1. Compilation Process

##### 4.1.1. Syntactic analysis

- Terminology

  - Syntactic analysis: Checks whether a program is syntactically correct.
    - **Lexical analysis**: Programs are decomposed into tokens. 
    - **Parsing**: Tokens are checked to ensure they form a word that belongs to the programming language.
  - In later phases, the compiler checks types (if the programming language is typed), generates code, performs optimisations, etc.

  ```mermaid
  graph TD
  	S[Source Code]
  	S --> Lexing((Lexing))
  	Lexing --> T[Tokens]
  	T --> Parsing((Parsing))
  	Parsing --> AST[Abstract Syntax Tree]
  ```

- Parser

  - A **parser** reads a sequence of tokens and builds a parse tree (or derivation tree), outputting an abstract syntax tree.
  - In practice, a parser also performs broader error detection and correction.
  - Two types of parsers:
    - Top-down: **Recursive descent parsing (RDP)**
    - Bottom-up: **Shift-reduce**

##### 4.1.2. Lexical Analysis

- Definition

  - A lexer reads a string and converts it to a sequence of tokens. 

    > Note. Can be done by a finite automaton. 

  - In practice, it will also:

    - remove whitespace and tabs (once recognised);
    - remove comments (once recognised);
    - (limited) error detection and correction; 
    - marcro expansion.

- Examples

  > e.g.
  >
  > - Arithmetic:
  >
  >   `3 + 4.5 ‚àó 67 => NUM(3) PLUSOP NUM(4.5) MULTOP NUM(67)`
  >
  > - Human languages:
  >
  >   `VERB(eats) VERB(shoots) AND VERB(leaves)?`
  >
  > - Programming languages:
  >
  >   `Integer myNum = 4.5;`

- Tokens of a programming language

  - Keywords

    > e.g, `if`, `else`, `while`, `do`, `int`

  - Operators

    > e.g. `+` `-` `*` `/` `!` `||` `++`

  - Punctuation

    > e.g. `()` `;` `{}`

  - Variables names

    > e.g. `myNum`

  - Literals

    > e.g. `"hello world"`

  - Constants

    > e.g. `42`, `3.1415`, `0x4D1`

  - Comments

    > e.g. `/* ... */` are erased by the lexical analyser

  - White space is ignored. 

- Errors

  - What if a word doesn‚Äôt belong to any token language

    - Can attempt to make modifications until the word fits. 

      > e.g. 
      >
      > remove a character, add a character, swap characters...
      >
      > `42. => 42.0`

  - What if a word belongs to more than one token language

    - Multiple sequences of tokens are produced.

  - What if the token order doesn't make sense

    - A lexical analyser can‚Äôt recognise this, as it has only a localised view, and does not understand the wider syntactical structure.
    - This is the job of the parser.

##### 4.1.3. Regular Expression

- Defining Tokens

  - Explicit sets
  - Finite automata
  - Regular expressions
    - Regular expressions and finite automata can both represent **regular languages**.

- Regular Expression

  - A **regular expression** $r$ denotes a language $L(r)$. 

    - Recall, a language is a set of acceptable words.

  - Formation rules for regular expressions over alphabet $X$:

    - $Œµ$ denotes $\{Œµ\}$.

    -  $a$ denotes $\{a\}$, for any symbol $a ‚àà X$. 

    - Suppose $r, s$ are regular expressions:

      - $(r)|(s)$ denotes $L(r) \cup L(s)$; this is some times written as $(r) + (s)$. 

      - $(r)?$ denotes $(r)|Œµ$. 

      - $(r)(s)$ denotes $L(r)L(s)$. 

      - $(r)^*$ denotes $L(r)^*$

        > i.e., $Œµ|r|rr|...$

      - $(r)^+$ abbreviates $(r)(r)^*$. 

    - Conventions:

      - Drop all unnecessary parentheses, all operators are left associative, Precedence: $*$, concatenation, $|$. 
      - Use abbreviations, including character classes: `[a-z] = a | b | ... | z`

  - Example

    > e.g.
    >
    > Let $X = \{a, b\}$.
    >
    > | Regular Expression $r$ | Language $L(r)$           |
    > | ---------------------- | ------------------------- |
    > | `aba`                  | `{aba}`                   |
    > | `(a|b)(a|b`)           | `{aa, ab, ba, bb}`        |
    > | `a | (bb) | (aba)`     | `{a, bb, aba}`            |
    > | `a*`                   | `{Œµ, a, aa, aaa, ...}`    |
    > | `a+`                   | `{a, aa, aaa, ...}`       |
    > | `(ab)+`                | `{ab, abab, ababab, ...}` |

- Algebraic rules for regular expressions
  $$
  \begin{array}{lcl}
  r|s &= &s|r \\
  (r|s)|t &= &r|(s|t) \\
  (rs)t &= &r(st) \\
  r(s|t) &= &rs|rt \\
  Œµr &= &r \\
  rŒµ &= &r \\
  r^‚àó &= &(r|Œµ)^‚àó \\ 
  r^{‚àó‚àó} &= &r^‚àó
  \end{array}
  $$

  > e.g.
  >
  > Show that `(a|b)* = (a*b*)*`. 
  >
  > > ...

- Regular Definition

  - A **regular definition**, over an alphabet $X$, is a sequence of definitions:
    $$
    \langle d_0 \rangle \to r_0 \\
    \langle d_1 \rangle \to r_1 \\
    ... \\
    \langle d_n \rangle \to r_n
    $$
    where each $d_i$ is a distinct name, and each $r_i$ is a regular expression over $X \cup \{d_0,...,d_{i‚àí1}\}$

  - Symbols in $X$ are called **terminals**.

  - $\{d_0,...,d_n\}$ are called **non-terminals**.

    > e.g.
    > $$
    > \begin{array}{lcl}
    > \langle \text{digit} \rangle &\to & 0|1|...|9 \\
    > \langle \text{digits} \rangle &\to & \langle \text{digit} \rangle \langle \text{digit} \rangle^* \\
    > \langle \text{fraction} \rangle &\to & . \text{digits} | \epsilon \\
    > \langle \text{number} \rangle &\to & \langle \text{digit} \rangle \langle \text{fraction} \rangle
    > \end{array}
    > $$
    > 

##### 4.1.4. Lexical Analyser

- Definition
  - The lexical analyser recognises tokens defined by regular expressions. For each regular expression there is a corresponding automaton. Each accepting state recognises a token.
- Programming and Tools
  - A finite automaton can be converted to code in our favourite programming language.
  - There are many tools available to build lexical analysers:
    - Lex, JLex, MLLex, etc.

----

### 4.2. Parsing

##### 4.2.1. Top-down Parsing

- Definition

  - Slogan for top-down parsing:

    > Starting from the start symbol, search for a rule that rewrites the non-terminals to yield terminals consistent with the input.

- Algorithm

  - Steps
    - Assume that input is derived from start symbol: `stat`
    - Examine each alternative rule for `stat`
    - Compare first unmatched token with first symbol on RHS of each alternative rule for `stat`
    - If a matching production is found, use it to rewrite `stat`
    - Repeat, using next input token to determine the rule to be used for the next non-terminal.
    - If no match, try a rule that begins with a non-terminal (e.g. `stat` ; `statlist`)
  - At each step, one of the rules was chosen, and used from left-to-right, to replace a non-terminal in the parse tree by a RHS.

  > e.g.
  >
  > Given the following definition:
  > $$
  > \langle S\rangle ‚Üí c \langle R\rangle b \\
  > \langle R\rangle ‚Üí a|ra
  > $$
  > Use top-down parsing to determine if `crab` is valid.
  >   >
  >   >```mermaid
  >   >graph TD
  >   >	S[‚ü®S‚ü©] --> c
  >   >	S --> R[‚ü®R‚ü©]
  >   >	S --> b
  >   >
  >   >	R --> ra
  >   >```

- Two problems with RDP (Recursive Descent Parsing):

  - Repeated terminal checking
    - Whenever there is a choice, we expect that a parser should be able to select the correct alternative by looking at the current symbol.

    - We could try the first alternative, and if it does not match then backtrack and try the next. 

    - Backtracking is inefficient (each token is examined several times). 
      - We can make it less expensive by left factoring the grammar.

    - This reduces the number of times a token needs to be checked. To **left factor** a grammar:
      - Expand rules to expose the common part, and factor it out.

  - Left recursion
    - Left recursion can cause RDP to get stuck in an *infinite loop*.
    
      > e.g.
      > $$
      > ‚ü®T‚ü© ‚Üí ‚ü®T‚ü©√ó‚ü®D‚ü© | ‚ü®D‚ü© \\
      > ‚ü®D‚ü© ‚Üí[0‚àí9]
      > $$
      > 
    
    - A grammar is **left-recursive** if it has a non-terminal $A$ such that there is a derivation $A \to A\alpha$, for some string $Œ±$.
    
      - Before applying RDP to a grammar we need to **eliminate** left recursion.
      - To eliminate left recursion from any rule, we can apply the following substitution.
    
    - We can also run into infinite loops if the grammar is **indirectly left-recursive**.
    
      > e.g.
      > $$
      > ‚ü®A‚ü© ‚Üí‚ü®B‚ü©Œ±|Œ≤ \\
      > ‚ü®B‚ü© ‚Üí‚ü®A‚ü©Œ≥|Œ¥
      > $$
    
      - We can rewrite indirect left-recursion as an equivalent direct left-recursion by using the substitution rule below. We can then eliminate the left-recursion as before.

- Left Factor

  > e.g.
  >
  > For the following code
  >
  > ```
  > stmt -> while exp do stmt | assign | call
  > assign -> ident = exp
  > call -> ident ( arglist )
  > ```
  >
  >   > Expand assign and call:
  >   >
  >   > ```
  >   > stmt -> ...  | ident = exp | ident ( arglist )
  >   > ```
  >   >
  >   > and then:
  >   >
  >   > ```
  >   > stmt -> ...  | ident rest
  >   > rest -> = exp | ( arglist )
  >   > ```

- Left recursion

  > e.g.
  >
  > ...

---

##### 4.2.2. Buttom-up Parsing

- Definition

  - In bottom-up parsing, the input is compared against the right-hand sides of the rules, to find where a string can be replaced by a non-terminal.
  - Parsing succeeds when the whole input has been replaced by the start symbol of the grammar.
  - We will use the **shift-reduce** parsing techniques, used in most parser generators.

- Shift-reduce

  - Shift-reduce is hard to do by hand. But efficient (since no need to rewrite the grammar). 
  - Commonly used in practice.

  > e.g.
  > $$
  > \begin{array}{llcl}
  > \text{Rule A}: &‚ü®\text{stat}‚ü© &\to &\text{begin} ‚ü®\text{statlist}‚ü© | S \\
  > \text{Rule B}: &‚ü®\text{statlist}‚ü© &\to &\text{end} | ‚ü®\text{stat}‚ü© ; ‚ü®\text{statlist}‚ü©
  > \end{array}
  > $$
  > Is `begin S; S; end` valid?
  >
  > > | Stack               | Current Symbol | Remaining Input | Action      |
  > > | ------------------- | -------------- | --------------- | ----------- |
  > > |                     | `begin`        | `S; S; end`     | shift       |
  > > | `begin`             | `S`            | `; S; end`      | reduce($A$) |
  > > | `begin`             | `stat`         | `; S; end`      | shift       |
  > > | `begin stat`        | `;`            | `S; end`        | shift       |
  > > | `begin stat ;`      | `S`            | `; end`         | reduce($A$) |
  > > | `begin stat ;`      | `stat`         | `; end`         | shift       |
  > > | `begin stat ; stat` | `;`            | `end`           | shift       |
  > > | `begin stat ; stat` | `end`          |                 | reduce($B$) |
  > > | ...                 | ...            | ...             | ...         |

- Programming and Tools

  - **Parser generator**: generates a parser from a given grammar.
    1. generate a push-down automata to recognise the language (Shift and Reduce transitions)
    2. generate code in a chosen programming language (C, Java, ML...).
