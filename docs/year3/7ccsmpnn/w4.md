## WEEK IV - Multilayer Perceptrons & Backpropagation

>[🏠 MENU - 7CCSMPNN](year3/7ccsmpnn.md)
>
>[⬅️ WEEK III - Introduction to Neural Networks](year3/7ccsmpnn/w3.md)
>
>[➡️ WEEK V - Deep Discriminative Neural Networks](year3/7ccsmpnn/w5.md)
>
>Outlines:
>
>1. Introduction to DNNs
>
>     - DNNs
>     - Taxonomy
>
>2. Feedforward NNs
>
>     - MLP and Neuron Model
>     - Three-Layer FC Feedforward NNs
>     - Commonly Used Activation Functions
>     - General Feedforward Operations
>3. Backpropagation
>4. RBF NNs

### 4.1. Introduction to Deep Neural Networks

##### 4.1.1. Deep Neural Networks

- Goal
  - Classify objects by learning *non-linearity*. 
  -  Motivation
    - Regarding to ANNs, there are many problems for which linear discriminants are insufficient for minimum error.
    - In previous methods, the central difficulty was the choice of the appropriate nonlinear functions
    - A brute-force approach might be to select a complete basis set such as all polynomials; such a classifier would require too many parameters to be determined from a limited number of training samples.
    - In using the multilayer Neural Networks, the form of the nonlinearity is learned from the training data.
    - Careful choice of network topology is required, nevertheless, to avoid an over-complex network or one that performs poorly.
- Characteristics
  - Massive parallelism.
  - Distributed representation and computation.
  - Learning ability.
  - Generalisation ability.
  - Adaptivity.
- Applications
  - Pattern recognition/classification
  - Forecasting/prediction
  - Function approximation
  - Clustering/categorisation
  - Control

##### 4.1.2. Taxonomy

- Network Architectures

  - **Feedforward networks:** no loop exists (static system)
  - **Feedback/Recurrent networks:** loop exists (dynamic system)

- Learning Paradigms

  - **Supervised learning**

    - Target is known for every input pattern. Weights are determined so that the network can produce output as close as possible to the known target. 

    - *Reinforcement learning* is a special case of supervised learning where the weights are determined by critiques on the corrections of network outputs. 

      > e.g., a reward function.

  - **Unsupervised learning**

    - Target is not known. Weights are determined by exploring the underlying structure in the data or correlation between patterns in the data.

  - **Hybird learning**

    - It combines the supervised learning and unsupervised learning. A portion of weights are determined by supervised learning while the others are determined by unsupervised learning.

---

### 4.2. Feedforward Neural Networks

##### 4.2.1. MLP and Neuron Model

- Feedforward Neural Networks
  - A **feedforward neural network** or **multilayer perceptron (MLP)** consists of one input layer, some hidden layers and one output layer.
    - Each layer is an array of neurons.
    - Layers are interconnected by links.
    - Each link is associate with a connection weight.
- Neuron Model
  - A single *bias unit* is connected to each unit other than the input units.
    $$
    net_j = x_1 w_{j1} + x_2 w_{j2} + ... + x_d w_{jd} + w_{j0} \\
    y_j = f(net_j)
    $$

    ```mermaid
    graph LR
    	x1 --wj1--> sum(Σ)
    	x2 --wj2--> sum
    	xd --wjd--> sum
    	1 --wj0--> sum
    	sum --netj--> act(f)
    	act-->yj
    ```

    > Where the flatten layer Σ and the activation function f structures the hidden node $j$. 

##### 4.2.2. Three-Layer Fully-Connected Feedforward Neural Networks

- Components
  - A three-layer neural network consists of 
    - an *input layer*, 
    - a *hidden layer* and 
    - an *output layer*, which interconnected by modifiable *weights* represented by links between layers.
  - A three-layer neural network can, in principle, model any nonlinear function arbitrarily well in a compact domain. (Universal approximator)
  - Typical structure: $d - n_H - c$.
  - Network training is often based on the *back propagation algorithm* which is a form of gradient descent procedure.

##### 4.2.3. Commonly Used Activation Functions

- Activation/Transfer Functions

  - Definition
    $$
    net_j = \sum^d_{i=1} x_i w_{ji} + w_{j0} = \sum^d_{i=0} x_iw_{ji} = \textbf{w}^T_j \textbf{x}
    $$
    where

    - $\textbf{w}_j = \begin{bmatrix}w_{j1} \\ w_{j2} \\ ... \\ w_{jd} \\ w_{j0}\end{bmatrix}$

    - $\textbf{x} = \begin{bmatrix}x_1 \\ x_2 \\ ... \\ x_d \\ 1 \end{bmatrix}$

    - The subscript $i$ indexes <u>units in the input (source) layer</u>, $j$ <u>in the hidden</u>, $w_{ij}$ denotes the input-into-hidden layer weights at the hidden unit $j, x_0 = 1$. 

      > In neurobiology, such weights or connections are called synapse.

  - Each hidden unit emits an output that is a nonlinear function of its activation, that is:
    $$
    y_j = f(net_j)
    $$

  - The function $f(\cdot)$ is called the *activation function* or *transfer function*.

- Computation

  - Each output unit similarly computes its net activation based on the hidden unit signals as:
    $$
    net_k = \sum_{j=1}^{n_H} y_j w_{kj} + w_{k0} = \sum_{j=0}^{n_H} y_j w_{kj} = \textbf{w}^T_k \textbf{y} \\
    z_k = f(net_k)
    $$
    where the subscript $k$ indexes <u>units in the output layer</u> and $n_H$ denotes the number of hidden units, $y_0=1$. 

  - In the case of $c$ outputs (classes), we can view the network as computing $c$ discriminants functions $z_k = g_k(\textbf{x})$ and classify the input $\textbf{x}$ according to the largest discriminant function $g_k(\textbf{x}), k \in \{1, ..., c\}$

- Commonly Used Activation/Transfer Funcitons

  - Symmetric hard limit (signum) transfer function
    $$
    f(n) = \text{sgn}(n) = 
    \begin{cases}
    1 &\text{if } n \geq 0\\
    -1 &\text{if } n < 0
    \end{cases}
    $$

  - Linear transfer function: 
    $$
    f(n) = n
    $$

  - Symmetric *sigmoid* transfer function
    $$
    f(n) = \frac{2}{1+e^{-2n}}-1
    $$

  - Logarithmic *sigmoid* transfer function
    $$
    f(n)=\frac{1}{1 + e^{-1}}
    $$

  - *Radial basis transfer* function
    $$
    f(n) = e^{-n^2}
    $$

##### 4.2.4. General Feed-Forward Operation

- Consider that
  $$
  y_j = f(net_j) = f \left( \sum^d_{i=1} x_iw_{ji} + w_{j0} \right) \\
  z_k = f(net_k) = f \left( \sum^{n_H}_{i=1} y_jw_{kj} + w_{k0} \right)
  $$

  - Hidden units enable us to express more complicated nonlinear functions and this extend the classification.
    $$
    g_k(\textbf{x}) = z_k = f \left( \sum^{n_H}_{i=1} f \left( \sum^d_{i=1} x_iw_{ji} + w_{j0} \right) w_{kj} + w_{k0} \right), k \in \{1, ..., c\}
    $$

  - In matrix form, $\textbf{z} = \begin{bmatrix}z_1 \\ z_2 \\ ... \\z_c \end{bmatrix} = f(\textbf{w}_{kj}\textbf{y} + \textbf{w}_{k0}) = f(\textbf{w}_{kj}f(\textbf{w}_{ji}\textbf{x} + \textbf{w}_{j0}) + \textbf{w}_{k0})$

  - The activation function does not have to be a signum function, it is often required to be **continuous** and **differentiable**.

  - We can allow the activation function in the output layer to be different from the activation function in the hidden layer or have different activation functions for each individual unit.

- Network Topology

  - Any function from input to output can be implemented as a three-layer neural network, i.e., universal approximators.
  - These results are of greater theoretical interest than practical, since the construction of such a network requires knowledge of the nonlinear functions and the weight values which are unknown.
  - Hence, it needs some approach to train the weights based on some criteria.

---

### 4.3. Backpropagation Algorithm

##### 4.3.1. Introduction to Backpropagation

- Definition
  - **Backpropagation** is one of the simplest and most general methods for *supervised training* of multilayer neural networks.
  - Our goal now is to set the *interconnection weights* based on the training patterns and the desired outputs.
  - The power of backpropagation is that it enables us to compute an effective error for each hidden unit, and thus derive a learning rule for the input-to-hidden weights, this is known as: “*The credit assignment problem*”.
- Modes of Operations
  - Feed-Forward Networks have two modes of operation:
    - **Feed-forward:**
      - The feed-forward operations consists of presenting a pattern to the input units and passing (or feeding) the signals through the network in order to get outputs units (no cycles!).
    - **Supervised Learning:**
      - The supervised learning consists of presenting an input pattern and modifying the network parameters (weights) to reduce distances between the computed output and the desired/teaching/target output pattern.

##### 4.3.2. Network Learning

- Network Initialization

  - Choose the network size, i.e., $d, n_H, c$.
  - Choose the number of hidden layers (for network with more than one hidden layer).
  - Choose the activation functions.
  - Initialise the weights with pseudo-random values.

- Network Learning

  - The backpropagation learning rule is based on gradient descent (c.f. MSE or LMS method).

  - **The training error** (at any instance):
    $$
    J(\textbf{w}) = \frac{1}{2} \sum^c_{k=1} (t_k - z_k)^c = \frac{1}{2} \parallel \textbf{t} - \textbf{z} \parallel^2
    $$
    where $t_k$ is the $k$-th <u>desired or target output</u>; $z_k$ is the $k$-th <u>computed output</u>, where $k \in \{1, 2, ..., c\}$; $\textbf{w}$ represents all weights of the network, $\parallel \cdot \parallel$ denotes the Euclidean norm operator. 

  - The weights are changed (updated) in a direction that will reduce the error:
    $$
    \textbf{w}_{(m+1)} = \textbf{w}_{(m)} + \Delta \textbf{w}_{(m)}, \Delta \textbf{w}_{(m)} = -\alpha \frac{\partial J(\textbf{w}_{(m)})}{\partial \textbf{w}_{(m)}}
    $$
    where $m$ denotes the iteration number and $\alpha > 0$ is the (pre-defined) *learning rate* (indicating the relative size of the change in weights).

  - **Error on the hidden-to-output weights** (at the $m$-th iteration):
    $$
    \frac{\partial J}{\partial w_{kj}} = \frac{\partial J}{\partial net_k} \frac{\partial net_k}{\partial w_{kj}} = -\delta_k \frac{\partial net_k}{\partial w_{kj}}
    $$
    where the sensitivity of unit $k$ is defined as:
    $$
    \delta_k = - \frac{\partial J}{\partial net_k} = ... = (t_k - z_k)f'(net_k)
    $$
    which describes <u>how the overall error (i.e.,  $J$) changes with the activation function of the unit’s net ($net_k$)</u>.
    - In this scheme, since $net_k = \textbf{w}^T_k \textbf{y}$,then $\frac{\partial net_k}{\partial w_{kj}} = y_{kj}, y_0 = 1$. 
    - The <u>weight update (learning rule)</u> for the hidden-to-output weights (i.e., $w_{kj}$) is then:
      $$
      \Delta w_{kj} = - \alpha \frac{\partial J}{\partial w_{kj}} = \alpha \delta_k y_j = \alpha (t_k - z_k) f'(net_k)y_j
      $$
      New weight$w_{kj}$ at the next iteration is:
      $$
      w_{kj, (m+1)} \leftarrow w_{kj, (m)} + \Delta w_{kj, (m)}
      $$
      where $j \in \{0, 1, ..., n_H\}, k \in \{1, ..., c\}, y_0 = 1$

  - **Error on the input-to-hidden units** (at the $m$-th iteration):
    $$
    \frac{\partial J}{\partial w_{ji}} = \frac{\partial J}{\partial y_j} \frac{\partial y_j}{\delta net_j} \frac{\partial net_j}{\partial w_{ji}} = - \underbrace{\sum^c_{k=1} \delta_k w_{kj} f'(net_j)}_{\delta_j}x_i
    $$

    - The sensitivity at a hidden unit (i.e., $\delta_j = \sum^c_{k=1} \delta_k w_{kj} f'(net_j) = f'(net_j) \sum^c_{k=1} \delta_k w_{kj}$ ) is simply the sum of the individual sensitivities at the output units (i.e., $\delta_j$) weighted by the hidden-to-output weights $w_{kj}$. All multiplied by $f'(net_j)$.

    - The <u>weight update (learning rule)</u> for the hidden-to-output weights (i.e., $w_{ji}$) is then:
      $$
      \Delta w_{ji} = -\alpha \frac{\partial J}{\partial w_{ji}} = \alpha \delta_j x_i = \alpha f'(net_j) \left[ \sum^c_{k=1} w_{kj}\delta_k \right] x_i
      $$
      New weight $w_{ji}$ at the next iteration is:
      $$
      w_{ji, (m+1)} \leftarrow w_{ji, (m)} + \Delta w_{ji, (m)}
      $$
      where $i \in \{0, 1, ..., d\}, j \in \{0, 1, ..., n_H\}, k \in \{1, ..., c\}, x_0 = 1, y_0 = 1$


##### 4.3.3. Stochastic and Batch Backpropagation

-  Stochastic Backpropagation

  ```
  Algorithm: Stochastic Backpropagation
  begin initialize network topology (d, nH, c), w, θ, α, m <- 0
  	do m <- m + 1
  		x^(m) <- randomly chosen pattern
  		w_kj <- w_kj + α δk yj
  		w_ji <- w_ji + α δj xi
  	until |∆J(w(m))| = |J(w^(m)) − J(w^(m − 1))| < θ
  	return w
  end
  
  ```

  > **Remark**: $δ_j, δ_k$ are calculated with the old values of $w_{ji}, w_{kj}$.

  - Stopping Criterion
    - The algorithm terminates when the change in the criterion function $J(\textbf{w})$ is smaller than some preset value $θ$.
    - So far, we have considered the error on a *single pattern*. A weight update may reduce the error on the single pattern being presented but can increase the error on the full training set.

- Batch Training

  - We want to consider an error defined over the entirety of patterns in the training set, the total training error is the sum over the errors of $n$ individual patterns:

  $$
  J = \sum^n_{p=1} J_p
  $$

  ```
  Algorithm: Batch Backpropagation
  begin initialise network topology (d, nH , c), w, criterion θ, α, r <- 0
  	do r <- r+1 (increment epoch)
  	m <- 0; ∆wji <- 0; ∆wjk <- 0
  		do m <- m+1
  			x^(m) <- select the m-th pattern
  			∆wkj <- ∆wkj +α δk yj (accumulate ∆wkj for all input patterns)
  			∆wji <- ∆wkj +α δj yi (accumulate ∆wji for all input patterns)
  		until m = n (n: number of individual patterns in the training set)
  		wkj <- wkj + ∆wkj (bach update wkj)
  		wji <- wji + ∆wji (bach update wji)	
  	until |∆J(w^(r))| = |J(w^(r)) − J(w^(r-1))| < θ
  	return w
  end
  	
  ```

##### 4.3.4. Learning Curves

- Terminologies
  - Dataset is partitioned into 3 sets: *training*, *validation* and *test* sets.
  - Before training starts, the error on the training set is high; through the learning process, the error becomes smaller.
    - The average error on an independent test set is always higher than on the training set, and it can decrease as well as increase.
  - A validation set is used in order to decide when to stop training; we do not want to overfit the network and decrease the power of the classifier generalization. **We stop training at a minimum of error on the validation set to avoid overfitting** (i.e., earling stopping).
  - A test set is used to evaluate the trained network with unseen data.

---

### 4.4. Radial Bias Function Neural Networks

##### 4.4.1. Introduction to RBF Networks

- Definition
  - An RBF network network is a three-layer network: input, hidden and output layers.
    - Input unit: Linear transfer function.
    - Hidden unit: Radial basis function, $h(\cdot)$.
    - Output unit: Any activation function, $f(\cdot)$.
  - Hidden Units
    $$
    d_j = \parallel \textbf{x} - \textbf{c}_j \parallel, j = 1, ..., n_H
    $$
    where $\textbf{x} = \begin{bmatrix} x_1 &x_2 &... &x_d\end{bmatrix}$, $\textbf{c}_j = \begin{bmatrix} c_{j1} &c_{j2} &... &c_{jd}\end{bmatrix}$ is the centre of the basis function. 
    
    - $\textbf{c}_j$ can be preset or determined by a training algorithm.
    - $h(\cdot)$ is a radial basis function (function and parameters can be different for each hidden unit).
  
- Commonly Used Basis Funtions
  $$
  \begin{array}{rll}
  \text{Gaussian function:} &h(d_j) = e^{-\frac{d^2_j}{2\sigma^2}} &\sigma >0 \\
  \text{Multi-quadric function:} &h(d_j) = (d^2_j + \sigma^2)^{\frac{1}{2}} &\sigma >0 \\
  \text{Generalized multi-quadric function:} &h(d_j) = (d^2_j + \sigma^2)^{\beta} &\sigma >0, \beta \in (0, 1) \\
  \text{Inverse multi-quadric function:} &h(d_j) = (d^2_j + \sigma^2)^{-\frac{1}{2}} &\sigma >0 \\
  \text{Generalized inverse multi-quadric function:} &h(d_j) = (d^2_j + \sigma^2)^{-\beta} &\sigma >0, \beta > 0 \\
  \text{Thin plate spline function: } &h(d_j) = d^2_j \ln(d_j) &~ \\
  \text{Cubic function: } &h(d_j) = d^3_j &~ \\
  \text{Linear function: } &h(d_j) = d_j &~ \\
  \end{array}
  $$

  - Parameters can be preset or determined by a training algorithm.

  - The Gaussian and inverse multi-quadratic functions are *localised*

    > i.e., $h(d_j, \sigma) \to 0$ as $d_j \to \infin$

  - The linear function is linear in $d_j$ but nonlinear in $\textbf{x}$.

##### 4.4.2. Input-output Mapping

- Output at hidden units:
  $$
  y_j(\textbf{x}) = h(d_j) = h(\parallel \textbf{x} - \textbf{c}_j \parallel), j \in \{1, ..., n_H\}
  $$

- Output at output units:
  $$
  z_k(\textbf{x}) = f(\sum^{n_H}_{j=1} w_{kj}y_j(\textbf{x}) + w_{k_0}) = f(\sum^{n_H}_{j=1} w_{kj}h(\parallel \textbf{x} - \textbf{c}_j \parallel) + w_{k_0})
  $$

- Training Goal
  $$
  J = \sum^n_{p=1} J_p = \frac{1}{2} \sum^n_{p=1} \underbrace{\parallel \textbf{t}_p - \textbf{z}_p \parallel^2}_{J_p} = \frac{1}{2} \sum^n_{p=1} \underbrace{\sum^c_{k=1}(t_{pk} - z_{pk})^2}_{J_p}
  $$
  This formula indicates the sum of the squared error, where

  $n$ is the number of patterns in the training set, 
  $\textbf{t}_p = \begin{bmatrix} t_{p1} &t_{p2} &... &t_{pc}\end{bmatrix}$ is the training target for the $p$-th input pattern $\textbf{x}_p = \begin{bmatrix} x_{p1} & x_{p2} &... & x_{pd} \end{bmatrix}$, 
  $p \in \{1, ..., n\}$, and
  $\textbf{z}_p = \begin{bmatrix} z_{p1} & z_{p2} & ... & z_{pc}\end{bmatrix}$

  - $J_p \to 0$ as $z_{pk} \to t_{pk} \forall k \implies J \to 0$
  - Determine $\textbf{c}_j, w_{kj}$, basis function parameters $(σ, β)$.
  - The above cost is used in batch backpropagation. Stochastic backpropagation can also be used.

##### 4.4.3. RBF Network Learning

- Two Phases Learning

  - (*Unsupervised learning*) **Determine the centres** $\textbf{c}_j$ (and function parameters).
    - Fixed centres selected at random.
    - Clustering based approaches.
  - (*Supervised learning*) **Determine the output weights** $w_{kj}$
    - Computing the output weights (*when linear output function is employed*) using *least squares method*.
    - *Gradient descent* (backpropagation) approaches.

- Determination of centres

  - Simple and quick.
  - Number of hidden units $n_H$ is less than the number of input patterns $n$, i.e., $n_H \leq n$.
  - Procedure:
    1. Choose number of hidden units, $n_H$ .
    2. Pick randomly $n_H$ input pattern from the data set (with $n$ input patterns) as the centres $\textbf{c}_j$, where $j \in \{1, ..., n_H\}$. 
    3. When Gaussian function is employed, define $\sigma_j = \frac{\rho_\max}{\sqrt{2n_H}}$ or $\sigma_j = 2\rho_\text{avg}$ for all $j$, where
       - $\rho_\max$ is  is the maximum distance between the chosen centres, and
       - $\rho_\text{avg}$ is the average distance between the chosen centres.
    4. Other parameters are chosen randomly.

  > e.g.
  >
  > Dataset (10 input samples): $\textbf{x}_1, \textbf{x}_2, \textbf{x}_3, \textbf{x}_4, \textbf{x}_5, \textbf{x}_6, \textbf{x}_7, \textbf{x}_8, \textbf{x}_9, \textbf{x}_{10}$.
  >
  > > Choose 3 centres, i.e., $n_H=3$.
  > >
  > > Randomly pick $\textbf{c}_1 = \textbf{x}_5, \textbf{c}_2 = \textbf{x}_2, \textbf{c}_3 =  \textbf{x}_9$.
  > >
  > > For $\sigma_j$:
  > >
  > > - $\rho_\max = \max\{\parallel \textbf{c}_1 - \textbf{c}_2\parallel, \parallel \textbf{c}_1 - \textbf{c}_3\parallel, \parallel \textbf{c}_2 - \textbf{c}_3\parallel \}$
  > > - $\rho_\text{avg} = \frac{\parallel \textbf{c}_1 - \textbf{c}_2\parallel + \parallel \textbf{c}_1 - \textbf{c}_3\parallel + \parallel \textbf{c}_2 - \textbf{c}_3\parallel}{3}$

  -  Clustering Based Approaches
    - K-Means Clustering
      - Centre $\textbf{c}_j$ is the mean/centroid of the input patterns in the cluster $S_j$, i.e., $\textbf{c}_j = \frac{1}{n_j}\sum_{p ∈S_j} \textbf{x}_p$.

- Determination of output weights

  - Computing the output weights using least squares method (*linear output function*)

    - $f(\cdot)$ is a linear function.
    - $z_k(\textbf{x}) = \sum^{n_H}_{j=1} w_{kj} y_j (\textbf{x}) + w_{k0}$ where $k \in \{1, ..., c\}$. 

    $$
    \underbrace{
    \begin{bmatrix}
    y_1(\textbf{x}_1) & y_2(\textbf{x}_1) & ... & y_{n_H}(\textbf{x}_1) & 1 \\
    y_1(\textbf{x}_2) & y_2(\textbf{x}_2) & ... & y_{n_H}(\textbf{x}_2) & 1 \\
    ... & ... & ... & ... & ... \\
    y_1(\textbf{x}_p) & y_2(\textbf{x}_p) & ... & y_{n_H}(\textbf{x}_p) & 1 \\
    \end{bmatrix}
    }_{\Phi(\textbf{x})}
    
    \cdot 
    
    \underbrace{
    \begin{bmatrix}
    w_{k1} \\
    w_{k2} \\
    ... \\
    w_{kn_H} \\
    w_{k0} \\
    \end{bmatrix}
    }_{\textbf{W}_k}
    
    =
    
    \underbrace{
    \begin{bmatrix}
    t_{k1} \\
    t_{k2} \\
    ... \\
    t_{kp} \\
    \end{bmatrix}
    }_{\textbf{t}_k}
    $$

    - $\Phi(\textbf{x}) \textbf{W}_k = \textbf{t}_k$ where $k \in \{1, ..., c\}$
      - $\Phi(\textbf{x})$ is a *square* matrix
        $$
        \textbf{W}_k = \Phi(\textbf{x})^{-1} \textbf{t}_k
        $$
      - $\Phi(\textbf{x})$ is a *non-square* matrix
        $$
        \textbf{W}_k = \left( \Phi(\textbf{x})^T \Phi(\textbf{x}) \right)^{-1} \Phi(\textbf{x})^T \textbf{t}_k
        $$
    
  - Gradient descent approach (Backpropagation)
  
    - Can be applied to nonlinear output function $f(\cdot)$.
    - Parameters to be learned: $w_{kj}, \sigma_j, \textbf{c}_j$.
    - Compute 
      $$
      \Delta w_{kj} = - \alpha \frac{\partial J}{\partial w_{kj}} \\
      \Delta \sigma_j = - \alpha \frac{\partial J}{\partial \sigma_j} \\
      \Delta \textbf{c}_j = - \alpha \frac{\partial J}{\partial c_{ji}} \\
      $$
    - Update parameters iteratively as:
      $$
      w_{kj, (m+1)} \leftarrow w_{kj, (m)} + \Delta w_{kj, (m)}\\
      \sigma_{j, (m+1)} \leftarrow \sigma_{j, (m)} + \Delta \sigma_{i, (m)}\\
      \textbf{c}_{ji, (m+1)} \leftarrow c_{ij, (m)} + \Delta c_{ji, (m)}\\
      $$
    - Stochastic or batch update algorithm can be used. Input normalisation have to be done for the dataset if necessary.

##### 4.4.4. Comparison of RBF and MLP Networks

- Similarities
  - Both are universal approximators.
  - Both are nonlinear feed-forward neural networks.
- Differences
  - RBF networks have only one hidden layer but MLP networks can have more than one hidden layer.
  - RBF networks use different basis functions from the activation functions used in MLP networks.
  - RBF networks compute the *distance* between the input patterns and centres while MLP networks compute the *inner product* of the input pattern and weights.
  - RBF are trained with two-phase algorithm but MLP networks are trained with a single-phase algorithm.