## WEEK V - Introduction to OSs

>[🏠 MENU - 5CCS2OSC](year2/5ccs2osc.md)
>
>[⬅️ WEEK IV - Concurrency Control](year2/5ccs2osc/w4.md)
>
>[➡️ WEEK VI - The address-binding Problem, Segementation and Page Tables](year2/5ccs2osc/w6.md)
>
>Outlines:
>
>- Introduction to OSs

### 12. Introduction to Operating Systems

##### 12.1 History

> Before OSs: *Human Operators*

##### 12.2. Concepts

- Terminology

  - `Scheduling and running tasks` - Content for the previous 4 weeks. 
  - `Loading, memory management`
  - `Input/Output` - A topic affecting the *structure* and *performance* of the operating system, and also affected by hardware.
  - `Security` - Deeply entwined with I/O, *e.g. because both programs and data are stored on I/O devices (e.g. ‘disks’)*
  - `Control` - On modern machines, most control is done by a variety of tools that are simply programs, often *privileged* to act on behalf of the system's owner/administrator bringing strong security requirements. 

- Evaluaiton

  - **Efficiency **- imposes minimal overheads, maximising use of hardware resources

  - **Fairness **- shares out system resources according to policy (however defined)

  - **Reliability** - keeps working (efficiently, fairly, ... ) even when programs are buggy or hardware is faulty

  - **Security** - keeps working (efficiently, fairly, ... ) even when users/programs are *adversarial* 

    > i.e. try to subvert intended behaviour or configured policy

  - **Usability** - offers services and behaviours that help humans get things done (including learning how to do so)

  - **Abstraction** - offers high-level, general and powerful services, for application programmers *and* for users

  - **Simplicity** - consists of a small codebase that is maintainable, comprehensible, auditable, assuredly secure

- Functionality - Secure multiplexing of the computer's resources
  - Secure multiplexing - i.e., Sharing out
  - Not possible to get more than your intended share, nor to interfere with the behaviour of another program's/user's share *(e.g. reading their processes' memory, ... )*
- Most real OSes are 'multi-user', meaning they distinguish multiple *user identities*. 

##### 12.3. Virtualisation

- Definition

  - A virtual computer provided by the OS is used for a program which is *in execution*
  - May includes the following components
    - virtual CPU(s) (thread(s) of execution)
    - virtual memory (a ‘private’ address space)
    - virtual storage (files on disk)
    - virtual network (sockets...)
    - Other virtual components, *e.g., screen/keyboard, windows, ...*

- Functionality

  > OSs don't *only* virtualise hardware. A program that does *only* this is called a *virtual machine monitor* or *hypervisor*.

  - Communication - what if programs want to interact with each other. 
  - Abstraction - higher-level staff, *e.g. files, not just a range of blocks on disk*
  - Control and inspection - the services about running programs, *e.g., starting and stopping them, inspecting/debugging, ...*

##### 12.4. Concurrency and OSs

- Concurrency abstractions

  - Inherently concurrent abstractions (for modern OSs)

    - User(s) may create multiple processes that exist simultaneously.
    - A process may contain multiple threads.
    - Processes/threads may share resources *(memory, files, ...)*

  - Batch operating systems (1950s OSs)

    > Each submitted job ran to completion independently. Internally the system could still be ‘multiprogrammed’, i.e. keep multiple processes in memory at once. 

  - Time-sharing systems (1960s OSs)

    > Multiprogrammed systems that also allowed interactive (non-batch) use by multiple users simultaneously, usually via connection of multiple *teletypes*. Means of *communication* among users were added.

- Concurrency versus parallelism

  - Concurrency isn't really about physical time. It's about (un)controlled interaction.

    >e.g., 
    >
    >Q: Given only one CPU, an OS can run programs concurrently by switching between them. (today a time-slice is ≈10ms) If two programs (on one core) aren’t really running at the same time, are they really concurrent? 
    >
    >A: Yes, because neither *controls* when the switching happens and therefore how their *interactions* are ordered.

  - Parallelism - 'True concurrency', *e.g., two separate things running on two CPUs at physically the same time.* 

  - Note that interaction is what makes things complicated. Physically parallel processes that don’t interact are easy. 

- Concurrency within OSs

  - Regardless of whether concurrent abstractions are provided, OSs are *internally concurrent* because of *parallelism of hardware*. 
  - A computer consists of multiple hardware devices, and any one instant they can all be doing. Abstractly, most computers from different things. The operating system has to coordinate these.

  > e.g.
  >
  > Q: If one process is paused waiting for an input/output device, how does the operating system know that the device has finished and the process can continue?
  >
  > A: 
  >
  > Very often this is done with a *hardware interrupt*: the hardware has a connection to the CPU and can cause it to jump to a special routine.
  >
  > - This means the operating system itself is a concurrent program: the CPU interrupt saves and restores a context, like a thread switch.
  > - A modern computer system is a parallel system: besides the CPU, other devices are active at the same time.
  >
  > Sometimes it’s not the I/O device itself but a *timer* that fires, allowing the OS to switch to another activity *(e.g. checking status of the I/O device)*. This is how preemptive schedulers work. 

---

### 13. Core Concepts

##### 13.1. Introduction to Five Core Concepts

- Address space
  - *Memory* consists of a collection of *locations* that are (somehow) *numbered*. 
  - OSs manage *many* address spaces, *e.g., one per process + physical memory + ...*
- Loading a program
  - To make a running *process* given a static *program* *(e.g. a binary `.exe` file)* we have to load it into memory.
- User vs system
  - Processes run <u>either in user or system (a.k.a. kernel) mode</u>. 
  - In user mode, user's (program) code runs and the CPU prevents access to hardware. 
  - In system/kernel mode, OS code runs and CPU allows all.
- Limited direct execution
  - Programs run on the *real hardware* (not e.g. a software emulation), but such that the OS can regain control, *e.g., by timer interrupt*. 
- System calls
  - When programs need to use the OS for its *privilege* and/or *abstractions*, it makes a call analogous to a procedure (method) call but different: changing *mode*, maybe switching *address space*, and jumping into OS code.

##### 12.2. Address Space

> ![img](https://velog.velcdn.com/images%2Fgabie0208%2Fpost%2Feaff93ef-af1b-414b-bfe9-ee7bfaa6199f%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-10-11%20%EC%98%A4%ED%9B%84%205.05.47.png)
>
> >- **Address space** - The set of numbered locations. Since memory locations are *numbered* and the number is an *address*. 
> >- **Reference** is achieved using the *number* of the referred-to memory location. We often say as **pointers**. 

##### 13.3. Loading a program

##### 13.4. User vs system/kernel mode

- kernel mode
  - Programs can execute any CPU instructions and access any memory address
  - Superuser mode

- user mode
  - When running in *user mode*, the CPU prohibits certain instructions.
    - ones that could violate *security* of *multiplexing*, *e.g., by accessing devices, accessing memory they shouldn't...*

  - To jump to *kernel mode*, use a *software interrupt instruction*, a.k.a. system call. 


##### 13.5. Limited direct execution

- A software middle layer could run a program on the hardware, by 

  - interpreting it, or
  - by *translating* it (compiling or rewriting...)

- OSs don’t do either of these. They actually run your program on the actual hardware, but still keep control. The process is as follows,

  1. to put the CPU in *user mode*
  2. jump to the user program code in memory
  3. ensure that it eventually somehow jumps back to the OSs

  >CPUs generally provide a single instruction that does 1. and 2. 
  >
  >Handle with 3. is depending on scheduler,
  >
  >- *Preemptive scheduler* - A *timer interrupt* is firing periodically
  >- *Cooperative* schedule - Rely on the program *doing I/O* or *yielding*

- Any *interrupt* will put the CPU in kernel mode and jump into the OS

  - timer interrupt - a hardware interrupt raised by programmable timer
  - doing I/O or yielding - a *software interrupt* a.k.a. *system call*

##### 13.6. System Calls

- Definition

  - System calls are like *procedure calls*, but where the procedure is inside the operating system.
  - Procedure for accessing virtual hardware, *e.g., reading and writing files on disk*. 

  - Need a special CPU instruction like jumping to the right code, also need to do *mode switch* into kernel mode.

- Procedure calls

  - A procedure call is like a *method call*, when there is no overriding.
  - There's only one jump target; jump to it *directly*.
  - The MARIE approach is not used on modern (post-1950s) machines.
    - It stores the return address amongst the code.
    - Instead, it’s better to *push it on the stack*.

