## WEEK V - SAT Solving

>[ğŸ  MENU - 5CCS2FC2](year2/5ccs2fc2.md)
>
>[â¬…ï¸ WEEK IV - Graph Algorithm](year2/5ccs2fc2/w4.md)
>
>[â¡ï¸ WEEK VI](year2/5ccs2fc2/w6.md)
>
>Outlines: 
>
>- N SAT Problem
>
> >Definition
> >
> >Restricted versions
>
>- DPLL Algorithm - idea is to assume argument as true to solve CNF
>
>>Pure Literal Elimination - 
>>
>>Unit Propagation - eliminate unit literals and clauses with these unit literals
>>
>>DPLL - 
>
>- 
>
>
>
>

#### 17. Introduction to SAT Solving

###### ***Theorem 17.1.*** The Boolean Satisfiability Problem N SAT

**Input)** A propositional formula $F$ in CNF with *at most* $N$ literals in each clause. 

**Output)** **True** if and only if $F$ is *satisfiable*. 

###### ***Theorem 17.2.*** Restricted versions of SAT I

We have the following chain of polynomial reductions: 

$2\text{SAT} \leq_p 3\text{SAT} \leq_p ... \leq_p k\text{SAT} \leq_p ... \leq_p  \text{SAT} $

***Proof.*** 

>This reduction is **easy** since every CNF formula with **at most** $k$ literals in each clause also has **at most** $(k+1)$ literals in each clause. 
>
>Note: Some definitions of **N SAT** stipulate exactly $N$ literals per clause. But the same chain of reductions can be proved for this alternative definitions as well. 

###### ***Theorem 17.3.*** Restricted versions of SAT II

We also have the following chain of polynomial reductions: 

$\text{SAT} \leq_p ... \leq_p k\text{SAT} \leq_p ... \leq_p 5\text{SAT} \leq_p 4\text{SAT} \leq_p  3\text{SAT} $

***Proof.***

>This direction is more surprising as the direction is reversed. 
>
>As It is enough to show that  $\text{SAT} \leq_p 3\text{SAT}(k+1)\text{SAT} \leq_p \text{SAT} \leq_p 3\text{SAT} \leq_p k\text{SAT}$
>
>1. Let $F$ be an arbitrary formula in CNF. 
>
>   $(P \vee \neg Q \vee R \vee S) \wedge (Q \vee \neg R \vee \neg T)$
>
>2. Find a clause which contains **more than 3 literals**. 
>
>   i.e., $(Q \vee \neg R \vee \neg T)$ âœ…
>
>3. Break up the clause into two pieces in the middle. 
>
>   i.e., $(P \vee \neg Q \ ğŸ’¥\  R \vee S)$
>
>4. Introduce a fresh propositional variable to **â€˜bridge the gapâ€™**. 
>
>   $(P \vee \neg Q \vee X) \wedge (\neg X \vee R \vee S) \wedge (Q \vee \neg R \vee \neg T)$
>
>5. Repeat until all clauses contain **at most 3 literals**. 
>
>   > The resulting formula is satisifiable if and only if the original formula is satisifiable. 

###### ***Theorem 17.4.*** 2 SAT Problem is solvable in polynomial time. 

***Proof.*** 

>We can solve **2 SAT** by using our strongly connected component algorithm. 
>
>1. Write each clause as **two implications**. 
>
>   $(\neg P \vee Q) \implies (P \to Q) \wedge (\neg Q \to \neg P)$
>
>   $(\neg Q \vee R) \implies (Q \to R) \wedge (\neg R \to \neg Q)$
>
>   $(P \vee \neg R) \implies (\neg P \to \neg Q) \wedge (R \to P)$
>
>   $(R \vee Q) \implies (\neg R \to Q) \wedge (\neg Q \to R)$
>
>2. Construct the **implication graph**. 
>
>3. Complete the **Strongly Connected Components (SCCs)**. 
>
>4. Check whether any SCC contains a **literal** and **its negation**. 
>
>5. Since we can compute and check each strongly connected component in polynomial time, we have that
>
>   **2 SAT** is solvable in **polynomial time**. 

###### ***Theorem 17.5.*** (Definite) Propositional Horn Clauses

$P, (P \to Q), (P \wedge Q \to R), (Q \to S), (S \wedge R \to T)$

- Each clause contains **exactly one** positive literal. 
- Every clause can be written in **implicational / rule form** with a **single (positive) head**. 

> The relationship:
>
> 2 SAT Formula / Horn Formulas $\in$ Solvable in polynomial time $\in$ All Formulas

---

#### 18. DPLL Algorithm

>ref: 
>
>[Conflict Driven Clause Learning (CN) - Zhihu](https://zhuanlan.zhihu.com/p/92659252)
>
>[Conflict Driven Clause Learning - GitHub](https://cse442-17f.github.io/Conflict-Driven-Clause-Learning/)

###### ***Theorem 18.1.***  A (Naive) Branching Divide-and-Conquer Agorithm

**Input1)** A set of clauses $C$

**Input2)** A patial assignment $U \subseteq \{\text{literals from }C\}$

1. We **branch** on any variable $P$ appearing in $C$: 

   - First choose to make $P:= \text{False}$  by adding $\neg P$ to $U$. 
   - Next choose to make $P:= \text{True}$  by adding $P$ to $U$. 

2. We eliminate any satisfied clauses from C and **simplify** the remaining clauses.

3. The remaining set of clauses is **self-similar** to the original set of clauses but with one fewer variable.

4. ence we can continue by <u>recursively</u> calling this algorithm until either: 

   - all clauses are satisfied and $C = âˆ…$.

   - a conflict is detected in the partial assignment $U$. 

>`BRANCH-SAT(C, U): `
>
>1. **If** $U$ contains a conflict: **Return** *False*
>2. **If** $C = âˆ…$: **Return** *True*
>3. Simplify the clauses in $C$ as much as possible
>4. Select a variable $P$ appearing in $C$
>5. **If** *BRANCH-SAT($C, U \cup \{\neg P\}$)* = *True*: **Return** *True*
>6. **If** *BRANCH-SAT($C, U \cup \{P\}$)* = *True*: **Return** *True*
>7. **Return** *False*

###### ***Theorem 18.2.*** Pure Literal Elimination

A **pure literal** is any literal that occurs <u>only positive or negatively in all clauses</u>

1. We can always add these literals to our assignments without risk of a conflict: $P:= \text{True}$  and $S:=\text{False}$ 

   $(P \vee Q \vee \neg S), (P \vee \neg Q), (Q \vee R), (Q \vee \neg R \vee \neg S)$

2. We can simplify to eliminate any clause containing these pure literals: 

â€‹	$âŒ(P \vee Q \vee \neg S), âŒ(P \vee \neg Q), âœ…(Q \vee R), âŒ(Q \vee \neg R \vee \neg S)$

> Pure Literal Elimination assigns literals that **SHOULD** be assigned. 

###### ***Theorem 18.3.*** Unit Propagation (UP)

1. We can **eliminate** any clause <u>containing a unit clause literal</u>, 

â€‹	$âŒ\neg Q, âœ…(P \vee Q), âœ…(\neg P \vee \neg R \vee S), âœ…(\neg P \vee Q \vee \neg S), âŒ(\neg P \vee \neg Q), âŒR, âŒ(Q \vee R \vee S)$

2. And then **simplify** any clause <u>containing the negation of the unit clause literal.</u>

â€‹	$âŒ\neg Q, âœ…P, âœ…(\neg P \vee S), âœ…(\neg P\vee \neg S), âŒ(\neg P \vee \neg Q), âŒR, âŒ(Q \vee R \vee S)$

These assignments propagate leading to further unit clauses $P:= \text{True}$ 

> Unit Propagation assigns literals that **MUST** be assigned. 

###### ***Theorem 18.4.*** The Davis-Putnam-Logemann-Loveland (DPLL) Algorithm

>A divide-and-conquer backtrack-search type algorithm to solve **SAT** problem, which employs pure literal elimination and unit propagation (Boolean Constraint Propagation, BCP). 

**Input1)** A set of clauses $C$

**Input2)** A patial assignment $U \subseteq \{\text{literals from } C\}$

1. We simplify $C$ and apply the following rules: 

   - pure liberal elimination

   - unit propagation

2. If any clauses remain unsatisfied, we branch on any remaining variable $P$: 

   - First choose to make $P:=$ *False* by adding $\neg P$ to $Q$, 
   - Next choose to make $P:=$ *True* by adding $P$ to $Q$. 

3. We can achieve this by recursively calling the DPLL algorithm until either: 

   - All clauses are **satisfied** and $C = âˆ…$, or
   - A **conflict** is detected in the partial assignment $U$. i.e., Any of the clauses get a *False*. 

>`DPLL(C, U): `
>
>1. **If** $U$ contains a conflict : **Return** *False*
>2. **If** $C=âˆ…$: **Return** *True*
>3. Simplify the clauses in $C$ as much as possible
>4. Apply `PURE-LITERAL-ELIMINATION` to $C$
>5. Apply `UNIT-PROPAGATION` to $C$
>6. Select a variable $P$ appearing in $C$
>7. **If** *DPLL($C, U \cup \{\neg P\}$)* = *True*: **Return** *True*
>8. **If** *DPLL($C, U \cup \{P\}$)* = *True*: **Return** *True*
>9. **Return** *False*

---

#### 19. Greedy Approach

###### ***Theorem 19.1.*** Why is SAT important 

- The first example of a problem shown to be **NP-complete**, i.e., 
  - All NP problems can be **reduced to SAT**
  - Finding a polynomial time algorithm for SAT proves that **P = NP**
- Logic acts as a *specification language* to describe real-world problems. 
  - Reductions to **SAT** are often straightforward. 
  - Even if **P $\neq$ NP** we still want to be able to answer real-world problems as quickly as possible. 
- SAT Solvers are used in industrial application to solve instances of SAT, modern solvers can cope with formulas with millions of literals. 

###### ***Theorem 19.2.*** A Greedy SAT Algorithm

1. Guess a variable assignment at random

   $P:=\text{True}, Q:=\text{False}, R:=\text{False}$

2. Evaluate your guess by counting the number of satisfied clauses: 

   $âœ…(P \vee Q), âœ…(\neg P \vee \neg Q \vee R), âœ…(\neg P \vee \neg Q), âœ…(P \vee \neg Q \vee R)$

   $âŒ(\neg P \vee Q \vee R), âŒ(Q \vee R), âŒ(\neg P \vee Q)$

3. Consider the effect of swapping a single variable from *True* to *False* (or vice versa)

4. Update the assignment to the assignment that leads the the biggest **increase** in the number of satisfied clauses

5. Repeat until no further improvements are possible.

   $P:=\text{True}P:=\text{False}, Q:=\text{True}Q:=\text{False}, R:=\text{True}R:=\text{False}$

>`GREEDY-SAT(C): `
>
>1. Randomly select a variable assignment $V$
>
>2. **While** there is some *unsatisfied* clause in $C$: 
>
>   3. Count the number of *unsatisfied* clauses.
>   4. **For each** variable $P$: 
>      5. Count the number of clauses satisfied by flipping the assignment of $P$. 
>
>   6. **If** no improvement: **Return** *False*
>   7. Update $V$ to the best improvement. 
>
>8. **Return** *True*

###### ***Theorem 19.3.*** A Greedy SAT Algorithm runs in polynomial time. 

***Proof.*** 

>1. Selecting a random assignment and evaluating the â€˜scoreâ€™ of the assignment can both be done in **linear time**.
>2. Each iteration involves evaluating at most n assignments that different in a single variable, requring at most a polynomial number of steps
>3. Since we never decrease our â€˜scoreâ€™, we iterate at most a polynomial number of times.
