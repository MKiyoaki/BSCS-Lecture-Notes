## WEEK III - Bayesian Networks

>[ðŸ  MENU - 6CCS3AIN](year3/6ccs3ain.md)
>
>[â¬…ï¸ WEEK II - Probabilities](year3/6ccs3ain/w2.md)
>
>[âž¡ï¸ WEEK IV - Sequential Decision Making](year3/6ccs3ain/w4.md)
>
>Outlines:
>
>1. Naive Bayes, Bayesian Networks
>
>    - Naive Bayes - Basing on Bayes' Rule. Can be used for classifier. 
>    - Bayesian Networks
>      - Graph based representation of conditional independence. 
>        - CPT - Table records with the probabilities
>2. Local Semantics and Markov Blanket
>
>    - Global Semantics
>    - Local Semantics, Markov Blanket
>    - Construction of Bayesian Networks
>3. Inference to BNs
>
>    - Inference Tasks by BNs
>
>    - Inference by Enumeration
>
>    - Complexity 
>
>      $O(d^kn)$, for $k$ parents and $d$ values. 
>4. Sampling Methods
>
>    - Prior Sampling
>    - Rejection Sampling
>    - Likelihood Sampling

### 3.1. Naive Bayes and Bayesian Networks

##### 3.1.1. Naive Bayes

- Definition

  - In naive Bayes models, one assumes that
    $$
    P(\text{Cause}, \text{Effect}_1, ..., \text{Effect}_n) = P(\text{Cause})\prod\limits_i P(\text{Effect}_i | \text{Cause})
    $$
    
  - Conditional independence is an example of naive Bayes. 
  
  - *Total number of parameters* is **linear** in *the number of conditionally independent effects* $n$.
  
- Naive, because it is oversimplifying

  - In many cases the $\text{effect}$ variables <u>aren't actually conditionally independent</u> given the $\text{cause}$ variable.
  
    > e.g.
    >
    > $\text{Cause}$: it rained yesterday
    >
    > $\text{Effect}_1$: the streets are wet this morning
    >
    > $\text{Effect}_2$: I'm late for my class
    >
    > If the streets are wet this morning ($E_1$), then an accident was more likely to happen and the caused traffic jam could be the reason for being late.
  
- Visualization

  ```mermaid
      graph TD
  	  Cav(Cavity)
  	  Ta(Toothache)
  	  Ca(Catch)
  	
  	  Cav-->Ta
  	  Cav-->Ca
  	
  	  C(Cause)
  	  other(...)
  	  E1(Effect1)
  	  En(Effectn)
  	
  	  C-->E1
  	  C-->other
  	  C-->En
  ```

##### 3.1.2. Bayesian Networks

- Definition

  - A simple, **graphical notation** for conditional independence assertions and hence for compact specification of full joint distributions. 

    >  e.g.
    >
    > Topology of network encodes conditional independence assertions:
    >
    > ```mermaid
    > graph TD
    > 	W(Weather)
    > 	C(Cavity)
    > 	Ta(Toothache)
    > 	Ca(Catch)
    > 	
    > 	C-->Ta
    > 	C-->Ca
    > ```
    >
    > $\text{Weather}$ is independent of the other variables. 
    >
    > $\text{Toothache, Catch}$ are conditionally independent given $\text{Cavity}$. 

- Bayesian networks are a way to represent these dependencies.

  - Each node corresponds to a random variable (may be discrete or continuous). 
  - A directed edge (also called link or arrow) from node $u$ to node $v$ means that $u$ is the **parent** of $v$. 
  - Likewise, $v$ is a **child** of $u$. 
  - The graph has no directed cycles (and hence isa directed acyclic graph, DAG).
  - Each node $u$ has a conditional probability $P(u|\text{Parents}(u))$ that quantifies the effect of the parent nodes. 

  > e.g.
  >
  > $C$ depends on $A$ and $B$, and $A, B$ are independent.
  >
  > ```mermaid
  > graph TD
  > 	A --> C
  > 	B --> C
  > ```

##### 3.1.3. Conditional Probability Table (CPT)

- Definition

  - Represent the knowledge about the probabilities, giving the distribution over $u$ for each combination of parent values. 

    > e.g.
    >
    > | $A$  | $B$  | $P(C | A, B)$ |
    > | :--: | :--: | :-----------: |
    > |  T   |  T   |      0.2      |
    > |  T   |  F   |     0.123     |
    > |  F   |  T   |      0.9      |
    > |  F   |  F   |     0.51      |

- Note

  - Beysian networks is **NOT equivalent** to Naive Bayes. These are somewhat orthogonal. Naive Bayes might be used in Bayesian networks.
  - Naive Bayes is basing on Bayes' Rule.

- Example

  > e.g.
  >
  > Q: I'm at work, neighbor John calls to say my alarm is ringing, but neighbor Mary doesn't call. Sometimes it's set off by minor earthquakes. Is there a burglar?
  >
  > Variables: $\text{Burglar, Earthquake, Alarm, JohnCalls, MaryCalls}$
  >
  > Network topology reflects causal knowledge:
  >
  > - A burglar can set the alarm off, 
  > - An earthquake can set the alarm off, 
  > - The alarm can cause Mary to call, 
  > - The alarm can cause John to call
  >
  > >```mermaid
  > >graph TD
  > >	B(Burglary)
  > >	E(Earthquake)
  > >	JC(JohnCalls)
  > >	MC(MarryCalls)
  > >	A(Alarm)
  > >	
  > >	B-->A
  > >	E-->A
  > >	A-->JC
  > >	A-->MC
  > >```
  > >
  > >Where $P(B)=0.001, P(E)=0.002$
  >
  > >CPTs
  > >
  > >- Alarm
  > >
  > >  | $B$  | $E$  | $P(A|B, E)$ |
  > >  | ---- | ---- | ----------- |
  > >  | T    | T    | 0.95        |
  > >  | T    | F    | 0.94        |
  > >  | F    | T    | 0.29        |
  > >  | F    | F    | 0.001       |
  > >
  > >- JohnCalls
  > >
  > >  | $A$  | $P(J|A)$ |
  > >  | ---- | -------- |
  > >  | T    | 0.90     |
  > >  | F    | 0.05     |
  > >
  > >- MarryCalls
  > >
  > >  | $M$  | $P(J|M)$ |
  > >  | ---- | -------- |
  > >  | T    | 0.70     |
  > >  | F    | 0.01     |
  > >
  > >Since $P(J|A) = 0.9$, $P(\neg J |A) = 0.1$

---

### 3.2. Local Semantics and Markov Blanket

##### 3.2.1. Global Semantics

- Definition

  - We can calculate the full joint distribution as the product of the local conditional distributions:
    $$
    P(x_1, ..., x_n) = \prod\limits_{i=1}^{n}P(x_i|\text{Parents}(X_i))
    $$
  
    > e.g.
    >
    > Considering the previous example. 
    >
    > $\begin{matrix} P(j \wedge m \wedge a \wedge \neg b \wedge \neg e) &= & P(j|a)P(m|a)P(a|\neg b, \neg e) P(\neg b) P(\neg e) \\ ~ &= & 0.9 \cdot 0.7 \cdot 0.001 \cdot 0.999 \cdot 0.998 \\ ~ &\approx &0.00063 \end{matrix}$
    >
    > This is an application of chain rule. 
  
- Compactness

  - A CPT for Boolean $X_i$ with $k$ Boolean parents has $2^k$ rows for the combinations of parent values. 
  - Each row requires one probability $p$ for $X_i = \text{True}$. 
  - If each variable has no more than $k$ parents, the complete network requires $O(n \cdot 2^k)$ numbers. 
  - Grows linearly with $n$, vs. $O(2^n)$ for the full joint distribution. 


##### 3.2.2. Local Semantics and Markov Blanket

- Motivation

  - We don't need to compute all the network for a specific nodes. 

  - We can consider the local semantics nodes for further computation, where they specify the nodes with direct connection to our target node.
  
  - This could help in reducing the time complexity. 
  
- Local Semantics

  - A node $X$ is conditionally independent of its non-descendants given its *parents*. 

    > e.g.
    >
    > ```mermaid
    > graph TD
    >   U_1
    >   U_m
    >   Z_1j
    >   Z_nj
    >   Y_1
    >   ...
    >   Y_n
    >   X
    > 
    > 	U_1 --> X
    > 	U_m --> X
    > 	Z_1j --> Y_1
    > 	Z_nj --> Y_n
    > 	X --> Y_1
    > 	X --> ...
    > 	X --> Y_n
    > ```
    >
    > The local semantics is then the area of $U_1, ..., U_m$, i.e., All the parents of $X$. 

- Markov Blanket

  - Each node is conditionally independent of all others given its **Markov blanket**: *parents, children and children's parents*. 

  - Note that the node itself is NOT included. 
  
    > e.g.
    >
    > The local semantics is then the area of $U_1, ..., U_m \vee Z_{1j} ,..., Z_{nj} \vee Y_1 ,..., Y_n$. 


##### 3.2.3. Construction of Bayesian Networks

- Knowledge representation

  - Build Bayesian networks like any other form of knowledge representation. 
    1. First figure out the variables that describe the world. 
    2. Then decide how they are connected (conditional independent relationship).
    3. Then work out the values in the CPTs.
  - CPT grows exponentially with number of parents. Use distributions that are defined compactly. 
  - **Deterministic** nodes are the simplest case.

  > e.g.
  >
  > $X = f(\text{Parents}(X))$ for some functions $f$: 
  >
  > - Boolean functions
  >
  >   $\text{NorthAmerican} \iff \text{Candian} \vee \text{US} \vee {Mexican}$
  >
  > - Numerical relationships among continuous variables
  >
  >   $\frac{\partial \text{Level}}{\partial t} = \text{inflow + precipitation - outflow - evaporation}$

---

### 3.3. Inference by Enumeration

##### 3.3.1. Inference Tasks by Using Bayesian Networks

- Examples of task
  - Simple queries - compute posterior marginal $P(X_i|E=e)$
    - Enumeration
    - Rejection sampling (using prior sampling)
    - Likelihood weighting
    - Gibbs sampling
  - Conjunctive queries - $P(X_i, X_j|E=e) = P(X_i|E=e)P(X_j|X_i, E=e)$
  - Optimal decisions
  - Value of information
  - Sensitivity analysis
  - Explanation
- Many approaches to inference in Bayesian networks. 
  - Motivation - Bayesian networks exploit conditional independence to create a more compact set of information. We want reasonable efficient computation for solving tasks. 
  - Methods including enumeration or other sampling techniques. 


##### 3.3.2. Inference by Enumeration

- Inference tasks for simple query

  > e.g.
  >
  > Still consider the burglary example.
  >
  > ```mermaid
  > graph TD
  > 	B --> A
  > 	E --> A
  > 	A --> J
  > 	A --> M
  > 	
  > ```
  >
  > $\begin{matrix} P(B|j, m) &= &\frac{P(B, j, m)}{P(j, m)} \\ ~ &= &\alpha P(B, j, m) \\ ~ &= &\alpha \sum\limits_e \sum\limits_a P(B, e, a, j, m) \end{matrix}$
  >
  > We could rewrite full joint entries taking network into account:
  >
  > $\begin{matrix} P(B|j, m) &= &\alpha \sum\limits_e \sum\limits_a P(B)P(e)P(a|B, e)P(j|a)P(m|a) \\ ~ &= & \alpha P(B) \sum\limits_e P(e)\sum\limits_a P(a|B, e) P(j|a) P(m|a) \end{matrix}$

  - Evaluation Tree

    - Evaluate the probabilistic expression by going trhough the variables in order, multiplying CPT entries along the way. 
    - At each point, loop through the possible values of the variable. 
    - Compute by **exact** samples. 
    - Use a tree to compute. Inefficient. 

  - Enumeration algorithm

    ```
    function ENUMERATION-ASK(X, e, bn) returns a distribution over X
    	inputs: 
    		X, the query variable
    		e, observed values for variables E
    		bn, a Bayesian network {X} union E union Y
    	Q(X) <- a distribution over X, initially empty 
    	
    	for each value xi of X do
    		extend e with value xi for X
    		Q(xi) <- ENUMERATE-ALL(VARS[bn], e) 	
    	return NORMALIZE(QpX q)
    
    ```

  - Other approach

    - Variable elimination - Evaluates the enumeration tree bottom up, remembering intermediate values.
    - Clustering algorithms - Group variables together strategically for improving multiple queries. 
    - However, *all* exact inference can be computationally intractable.

##### 3.3.3. Complexity of Exact Inference

- Singly connect networks (Polytrees)
  - Any two nodes are connected by at most one (undirected) path. 
  - Time & space complexity is $O(d^kn)$, for $k$ parents and $d$ values. 
- Multiply connected networks
  - Exponential time and space complexity, even when number of parents of a node is bounded.
  - Inference is NP-hard. 

---

### 3.4. Sampling Methods

##### 3.4.1. Prior Sampling

- Motivation

  - Joint Distribution has a high time complexity, as it is an NP-hard problem. 

  - Approximate sampling could help us for optimization. 
  
- Process

  - Estimate $P(e)$. 

  - Take $m$ random samples from the network. Let $X_i$ be the binary r.v. that is $1$ if the event sampled in the $i$th run is $e$. Simply output: 
    $$
    \hat{P}(e) = \frac{\sum\limits^n_{i=1} X_i}{n}
    $$

  - Accroding to the law of large numbers, $\lim_{n \to \infin} \hat{P} = P$. 

- Evaluation

  - Same for joint probabilities. 
  - The more runs, the more accurate the probability. 
  - Compute by **approximation.** 
  - Ineffecient. 

- Prior sampling algorithm

  ```
  function PRIOR_SAMPLE(bn) returns an event sampled from bn
  	inputs: 
  		bn, a belief network specifying joint distribution P(X1, ..., Xn)
  	x <- an event with n elements
  	
  	for i = 1 to n do
  		xi <- a random sample from P(Xi | parents(Xi))
  			given the values of parents(Xi) in x
  	return x
  	
  ```

##### 3.4.2. Rejection Sampling

- Process

  - Estimate $P(X|e)$. 
  - Generate samples by prior sampling. 
    - If the sample is such taht $e$ holds, use it to build an estimate. 
    - Otherwise, ignore it. 

- Evaluation

  - More efficient than prior sampling. But,
  - For unlikely events, may have to wait a long time to get enough matching samples. 
  - Compute by **approximation.** 
  - Still inefficient. 

- Rejection sampling algorithm

  ```
  function REJECTION-SAMPLING(X, e, bn, N) returns an estimate of P(X|e)
  	local variables: 
  		N, a vector of counts over X, initially zero
  		
    for j = 1 to N do
    	x <- PRIOR-SAMPLE(bn)
    	if x is consistent with e then
    		N[x] <- N[x]+1 where x is the value of X in x
    return NORMALIZE(N[X])
    	
  ```

##### 3.4.3. Likelihood Sampling

- Likelihood Function* 

  - Estimate $P(X|\theta)$ where $\theta$ is a parameter of the distribution $X$. 

  - Assume we have samples $x_1, x_2, ..., x_n \in X$, the likelihood function $L(\theta)$ is defined by the joint probability of data basing on a given parameter $\theta$: 
    $$
    L(\theta) = P(x_1, x_2, ..., x_n | \theta)
    $$

- Process

  - Sampling technique basing on likelihood function. Version of importance sampling. 
  - Fix evidence variable to $\text{True}$, so just sample relevant events. Then weight them with the likelihood that they fit the evidence. 
  - Use the probabilities we know to weight the samples. 

- Evaluation

  - Compute by **approximation.** 
  - More samples, more accuracy. 

- Likelihood Algorithm

  ```
  function LIKELIHOOD-WEIGHTING(X, e, bn, N) returns an estimate of P(X|e)
  	local variables:
  		W, a vector of weighted counts over X, initially zero
  		
  	for j = 1 to N do
  		x, w <- WEIGHTED-SAMPLE(bn)
  		W[x] <- W[x] + w where x is the value of X in x
  	return NORMALIZE(W[X])
  
  ```

  ```
  function WEIGHTED-SAMPLE(bn, e) returns an event and a weight
  	x <- an event with n elements
  	w <- 1
  	
  	for i = 1 to n do
  		if Xi has a value xi in e
  			then w <- w * P(Xi = xi |parents(Xi))
  			else xi <- a random sample from P(Xi | parents(Xi))
  	return x, w
  	
  ```

##### 3.4.4. Gibbs Sampling

> Note: This is not assessed. 

- Process

  - A rather different approach to sampling. Part of the Markov Chain Monte Carlo (MCMC) family of algorithms. 
  - Generate samples by making a random change to the previous sample, instead of from scartch. 
    - Starts with an arbitrary state.
    - Pcik state with evidence variables fixed at observed values.
    - Generate next state by randomly sampling from a non-evidence variable.
    - Do this sampling conditional on the current values of Markov blanket. 

- Evaluation

  - Compute by **approximation.** 

- Gibbs Sampling Algorithm

  ```
  function GIBBS-ASK(X, e, bn, N) returns an estimate of P(X|e)
  	local variables:
  		N[X], a vector of counts over X, initially zero
  		Z, the nonevidence variables in bn
  		x, the current state of the network, initially copied from e
  		
  	initialize x with random values for the variables in Z
  	for j = 1 to N do
  		for each Zi in Z do
  			sample the value of Zi in x from P(Zi|mb(Zi))
  				given the values of MB(Zi) in x
  			N[x] <- N[x] + 1 where x is the value of X in x
  	return NORMALIZE(N[X])
  	
  ```


##### 3.4.5. Example

> e.g.
>
> Consider the following BN
>
> ```mermaid
> graph TD
> 	M --> S
> 	M --> T
> 	S --> C
> 	T --> C
> 	T --> H
> ```
>
> with the following CPT
>
> | P(M) |
> | :--: |
> | 0.1  |
>
> |  M   | P(S\|M) |
> | :--: | :-----: |
> |  T   |   0.8   |
> |  F   |   0.2   |
>
> |  M   | P(T\|M) |
> | :--: | :-----: |
> |  T   |   0.7   |
> |  F   |   0.1   |
>
> |  S   |  T   | P(C\|S, T) |
> | :--: | :--: | :--------: |
> |  T   |  T   |    0.95    |
> |  T   |  F   |    0.95    |
> |  F   |  T   |    0.85    |
> |  F   |  F   |    0.01    |
>
> |  T   | P(H\|T) |
> | :--: | :-----: |
> |  T   |   0.9   |
> |  F   |   0.7   |
>
> Assume we have a random number generator that gives the numbers in the given order
>
> ```
> run1: 0.14, 0.57, 0.01, 0.43, 0.59
> run2: 0.50, 0.12, 0.54, 0.97, 0.51
> run3: 0.49, 0.67, 0.96, 0.55, 0.89
> run4: 0.21, 0.34, 0.54, 0.97, 0.51
> run5: 0.99, 0.99, 0.99, 0.99, 0.99
> ```
>
> We want to get the *prior sampling* result of $P(m, t, h, s, c)$ for the first 5 times runs. 
>
> > Sample $m$:
> > Since $P(m) = 0.1$, we pick a random number $x$ and check, if $x \leq P(m)$ then $m$ else $\neg m$
> > We get $x=0.14, x > P(m)$, thus $\neg m$. 
> >
> > Sample $t$: ...
> > 
> > Sample $h$: ...
> > 
> > Sample $s$: ...
> > 
> > Sample $c$: ...
> >
> > Processing all the variables for the first run, we get the sampled result $(\neg m, \neg s, t, h, c)$ as a result. We continue our sampling for 5 times, there are 2 sampled results as $(\neg m, \neg s, \neg t, \neg h, \neg c)$.
> > Thus, the result is $\frac{2}{5}$. 
> 

