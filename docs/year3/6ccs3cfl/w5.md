## WEEK V - Grammar & Parsing

>[🏠 MENU - 6CCS3CFL](year3/6ccs3cfl.md)
>
>[⬅️ WEEK WEEK IV - Lexing](year3/6ccs3cfl/w4.md)
>
>[➡️ WEEK VI - Parsing Combinators](year3/6ccs3cfl/w6.md)
>
>Outlines:
>
>1. Parser
>     - Introduction to Parser
>     - CFGs
>     - CFL
>
>2. CYK Algorithm
>     - Removing Left-Recursion
>     - Removeing Epsilon-Rules
>     - CYK Algorithm
>     - Context Sensitive Grammars

### 5.1. Parser

##### 5.1.1. Introduction to Parser

- Definition

  - Parser takes a sequence of tokens. 

    `key(read) lpar id(n) rpar semi`

  - Output is an asbtract syntax tree, identity and verify the code structure. 
  - However, prasing does NOT check semantics correctness. 

    > e.g.
    >
    > whether a function is not used before it is defined.
    >
    > whether a function has the correct number of arguments or are of correct type.
    >
    > whether a variable can be declared twice in a scope. 

##### 5.1.2. Context-Free Language and Context-Free Grammars (CFGs)

- Motivation

  - While regular expressions are very useful for lexing, it is limited in recongizing tokens.
    - There is no regular expression that can recognize the language $a^nb^n$. i.e.,
      $(((()()))())$ vs. $(((()())()))$
      Thus we cannot find out with regular expressions whether parentheses are matched or unmatched. 
    - Regular expressions are not recursive, e.g., $(1 + 2) + 3$. 

  - In order to solve recognition problems, we need more powerful tools. Thus, we will introduce **context-free languages**. 

  - Hierarchy of Languages

    > All languages
    >
    > > Decidable languages
    > >
    > > > Context sensitive languages
    > > >
    > > > Context-free languages
    > > >
    > > > > Regular languages

- Definition

  - Context-free in this setting means that "words" have one meaning only and this meaning is independent from the context the "words" appear in. 

    > e.g.
    >
    > In CFGs, ambiguity issues like `Time flies like an arrow. Fruit flies like bananas.` from natue languages where the meaning of `files` depends on the surrounding `context` are avoided as much as possible. 

  - Context-free languages are usually specified by grammars. 
  - A CFG $G$ consists of

    - A finite set of **non-terminal symbols** and the $\epsilon$-symbol for empty string. Stands for the symbols that can be further substituted by rules. Usually notated in upper case letters, e.g. $A, B, C$. 
    - A finite set **terminal symbols or tokens**. Stands for the symbols that cannot be subsituted any more. Usually notated in lower case letters, e.g. $a, b, c$. 
      > e.g. Lower case letters, numbers, other static values. 
    
    - A start symbol (which MUST be a nonterminal).
    - A set of rules
      $$
      A ::= \text{rhs} \\
      A ::= \text{rhs}_1 | \text{rhs}_2 | ...
      $$
      
      where $\text{rhs}$ are sequences involving terminals and nonterminals, including the empty sequence $\epsilon$. 
    - We use $\cdot$ symbol to separate components on the right hand-side, as in the grammar for well-parenthesised expressions. 
    - We use $|$ symbol as a shorthand notation for several rules. Left hand-side symbol can be replaced by every single rule in the right hand-side. 

- Palindromes Example

  - A grammar for palindromes over the alphabet $\{a, b\}$:


$$
  \begin{array}{lll}
  S &::= &a \cdot S \cdot a \\
  S &::= &b \cdot S \cdot b \\
  S &::= &a \\
  S &::= &b \\
  S &::= &\epsilon \\
  \end{array}
$$
  i.e.,
$$
  S ::= a \cdot S \cdot a | b \cdot S \cdot b | a | b | \epsilon
$$

  - Arithmetic Expressions

$$
  \begin{array}{lll}
  E &::= &0|1|2|...|9 \\
  ~ &~ &|E \cdot + \cdot E \\
  ~ &~ &|E \cdot - \cdot E \\
  ~ &~ &|E \cdot * \cdot E \\
  ~ &~ &|(\cdot E \cdot) \\
  \end{array}
$$

  > e.g. $1 + 2 * 3 + 4$

- A CFG Derivation

	- A *derivation* for a grammar starts with the starting symbol of the grammar and in each step replaces one non-terminal by a right-hand side of a rule. 
  - Process
    1. Begin with a string containing only the start symbol, say $S$
    2. Replace any nonterminal $X$ in the string by the right-hand side of some production $X ::= \text{rhs}$
    3. Repeat 2. until there are no nonterminals left
    
        $S \to ... \to ... \to ... \to ...$

  > e.g.
  > $$
  > S ::= \epsilon | a \cdot S \cdot a | b \cdot S \cdot b
  > \\
  > \begin{array}{lll}
  > S &\to &aSa \\
  > ~ &\to &abSba \\
  > ~ &\to &abaSaba \\
  > ~ &\to &abaaba \\
  > \end{array}
  > $$
  > 


##### 5.1.3. Language of a CFG

- Definition

  - Let $G$ be a context-free grammar with start symbol $S$. Then the **language** $L(G)$ is defined as the set of strings derivated by a derivation, that is
    $$
    \{c_1 ... c_n | S \to^* c_1 ... c_n \text{ with all } c_i \text{ being non-terminals}\}
    $$
    or
    $$
    \{c_1, ..., c_n | \forall i. c_i \in T \wedge S \to^* c_1, ..., c_n \}
    $$

- Properties

  - Terminals, since there are no rules for replacing them.
  - Once generated, terminals are *permanent*. 
  - Terminals ought to be tokens of the language (but can also be strings).

- Parse Trees

  - A *parse-tree* encodes how a string is derived with the starting symbol on top and each non-terminal containing a subtree for how it is replaced in a derivation.
  - We are often interested in these parse-trees since they encode the structure of how a string is derived by a grammar.

  ```mermaid
  graph TD
  	E1[E] --> T1[T]
  	
  	E1 --> p1[+]
  	E1 --> E2[E]
  	T1 --> F1[F]
  	F1 --> 1
  	
  	E2 --> T2[T]
  	T2 --> F2[F]
  	F2 --> 2
  	T2 --> m1[+]
  	T2 --> T3[T]
  	T3 --> F3[F]
  	F3 --> 3
  	
  	E2 --> p2[+]
  	E2 --> E3[E]
  	E3 --> T4[T]
  	T4 --> F4[F]
  	F4 --> 4
  	

- Examples

  > e.g. Arithmetic Expressions
  > $$
  > \begin{array}{lcl}
  > E &::= &0 ... 9 \\
  > ~ &| &E \cdot + \cdot E \\
  > ~ &| &E \cdot - \cdot E \\
  > ~ &| &E \cdot * \cdot E \\
  > ~ &| &(\cdot E \cdot) \\
  > \end{array}
  > $$
  > 

- A CFG is left-recursive if it has a nonterminal $E$ such that $E \to^+ E \cdot ...$


---

### 5.2. CYK Algorithm

##### 5.2.1. Removing Left-Recursion

- Ambiguous Grammar

  - A grammar is **ambiguous** if there is a string that has at least two different parse trees.

    > e.g. 
    >
    > $1 + 2 * 3 + 4$
    >
    > $\texttt{if a then if x then y else c}$

- Left-recursiveness

  - Left-recursiveness can involve more than one step in the derivation. Since some algorithms cannot cope with them (with left-recursive grammars they will fall into a loop). 

- Process

  > e.g.
  >
  > Consider the following grammar for binary numbers with defining by a left-recursion:
  > $$
  > B ::= B \cdot B | 0 | 1
  > $$
  >
  > - We can separate the grammar into two parts and focus on the recursion part. 
  >
  > - Suppose the left recursion rule is of the form $B\alpha$ ($\alpha$ is the things following with left-recursive non-terminal) and the rest part called $\beta$. We could introduce a new non-terminal $B'$.
  >   $$
  >   B ::= \beta \cdot B' \\
  >   B' ::= \alpha \cdot B' | \epsilon
  >   $$
  >
  > - We would after the transformation end up with the rules
  >   $$
  >   B ::= 0 \cdot B' | 1 \cdot B' \\
  >   B ::= B \cdot B' | \epsilon
  >   $$
  >
  > - Because there will always be a $B$ in front of a $B'$, and $B$ now has always a 0 or 1 in front, so a $B'$ can never be in the first place.
  >
  > The point is that we can in principle transform every left-recursive grammar into one that is *non-left-recursive*. 

##### 5.2.2. Removing $\epsilon$-Rules

- Motivation

  - $\epsilon$-rule always applies but since it recognizes the empty string, it does not make any progress with recognizing a string. 
  - Get rid of $\epsilon$ can significantly optimize the complexity of parse combinators and CYK algorithm. The best possible complexity for parsing is $O(n^3)$ for context-free languages. 

- Process

  > e.g.
  >
  > Consider again the following grammar for binary numbers with defining by empty string.
  > $$
  > B ::= 0 \cdot B' | 1 \cdot B' \\
  > B' ::= B \cdot B' | \epsilon
  > $$
  > In this case we look for rules of the generic form $A ::= \alpha \cdot B' \cdot \beta$. 
  >
  > - There are rules that use $B'$ and something (say, $\alpha$) is in front of $B'$ and something follows ($\beta$). Such rules need to be replaced by additional rules of the form $A := \alpha \cdot B' \cdot \beta$. 
  > - In our running example there are the two rules for $B$ which fall into the category $B ::= 0 \cdot B' | 1 \cdot B'$. 
  > - To follow the general scheme of the transformation, the $\alpha$ is either 0 or 1, and the $\beta$ happens to be empty. So we need to generate new rules for the form $A := \alpha \cdot \beta$, which in our particular example means we obtain $B ::= 0 \cdot B' | 1 \cdot B' | 0 | 1$
  >
  > - Recursively check and update and obtain $B' ::= B \cdot B' | B$
  >
  > - Thus we get a final grammar with no $\epsilon$ symbol. 
  >   $$
  >   B ::= 0 \cdot B' | 1 \cdot B' | 0 | 1 \\
  >   B' ::= B \cdot B' | B
  >   $$

##### 5.2.3. Cocke-Younger-Kasami (CYK) Algorithm

- Definition

  - Used to check if a string can be generated by a given CFG. This could also helps for building a syntax tree. 
  - This algorithm works with grammars that are in *Chomsky normal form*. In Chomsky normal form all rules must be of the form 
    - $A ::= a$, where $a$ is a terminal, or
    - $A ::= B \cdot C$, where $B$ and $C$ are non-terminals. 
    - No rules can contain $\epsilon$. 
  
  - Chomsky Normal Form
  
    - A grammar for palindromes over the alphabet $\{a, b\}$:
  
      $S ::= a \cdot S \cdot a | b \cdot S \cdot b | a \cdot a | b \cdot b | a | b $
  
    - CYK Algorithm
      - Fastest possible algorithm for **recognition problem**. 
      - TIme Complexity - $O(n^3)$
      - Grammars need to be transformed into Chomsky normal form
  
- Process

  > e.g.
  >
  > Suppose the following grammar in Chomsky norml form: 
  > $$
  > \begin{array}{lll}
  > S &::= & N \cdot P \\
  > P &::= & V \cdot N \\
  > N &::= & N \cdot N \\
  > N &::= & \text{students | Jeff | geometry | trains} \\
  > V &::= & \text{trains} \\
  > \end{array}
  > $$
  > The rough idea behind this grammar is that $S$ stands for a sentence, $P$ is a predicate, $N$ is a noun and so on.
  >
  > Consider the string `Jeff trains geometry students`
  >
  > | **1** |          |            |              |              |
  > | ----- | -------- | ---------- | ------------ | ------------ |
  > | **2** |          |            |              |              |
  > | **3** |          |            |              |              |
  > | **4** | $N$      | $N, V$     | $N$          | $N$          |
  > |       | **Jeff** | **trains** | **geometry** | **students** |
  >
  > - The last row contains the information about all words and their corresponding non-terminals. 
  >
  > - The row above contains the information about 2-word parts of the sentence. For instance, the grid *3a)* contains `Jeff trains` while *3b)* contains `trains geometry`. 
  >
  >   According to the rules we thus get the following table: 
  >
  >   | **1** | $S$      |            |              |              |
  >   | ----- | -------- | ---------- | ------------ | ------------ |
  >   | **2** | NA       | $N$        |              |              |
  >   | **3** | $P$      | $N$        | $N$          |              |
  >   | **4** | $N$      | $N, V$     | $N$          | $N$          |
  >   |       | **Jeff** | **trains** | **geometry** | **students** |
  >
  > - For 2nd row we continue the computation by considering the 3-word parts of the sentence. For instance the grid *2a)* contains `Jeff trains | geometry` and `Jeff | trains geometry`. We then compute them by rules. 
  >
  > - If in the top-field the **staring symbol $S$ appears** (possibly together with other non-terminals), then the sentence is ACCEPTED by the grammar. It will be rejected otherwise. 
  >
  >   - Here $S ::= N \cdot P$ according to the split `Jeff | trains geometry students`

##### 5.2.3. Context Sensitive Grammars

- It is much harder to find out whether a string is parsed by a context sensitive grammar:
  $$
  \begin{array}{lll}
  S &::= &bSAA | \epsilon \\
  A &::= & a\\
  bA &::= & Ab \\
  \end{array}
  $$
  $S \to ... \to^? ababaa$
