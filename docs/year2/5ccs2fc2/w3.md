## WEEK III - The Cook-Levin Theorem / Divide-and-Conquer

> [🏠 MENU - 5CCS2FC2](year2/5ccs2fc2.md)
>
> [⬅️ WEEK II - P vs NP](year2/5ccs2fc2/w2.md)
>
> [➡️ WEEK IV - Graph Algorithm](year2/5ccs2fc2/w4.md)
>
> Outlines:
>
> - The Cook-Levin Theorem: $\textbf{SAT}$ is **NP-complete**
> - Divide-and-Conquer *(i.e., mostly about recursion)*
>   - Towers of Hanoi algorithm
>   - Merge-Sort algorithm
> - Induction *
>   - Giving a recursively defined function, prove the solution is correct
> - The Master theory *
>   - Used to compute a recursive complexity expression
>   - Three cases: depending on the non-recursive function
>   
>     $\begin{cases} f(n) < \Theta(n^k) \implies T(n) \in \Theta(n^k) \\f(n) = \Theta(n^k) \implies T(n) \in \Theta(n^k\log_2n)\\ f(n) > \Theta(n^k) \implies T(n) \in \Theta(f(n)) \end{cases} $

### 10. The Cook-Levin Theorem

> ref:
>
> [Proof of the Cook-Levin Theorem - Harvard](http://people.seas.harvard.edu/~cs125/fall16/lec15.pdf)

##### ***Theorem 10.1.*** The Boolean Satisfiability problem $\textbf{SAT}$ is **NP-complete**. 

***Proof.*** 

>We want to show that every problem $X \in \textbf{NP}$ can be reduced to $\textbf{SAT}$. 
>
>1. Let $X \in \textbf{NP}$ be **any problem** belonging to the class $\textbf{NP}$. By definition there is some NDTM $M$ such that, 
>
>    $M$ has polynomial-length computation that accepts $w \iff w \in X
>
>2. For each state $q \in Q$, symbol $a \in \Sigma$ and integers $i, t \leq T_M(n)$:
>
>    $C_{i,t,a}=$ Cell $i$ of the $M$'s tape contains symbol $a$ at time $t$. 
>
>    $H_{i,t}$ = The tape head is in the position $i$ at time $t$.
>
>    $S_{i, t}$ = The machine is in state $q$ at time $t$. 
>
>  > e.g. 
>  >
>  > - "The machine cannot be both in state $q_4$ and $q_5$ at time $t=2$" $\implies \neg(S_{q_4, 2} \land S_{q_5, 2})$
>  > - "At time $t=3$ the tape head must be in positions 0 or 1 or 2 or 3" $\implies (H_{0,3} \vee H_{1,3} \vee H_{2,3} \vee H_{3,3})$
>  > - "At time $t=3$ if cell 1 contains an $a$ then it must not contain a $b$" $\implies C_{3,1,a} \to \neg C_{3,1,b} $
>  > - "At the time $t=6$ if the machine is in state $q_1$ and the tape head is in position 4 and cell 4 contains an $a$ at time $t = 6$, then time $t=7$ the machine will be in state $q_2$, the tape head will move to position 3 and cell 4 will contain a $b$" $\implies (S_{q_1, 6} \vee H_{4,6} \vee C_{4, 6, a}) \to (S_{q_2,7} \vee H_{3,7} \vee C_{4,7,b})$
>
>3. With these propositional variables, we can construct a formula: 
>
>   $F_{M,w} = $ $M$ has a polynomial-length computation that accepts $w$ $\iff w \in X$ 
>
>4. We then have that 
>
>   $w \in X \iff F_{M,w} \text{ is satisifiable }$
>
>   $X \leq_p \textbf{SAT}$ for all $X \in \textbf{NP}$
>

---

### 11. Divide-and-Conquer

##### ***Theorem 11.1.***  Divide-and-Conquer Technique

**Divide)** Divide the problem into several 'self-similar' but smaller sub-problems. 

**Conquer)** Solve these sub-problems recursively. 

**Combine)** Recombine the sub-problems into a solution for the whole problem. 

>e.g. The Towers of Hanoi
>
>Constraint 1) You can only move one block at a time. 
>
>Constraint 2) You cannot place any block on top of a smaller block. 

##### ***Theorem 11.2.***  The Towers of Hanoi

The number of steps required for the `MOVETOWER` algorithm satisfies the following recurrence relation: 

$T(1) = 1,\ T(n)=2T(n-1)+1$ for all $n>1$. 

>`MOVETOWER(n, 1, 3)`: 
>
>1. If $n = 1$ then `MOVE(1, 3)`
>2. Else
>	3. `MOVETOWER(n-1, 1, 2)`
>	4. `MOVE(1,3)`
>	5. `MOVETOWER(n-1, 2, 3)`

##### ***Theorem 11.3.***  The Merge-Sort Algorithm

The number of steps required for the MERGESORT algorithm satisfies the following recurrence relation:

$T(1)=1,\ T(n)=T(\lfloor\frac{n}{2}\rfloor)+T(\lceil\frac{n}{2}\rceil)+n$ for all $n>1$. 

>`MERGERSORT([a1,...,an])`:
>
>1. If $n=1$ then Return `[a1]`
>2. Else
>	3. `MERGESORT([a1,...,a[n//2]]) ` $\rightarrow L$ 
>	3. `MERGESORT([a[n//2+1],...,an])` $\leftarrow R$
>	3. `MERGE(L, R)` $\rightarrow A$
>	3. Return $A$

---

### 12. Induction

##### ***Theorem 12.1.*** Proof by Induction

**Base Case)** Show that your solution holds for $n=1$,  

**Inductive Case)** 

i) Assume your result holds for $n=k$, 

ii) Substitute to confirm that it also holds for $n=(k+1)$. 

> i.e., Giving a function that is defined recursively, using induction to prove that the solution is held for all values. 

***Example 12.1.***

Let $T(n)$ be a recursion relation defined by $T(1)=1,\ T(n)=2T(n-1)-1$ for all $n>1$. 

Show that $T(n)=2^n-1$, for all $n \geq 1$. 

> **Base Case)** First show that $T(n) = 2^n - 1$ for $n=1$. 
>
> $T(1)=1$ *(Left Hand Side)* **=** $2^1-1=1$ *(Right Hand Side)*
>
> **Inductive Case)** Assume that 
>
> *(I.H.)* $T(k)=2^k-1$ for some $k \geq 1$, we then have that for $n=(k+1)$, we have that: 
>
> > $T(k+1) \\= 2T(k) + 1 \\= 2(2^k-1) + 1 \\= (2^{k+1}-2) + 1 \\= 2^{k+1}-1$

***Example 12.2.***

Let $T(n)$ be a recursion relation defined by $T(1)=2,\ T(n)=T(n-1)+n$ for all $n>1$. 

Show that $T(n)=\frac{n^2+n}{2}$, for all $n>1$. 

>**Base Case)** First show that $T=\frac{n^2+n}{2}$ for $n=1$. 
>
>$T(1)=1$ *(Left Hand Side)* **=** $\frac{1^2+1}{2}=1$ *(Right Hand Side)*
>
>**Inductive Case)** Assume that
>
>*(I.H.)* $T(k)=\frac{k^2+k}{2}$ for some $k \geq 1$, we then have that for $n=(k+1)$. 
>
>>$T(k+1) \\= T(k) + (k+1) \\= (\frac{k^2+k}{2})+(k+1) \\= \frac{(k+1)^2+(k+1)}{2}$

##### ***Theorem 12.2.*** Proof by Strong Induction

**Base Case)** Show that your solution holds for $n=1$, 

**Inductive Case)** 

i) Assume your result holds for **all** $m \leq k$, 

ii)  Substitute to confirm that it also holds for $n = (k + 1)$.

***Example 12.3.***

Let $T(n)$ be a recursion relation defined by $T(1)=1,\ T(n)=2T(\lceil\frac{n}{2}\rceil) + n$ for all $n>1$. 

Show that $T(n) \geq n\log_2n$, for all $n \geq 1$. 

>**Base Case)** First show that $T(n) \geq n\log_2n$ for $n=1$. 
>
>$T(1)=1$ *(Left Hand Side)* **=** $1\cdot\log_2(1)=0$ *(Right Hand Side)*
>
>**Inductive Case)** Assume that
>
>*( I.H.)* $T(m) \geq m\log_2m$ for all $m \leq k$ for some $k \geq 1$, we then have that for $n=(k+1)$. 
>
>>$T(k+1) \\ = 2T(\lceil\frac{k+1}{2}\rceil) + (k+1)\\
>>\geq 2(\lceil\frac{k+1}{2}\rceil)\log_2(\lceil\frac{k+1}{2}\rceil)+(k+1)\\
>>\geq 2(\frac{k+1}{2})\log_2(\frac{k+1}{2})+(k+1) \\
>>=(k+1)\log_2(k+1)$

***Example 12.4.***

Let $F(n)$ denote the $n$th *Fibonacci Number* given by $F(0)=0,\ F(1)=1,\ F(n)=F(n-1)+F(n-2)$ for all $n > 1$.

Show that $F(n)=\frac{\Phi^n-\phi^n}{\sqrt{5}}$  for all $n \geq 0$, where $\Phi = \frac{1+\sqrt{5}}{2},\ \phi = \frac{1-\sqrt{5}}{2}$ are *Golden Ratios*. 

>**Base Case)** First show that the formula holds for $n=0$ and $n = 1$. 
>
>$F(0)=0$ *(Left Hand Side)* **=** $\frac{\Phi^0-\phi^0}{\sqrt{5}}=0$ *(Right Hand Side)*
>
>$F(1)=1$ *(Left Hand Side)* **=** $\frac{\Phi^1-\phi^1}{\sqrt{5}}=1$ *(Right Hand Side)*
>
>**Inductive Case)** Assume that 
>
>*(I.H.)* $F(m)=\frac{\Phi^m-\phi^m}{\sqrt{5}}$ for all $m \leq k$ for some $k \geq 1$, we then have that for $n=(k+1)$. 
>
>>$F(k+1) \\ = F(k) + F(k-1) \\
>>= (\frac{\Phi^k-\phi^k}{\sqrt{5}}) + (\frac{\Phi^{k-1}-\phi^{k-1}}{\sqrt{5}})\\
>>= (\frac{(\Phi+1)\Phi^{k-1}-(\phi+1)\phi^{k-1}}{\sqrt{5}})\\
>>= \frac{\Phi^{k+1}-\phi^{k+1}}{\sqrt{5}}
>>$

---

### 13. The Master Theorem

> ref:
>
> [Master Theorem - Zhihu](https://zhuanlan.zhihu.com/p/100531135)
>
> [Proof for Master Theorem - Luogu](https://www.luogu.com.cn/blog/GJY-JURUO/master-theorem)

##### ***Theorem 13.1.*** The Master Theorem

Let $T(n)$ be a monotonically increasing recurrence relation such that, 

$T(n)=aT(\frac{n}{b})+f(n)$ for some constants $a \geq 1, b \geq 2$. Then

$T(n)=\begin{cases} \Theta(n^k) &\text{if }f(n) \in O(n^{k-\epsilon})\\ \Theta(n^k\log_2n) &\text{if } f(n) \in \Theta(n^k)\\ \Theta(f(n)) &\text{if } f(n) \in \Omega(n^{k+\epsilon})\end{cases}$

for some $\epsilon>0$, where $k=\log_ba\ (k>0)$. 

> Note: i.e., 
>
> If a time complexity of an algorithm is a recursive expression $T(n)$, to get the complexity: 
>
> We just need to split the expression in two parts: $aT(\frac{n}{b})$ and $f(n)$ and check the complexity of $f(n)$: 
>
> - If the complexity of $f(n) < \Theta(n^k) \implies T(n)=\Theta(n^k)$ 
> - If the complexity of $f(n) = \Theta(n^k) \implies T(n)=\Theta(n^k\log_2n)$ 
> - If the complexity of $f(n) > \Theta(n^k) \implies T(n)=\Theta(f(n))$ 

***Example 13.1.***

Let $T(n)$ be a recurrence relation defined by $T(1)=1,\ T(n)=9T(\lfloor\frac{n}{3}\rfloor)+\sqrt{(n+1)^5}$ for all $n>1$. Calculate the growth rate of $T(n)$. 

> 1. Identify the parameters: 
>
>    $a=9,\ b=3, \text{therefore }\ k=\log_3(9)=2$
>
> 2. Identify the growth rate of $f(n)$: 
>
>    $f(n)=\sqrt{(n+1)^5} \in \Theta(n^{\frac{5}{2}})$
>
> 3. Identify the case: 
>
>    Assume $\epsilon=\frac{1}{2}$, since $f(n) \in \Theta(n^{\frac{5}{2}})=\Theta(n^{k+\epsilon})>\Theta(n^k)$, then
>
>    $T(n)=\Theta(f(n))=\Theta(n^{\frac{5}{2}})$

***Example 13.2.***

Let $T(n)$ be a recurrence relation defined by $T(1)=1,\ T(n)=2T(\lceil\frac{n}{2}\rceil)+n$ for all $n>1$. Calculate the growth rate of $T(n)$.

>1. Identify the parameters: 
>
>   $a=2,\ b=2, \text{therefore }k=\log_2(2)=1$
>
>2. Identify the growth rate of $f(n)$: 
>
>   $f(n)=n \in \Theta(n^1)$
>
>3. Identify the case: 
>
>   Since $f(n) \in \Theta(n^1)=\Theta(n^k)$, then
>
>   $T(n)=\Theta(n^k\log_2n)=\Theta(n\log_2n)$

***Example 13.3.***

Let $T(n)$ be a recurrence relation defined by $T(1)-1,\ T(n)=2T(\lfloor\frac{n}{3}\rfloor)+\log_2(5n^2)$ for all $n>1$. Calculate the growth rate of $T(n)$. 

>1. Identify the parameters: 
>
>   $a=2,\ b=3, \text{therefore }k=\log_3(2) \approx 1.58$
>
>2. Identify the growth rate of $f(n)$: 
>
>   $f(n)=\log_2(5n^2) \in \Theta(log_2n)$
>
>3. Identify the case: 
>
>   Since $f(n) \in \Theta(log_2n) < \Theta(n^k)=\Theta(n^{log_32})$, then
>
>   $T(n)=\Theta(n^k)=\Theta(n^{log_32})$